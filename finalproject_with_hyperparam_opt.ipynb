{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6_rKmAQu7VE",
        "outputId": "926be32f-39cd-463d-956e-0e6e085c5c7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DTU_Deep_Learning_Image_Segmentation_Project' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://jakabfarkas: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@github.com/Frostforus/DTU_Deep_Learning_Image_Segmentation_Project.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMDSvJ_WvF2l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import json\n",
        "import numpy as np\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "import re\n",
        "import colorsys\n",
        "from scipy.ndimage import zoom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVo8_JbwvJ5R",
        "outputId": "13ec40dc-737a-4e82-d7cc-aaa91a38a7e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: 30,\n",
              " 20: 120,\n",
              " 30: 60,\n",
              " 40: 180,\n",
              " 50: 270,\n",
              " 60: 150,\n",
              " 70: 210,\n",
              " 80: 330,\n",
              " 90: 0,\n",
              " 0: 1}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data = [\n",
        "    [\"orange\", \"hood\", 10],\n",
        "    [\"dark green\", \"front door\", 20],\n",
        "    [\"yellow\", \"rear door\", 30],\n",
        "    [\"cyan\", \"frame\", 40],\n",
        "    [\"purple\", \"rear quarter panel\", 50],\n",
        "    [\"light green\", \"trunk lid\", 60],\n",
        "    [\"blue\", \"fender\", 70],\n",
        "    [\"pink\", \"bumper\", 80],\n",
        "    [\"no color\", \"rest of car\", 90],\n",
        "    [\"white\", \"background\", 0]\n",
        "]\n",
        "\n",
        "color_to_hue = {\n",
        "    \"orange\": 30,\n",
        "    \"dark green\": 120,\n",
        "    \"yellow\": 60,\n",
        "    \"cyan\": 180,\n",
        "    \"purple\": 270,\n",
        "    \"light green\": 150,\n",
        "    \"blue\": 210,\n",
        "    \"pink\": 330,\n",
        "    #TODO: change this to black later\n",
        "    \"no color\": 0,\n",
        "    \"white\": 1,\n",
        "}\n",
        "\n",
        "#, row[1] this can be put into the thing too\n",
        "class_decode_dict = {row[2]: color_to_hue.get(row[0], row[0]) for row in data}\n",
        "class_decode_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnBrRcyzvQkz"
      },
      "outputs": [],
      "source": [
        "def filter_files_by_regex(directory, pattern):\n",
        "    # Use os.listdir() to get a list of all files and directories in the specified directory\n",
        "    file_list = os.listdir(directory)\n",
        "\n",
        "    # Use a list comprehension to filter the files based on the regex pattern\n",
        "    filtered_files = [filename for filename in file_list if re.match(pattern, filename)]\n",
        "\n",
        "    return filtered_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7Ek-ZczvVOv"
      },
      "outputs": [],
      "source": [
        "def load_numpy_arrays(directory, file_names,hue_mapping=class_decode_dict, max_load = 0):\n",
        "    # Create an empty list to store the numpy arrays\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    # Iterate through the file names\n",
        "    for filename in file_names:\n",
        "        if len(x) == max_load: break\n",
        "\n",
        "        # Load the numpy array from the file path\n",
        "        array = np.load(directory + filename)\n",
        "        # Extract the first 3 channels for x\n",
        "        x.append(array[..., :3])\n",
        "\n",
        "\n",
        "        # Extract y\n",
        "        hue_values = np.vectorize(hue_mapping.get)(array[..., -1])\n",
        "\n",
        "        # Convert hue values to RGB values\n",
        "        y_temp = np.empty_like(array[..., :3], dtype=np.uint8)\n",
        "        for i in range(256):\n",
        "            for j in range(256):\n",
        "                if hue_values[i, j] == 1:\n",
        "                    y_temp[i, j] = (0,0,0)\n",
        "\n",
        "                elif hue_values[i, j] == 0:\n",
        "                    y_temp[i, j] = (array[i, j, 0], array[i, j, 1], array[i, j, 2])\n",
        "\n",
        "                else:\n",
        "                    hsv_color = (hue_values[i, j] / 360.0, 1, 1)  # Convert hue to HSV format\n",
        "                    rgb_color = colorsys.hsv_to_rgb(*hsv_color)  # Convert to RGB\n",
        "                    y_temp[i, j] = (int(rgb_color[0] * 255), int(rgb_color[1] * 255), int(rgb_color[2] * 255))\n",
        "\n",
        "        y.append(y_temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMRsCB2Dve-R",
        "outputId": "e43f744f-91d8-487c-d04c-29a93006ea8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "directory_path = 'drive/My Drive/carseg_data/new_arrays/'\n",
        "# regex_pattern = r'black_5_doors_[0-9]*\\.npy'\n",
        "regex_pattern = r'photo_[0-9]*\\.npy'\n",
        "black_car_image_file_names = sorted(filter_files_by_regex(directory_path, regex_pattern))\n",
        "\n",
        "#for filename in black_car_image_file_names:\n",
        "#    print(filename)\n",
        "#    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMEejMsowVqW"
      },
      "outputs": [],
      "source": [
        "numpy_arraysx, numpy_arraysy = load_numpy_arrays(directory_path, black_car_image_file_names, max_load=2001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_8k8nQSwZLO",
        "outputId": "a608bbee-4d54-4e2f-9504-844ea7bfc4c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "169"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(numpy_arraysx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inMEJY_dwe5K"
      },
      "outputs": [],
      "source": [
        "def show_image(image):\n",
        "    # Extract the image data from the last channel (the alpha channel, for example)\n",
        "    image_data = image[:, :]\n",
        "\n",
        "    # Display the image using Matplotlib\n",
        "    plt.imshow(image_data)  # Use 'gray' colormap for grayscale images\n",
        "    plt.axis('off')  # Turn off the axis labels and ticks\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "BJjvOv34whb1",
        "outputId": "cffef676-7a2c-4bb6-ce0a-8ba40f354c77"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "show_image(numpy_arraysx[0])\n",
        "show_image(numpy_arraysy[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVIEvDK4wjd_",
        "outputId": "e83fbb3b-b2c0-4fd7-f4c7-66e30d8dc969"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['orange', 'hood', 10],\n",
              " ['dark green', 'front door', 20],\n",
              " ['yellow', 'rear door', 30],\n",
              " ['cyan', 'frame', 40],\n",
              " ['purple', 'rear quarter panel', 50],\n",
              " ['light green', 'trunk lid', 60],\n",
              " ['blue', 'fender', 70],\n",
              " ['pink', 'bumper', 80],\n",
              " ['no color', 'rest of car', 90],\n",
              " ['white', 'background', 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRRyuIwmwocC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Conv2D, Input, MaxPooling2D, concatenate, Dropout,\\\n",
        "                                    Lambda, Conv2DTranspose, Add\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "\n",
        "imshape = (256, 256, 3)\n",
        "n_classes = len(data)\n",
        "\n",
        "\n",
        "def preprocess_input(x):\n",
        "    x /= 255.\n",
        "    x -= 0.5\n",
        "    x *= 2.\n",
        "    return x\n",
        "\n",
        "\n",
        "def dice(y_true, y_pred, smooth=1.):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "def unet(pretrained=False, base=4):\n",
        "\n",
        "    if pretrained:\n",
        "        path = os.path.join('models', model_name+'.model')\n",
        "        if os.path.exists(path):\n",
        "            model = load_model(path, custom_objects={'dice': dice})\n",
        "            model.summary()\n",
        "            return model\n",
        "        else:\n",
        "            print('Failed to load existing model at: {}'.format(path))\n",
        "\n",
        "    if n_classes == 1:\n",
        "        loss = 'binary_crossentropy'\n",
        "        final_act = 'sigmoid'\n",
        "    elif n_classes > 1:\n",
        "        loss = 'categorical_crossentropy'\n",
        "        final_act = 'softmax'\n",
        "\n",
        "    b = base\n",
        "    i = Input((imshape[0], imshape[1], imshape[2]))\n",
        "    s = Lambda(lambda x: preprocess_input(x)) (i)\n",
        "\n",
        "    c1 = Conv2D(2**b, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
        "    c1 = Dropout(0.1) (c1)\n",
        "    c1 = Conv2D(2**b, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "    c2 = Conv2D(2**(b+1), (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
        "    c2 = Dropout(0.1) (c2)\n",
        "    c2 = Conv2D(2**(b+1), (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "    c3 = Conv2D(2**(b+2), (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
        "    c3 = Dropout(0.2) (c3)\n",
        "    c3 = Conv2D(2**(b+2), (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "    c4 = Conv2D(2**(b+3), (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
        "    c4 = Dropout(0.2) (c4)\n",
        "    c4 = Conv2D(2**(b+3), (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "    c5 = Conv2D(2**(b+4), (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
        "    c5 = Dropout(0.3) (c5)\n",
        "    c5 = Conv2D(2**(b+4), (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "\n",
        "    u6 = Conv2DTranspose(2**(b+3), (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(2**(b+3), (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
        "    c6 = Dropout(0.2) (c6)\n",
        "    c6 = Conv2D(2**(b+3), (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(2**(b+2), (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(2**(b+2), (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
        "    c7 = Dropout(0.2) (c7)\n",
        "    c7 = Conv2D(2**(b+2), (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(2**(b+1), (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(2**(b+1), (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
        "    c8 = Dropout(0.1) (c8)\n",
        "    c8 = Conv2D(2**(b+1), (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(2**b, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(2**b, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
        "    c9 = Dropout(0.1) (c9)\n",
        "    c9 = Conv2D(2**b, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
        "\n",
        "    o = Conv2D(n_classes, (1, 1), activation=final_act) (c9)\n",
        "\n",
        "    model = Model(inputs=i, outputs=o)\n",
        "    model.compile(optimizer=Adam(1e-4),\n",
        "                  loss=loss,\n",
        "                  metrics=[dice])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkWNCE4zwtJf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "import cv2\n",
        "import json\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "ia.seed(1)\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.Multiply((1.2, 1.5)),\n",
        "    iaa.Affine(\n",
        "        #scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "        rotate=(-90, 90)\n",
        "    ),\n",
        "    iaa.Sometimes(0.5,\n",
        "        iaa.GaussianBlur(sigma=(0, 8))\n",
        "    )\n",
        "], random_order=True)\n",
        "\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    # Generates data for Keras\n",
        "    def __init__(self, paths, batch_size=32, shuffle=True, augment=False):\n",
        "        self.paths = paths\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augment\n",
        "        self.on_epoch_end()\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        # Denotes the number of batches per epoch\n",
        "        return int(np.floor(len(self.paths) / self.batch_size))\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        paths = [self.paths[k] for k in indexes]\n",
        "\n",
        "        X, y = self.__data_generation(paths)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Updates indexes after each epoch\n",
        "        self.indexes = np.arange(len(self.paths))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "\n",
        "    #TODO: This is where the data is generated I need to change this to the one I wrote above^\n",
        "    def __data_generation(self, paths):\n",
        "\n",
        "        X = np.empty((self.batch_size, imshape[0], imshape[1], imshape[2]), dtype=np.float32)\n",
        "        Y = np.empty((self.batch_size, imshape[0], imshape[1], n_classes),  dtype=np.float32)\n",
        "\n",
        "        for i, path in enumerate(paths):\n",
        "\n",
        "            array = np.load(path)\n",
        "\n",
        "            im = array[...,:3]\n",
        "\n",
        "            mask = np.zeros((imshape[0], imshape[1], n_classes))\n",
        "\n",
        "            classes = np.array([0,10,20,30,40,50,60,70,80,90])\n",
        "\n",
        "            for j, current_class in enumerate(classes):\n",
        "                a, b = np.where(array[...,-1]==current_class)\n",
        "                mask[a,b,np.repeat(j,a.size)] = 1\n",
        "\n",
        "            X[i,] = im\n",
        "            Y[i,] = mask\n",
        "\n",
        "        return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fql5qNbEwxBX",
        "outputId": "643baeaa-8d75-4076-df18-0b2cc84c4ec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda (Lambda)             (None, 256, 256, 3)          0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 256, 256, 16)         448       ['lambda[0][0]']              \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 256, 256, 16)         0         ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 16)         2320      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 128, 128, 16)         0         ['conv2d_1[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 32)         4640      ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 128, 128, 32)         0         ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 32)         9248      ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 32)           0         ['conv2d_3[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 64)           18496     ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 64, 64, 64)           0         ['conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 64)           36928     ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 64)           0         ['conv2d_5[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 32, 32, 128)          0         ['conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 128)          147584    ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_7[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 16, 16, 256)          0         ['conv2d_8[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 256)          590080    ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 32, 32, 128)          131200    ['conv2d_9[0][0]']            \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 32, 32, 256)          0         ['conv2d_transpose[0][0]',    \n",
            "                                                                     'conv2d_7[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 32, 32, 128)          295040    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 32, 32, 128)          0         ['conv2d_10[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 32, 32, 128)          147584    ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 64, 64, 64)           32832     ['conv2d_11[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 64, 64, 128)          0         ['conv2d_transpose_1[0][0]',  \n",
            " )                                                                   'conv2d_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 64, 64, 64)           73792     ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 64, 64, 64)           0         ['conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 64, 64, 64)           36928     ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2D  (None, 128, 128, 32)         8224      ['conv2d_13[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 128, 128, 64)         0         ['conv2d_transpose_2[0][0]',  \n",
            " )                                                                   'conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 128, 128, 32)         18464     ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 128, 128, 32)         0         ['conv2d_14[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 128, 128, 32)         9248      ['dropout_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2D  (None, 256, 256, 16)         2064      ['conv2d_15[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 256, 256, 32)         0         ['conv2d_transpose_3[0][0]',  \n",
            " )                                                                   'conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 256, 256, 16)         4624      ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 256, 256, 16)         0         ['conv2d_16[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 256, 256, 16)         2320      ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 256, 256, 10)         170       ['conv2d_17[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "#TODO: Make tensorflow work\n",
        "#TODO: make the data generator work,\n",
        "# Keras no longer in tensorflow? checkout how that works\n",
        "# from tensorboard_callbacks import TrainValTensorBoard, TensorBoardMask\n",
        "\n",
        "\n",
        "\n",
        "def sorted_fns(dir):\n",
        "    return sorted(os.listdir(dir), key=lambda x: int(x.split('.')[0][-4:]))\n",
        "\n",
        "paths = [os.path.join(directory_path, x) for x in sorted_fns(directory_path)]\n",
        "\n",
        "model = unet(pretrained=False, base=4)\n",
        "\n",
        "tg = DataGenerator(paths=paths, batch_size=5, augment=True)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(os.path.join('models', model_name+'.model'), monitor='dice', verbose=1, mode='max',\n",
        "#                              save_best_only=True, save_weights_only=False, period=10)\n",
        "#\n",
        "# train_val = TrainValTensorBoard(write_graph=True)\n",
        "# tb_mask = TensorBoardMask(log_freq=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4FJvs_cw_dt",
        "outputId": "b05a1f48-0c35-462c-b13c-f02d67222815"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-15-4981a8ed29ad>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator=tg,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "33/33 [==============================] - 22s 72ms/step - loss: 2.3179 - dice: 0.1439\n",
            "Epoch 2/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 1.6115 - dice: 0.2934\n",
            "Epoch 3/500\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 1.3478 - dice: 0.4228\n",
            "Epoch 4/500\n",
            "33/33 [==============================] - 2s 71ms/step - loss: 1.1638 - dice: 0.5080\n",
            "Epoch 5/500\n",
            "33/33 [==============================] - 2s 71ms/step - loss: 1.0974 - dice: 0.5487\n",
            "Epoch 6/500\n",
            "33/33 [==============================] - 2s 72ms/step - loss: 1.0701 - dice: 0.5583\n",
            "Epoch 7/500\n",
            "33/33 [==============================] - 2s 71ms/step - loss: 1.0197 - dice: 0.5748\n",
            "Epoch 8/500\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 0.9612 - dice: 0.5982\n",
            "Epoch 9/500\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.9564 - dice: 0.6006\n",
            "Epoch 10/500\n",
            "33/33 [==============================] - 3s 73ms/step - loss: 0.9536 - dice: 0.6019\n",
            "Epoch 11/500\n",
            "33/33 [==============================] - 3s 78ms/step - loss: 0.9252 - dice: 0.6109\n",
            "Epoch 12/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.8978 - dice: 0.6171\n",
            "Epoch 13/500\n",
            "33/33 [==============================] - 3s 98ms/step - loss: 0.8802 - dice: 0.6309\n",
            "Epoch 14/500\n",
            "33/33 [==============================] - 3s 73ms/step - loss: 0.8749 - dice: 0.6301\n",
            "Epoch 15/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.8752 - dice: 0.6298\n",
            "Epoch 16/500\n",
            "33/33 [==============================] - 2s 72ms/step - loss: 0.8638 - dice: 0.6314\n",
            "Epoch 17/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.8682 - dice: 0.6344\n",
            "Epoch 18/500\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 0.8459 - dice: 0.6407\n",
            "Epoch 19/500\n",
            "33/33 [==============================] - 3s 98ms/step - loss: 0.8309 - dice: 0.6506\n",
            "Epoch 20/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.8248 - dice: 0.6479\n",
            "Epoch 21/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.8110 - dice: 0.6574\n",
            "Epoch 22/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.8073 - dice: 0.6542\n",
            "Epoch 23/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.7999 - dice: 0.6615\n",
            "Epoch 24/500\n",
            "33/33 [==============================] - 3s 97ms/step - loss: 0.7837 - dice: 0.6679\n",
            "Epoch 25/500\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 0.7670 - dice: 0.6708\n",
            "Epoch 26/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.7798 - dice: 0.6718\n",
            "Epoch 27/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.7631 - dice: 0.6745\n",
            "Epoch 28/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.7484 - dice: 0.6791\n",
            "Epoch 29/500\n",
            "33/33 [==============================] - 3s 101ms/step - loss: 0.7421 - dice: 0.6857\n",
            "Epoch 30/500\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 0.7351 - dice: 0.6844\n",
            "Epoch 31/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.7235 - dice: 0.6894\n",
            "Epoch 32/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.7171 - dice: 0.6942\n",
            "Epoch 33/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.6998 - dice: 0.6992\n",
            "Epoch 34/500\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.6954 - dice: 0.7011\n",
            "Epoch 35/500\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.6982 - dice: 0.7008\n",
            "Epoch 36/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.6869 - dice: 0.7037\n",
            "Epoch 37/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.6771 - dice: 0.7067\n",
            "Epoch 38/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.6683 - dice: 0.7129\n",
            "Epoch 39/500\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 0.6622 - dice: 0.7122\n",
            "Epoch 40/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.6554 - dice: 0.7168\n",
            "Epoch 41/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.6528 - dice: 0.7187\n",
            "Epoch 42/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.6301 - dice: 0.7276\n",
            "Epoch 43/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.6246 - dice: 0.7283\n",
            "Epoch 44/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.6137 - dice: 0.7323\n",
            "Epoch 45/500\n",
            "33/33 [==============================] - 4s 123ms/step - loss: 0.6027 - dice: 0.7362\n",
            "Epoch 46/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.5953 - dice: 0.7398\n",
            "Epoch 47/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.5804 - dice: 0.7457\n",
            "Epoch 48/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.5738 - dice: 0.7494\n",
            "Epoch 49/500\n",
            "33/33 [==============================] - 3s 82ms/step - loss: 0.5730 - dice: 0.7474\n",
            "Epoch 50/500\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.5620 - dice: 0.7546\n",
            "Epoch 51/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.5463 - dice: 0.7583\n",
            "Epoch 52/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.5453 - dice: 0.7592\n",
            "Epoch 53/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.5371 - dice: 0.7617\n",
            "Epoch 54/500\n",
            "33/33 [==============================] - 3s 86ms/step - loss: 0.5169 - dice: 0.7684\n",
            "Epoch 55/500\n",
            "33/33 [==============================] - 3s 100ms/step - loss: 0.5203 - dice: 0.7721\n",
            "Epoch 56/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.5065 - dice: 0.7734\n",
            "Epoch 57/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.4958 - dice: 0.7756\n",
            "Epoch 58/500\n",
            "33/33 [==============================] - 3s 85ms/step - loss: 0.4999 - dice: 0.7791\n",
            "Epoch 59/500\n",
            "33/33 [==============================] - 3s 99ms/step - loss: 0.4992 - dice: 0.7769\n",
            "Epoch 60/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.4853 - dice: 0.7825\n",
            "Epoch 61/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.4713 - dice: 0.7859\n",
            "Epoch 62/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.4649 - dice: 0.7884\n",
            "Epoch 63/500\n",
            "33/33 [==============================] - 3s 82ms/step - loss: 0.4580 - dice: 0.7924\n",
            "Epoch 64/500\n",
            "33/33 [==============================] - 3s 100ms/step - loss: 0.4527 - dice: 0.7937\n",
            "Epoch 65/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.4460 - dice: 0.7978\n",
            "Epoch 66/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.4453 - dice: 0.7964\n",
            "Epoch 67/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.4406 - dice: 0.7973\n",
            "Epoch 68/500\n",
            "33/33 [==============================] - 3s 82ms/step - loss: 0.4376 - dice: 0.7998\n",
            "Epoch 69/500\n",
            "33/33 [==============================] - 3s 99ms/step - loss: 0.4239 - dice: 0.8039\n",
            "Epoch 70/500\n",
            "33/33 [==============================] - 3s 84ms/step - loss: 0.4220 - dice: 0.8044\n",
            "Epoch 71/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.4197 - dice: 0.8052\n",
            "Epoch 72/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.4531 - dice: 0.7952\n",
            "Epoch 73/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.4346 - dice: 0.8003\n",
            "Epoch 74/500\n",
            "33/33 [==============================] - 3s 84ms/step - loss: 0.4081 - dice: 0.8093\n",
            "Epoch 75/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.3918 - dice: 0.8151\n",
            "Epoch 76/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.3879 - dice: 0.8158\n",
            "Epoch 77/500\n",
            "33/33 [==============================] - 2s 72ms/step - loss: 0.3881 - dice: 0.8162\n",
            "Epoch 78/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.3840 - dice: 0.8200\n",
            "Epoch 79/500\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.3877 - dice: 0.8172\n",
            "Epoch 80/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.3757 - dice: 0.8205\n",
            "Epoch 81/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.3682 - dice: 0.8242\n",
            "Epoch 82/500\n",
            "33/33 [==============================] - 3s 84ms/step - loss: 0.3584 - dice: 0.8282\n",
            "Epoch 83/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.3600 - dice: 0.8273\n",
            "Epoch 84/500\n",
            "33/33 [==============================] - 3s 73ms/step - loss: 0.3560 - dice: 0.8289\n",
            "Epoch 85/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.3597 - dice: 0.8275\n",
            "Epoch 86/500\n",
            "33/33 [==============================] - 2s 72ms/step - loss: 0.3579 - dice: 0.8289\n",
            "Epoch 87/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.3486 - dice: 0.8317\n",
            "Epoch 88/500\n",
            "33/33 [==============================] - 3s 79ms/step - loss: 0.3476 - dice: 0.8329\n",
            "Epoch 89/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.3509 - dice: 0.8320\n",
            "Epoch 90/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.3421 - dice: 0.8322\n",
            "Epoch 91/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.3346 - dice: 0.8386\n",
            "Epoch 92/500\n",
            "33/33 [==============================] - 3s 84ms/step - loss: 0.3277 - dice: 0.8395\n",
            "Epoch 93/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.3226 - dice: 0.8421\n",
            "Epoch 94/500\n",
            "33/33 [==============================] - 3s 82ms/step - loss: 0.3192 - dice: 0.8434\n",
            "Epoch 95/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.3190 - dice: 0.8437\n",
            "Epoch 96/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.3135 - dice: 0.8468\n",
            "Epoch 97/500\n",
            "33/33 [==============================] - 2s 72ms/step - loss: 0.3066 - dice: 0.8483\n",
            "Epoch 98/500\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.2983 - dice: 0.8516\n",
            "Epoch 99/500\n",
            "33/33 [==============================] - 3s 101ms/step - loss: 0.2961 - dice: 0.8534\n",
            "Epoch 100/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.2978 - dice: 0.8530\n",
            "Epoch 101/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.2992 - dice: 0.8521\n",
            "Epoch 102/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.2928 - dice: 0.8550\n",
            "Epoch 103/500\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.2918 - dice: 0.8559\n",
            "Epoch 104/500\n",
            "33/33 [==============================] - 3s 78ms/step - loss: 0.2875 - dice: 0.8569\n",
            "Epoch 105/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.2814 - dice: 0.8596\n",
            "Epoch 106/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.2796 - dice: 0.8603\n",
            "Epoch 107/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.2726 - dice: 0.8632\n",
            "Epoch 108/500\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.2719 - dice: 0.8636\n",
            "Epoch 109/500\n",
            "33/33 [==============================] - 3s 80ms/step - loss: 0.2641 - dice: 0.8674\n",
            "Epoch 110/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.2609 - dice: 0.8683\n",
            "Epoch 111/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.2575 - dice: 0.8696\n",
            "Epoch 112/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.2554 - dice: 0.8709\n",
            "Epoch 113/500\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.2488 - dice: 0.8732\n",
            "Epoch 114/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.2498 - dice: 0.8736\n",
            "Epoch 115/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.2434 - dice: 0.8770\n",
            "Epoch 116/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.2407 - dice: 0.8779\n",
            "Epoch 117/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.2379 - dice: 0.8788\n",
            "Epoch 118/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.2326 - dice: 0.8809\n",
            "Epoch 119/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.2350 - dice: 0.8806\n",
            "Epoch 120/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.2361 - dice: 0.8803\n",
            "Epoch 121/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.2330 - dice: 0.8814\n",
            "Epoch 122/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.2297 - dice: 0.8829\n",
            "Epoch 123/500\n",
            "33/33 [==============================] - 3s 80ms/step - loss: 0.2250 - dice: 0.8852\n",
            "Epoch 124/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.2202 - dice: 0.8870\n",
            "Epoch 125/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.2197 - dice: 0.8870\n",
            "Epoch 126/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.2264 - dice: 0.8859\n",
            "Epoch 127/500\n",
            "33/33 [==============================] - 3s 81ms/step - loss: 0.2338 - dice: 0.8835\n",
            "Epoch 128/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.2244 - dice: 0.8859\n",
            "Epoch 129/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.2139 - dice: 0.8898\n",
            "Epoch 130/500\n",
            "33/33 [==============================] - 2s 72ms/step - loss: 0.2095 - dice: 0.8922\n",
            "Epoch 131/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.2063 - dice: 0.8941\n",
            "Epoch 132/500\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.2007 - dice: 0.8961\n",
            "Epoch 133/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1979 - dice: 0.8980\n",
            "Epoch 134/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1992 - dice: 0.8971\n",
            "Epoch 135/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1956 - dice: 0.8987\n",
            "Epoch 136/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1964 - dice: 0.8988\n",
            "Epoch 137/500\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.1934 - dice: 0.9000\n",
            "Epoch 138/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1943 - dice: 0.9004\n",
            "Epoch 139/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1880 - dice: 0.9024\n",
            "Epoch 140/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.1858 - dice: 0.9035\n",
            "Epoch 141/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.1876 - dice: 0.9029\n",
            "Epoch 142/500\n",
            "33/33 [==============================] - 3s 81ms/step - loss: 0.1889 - dice: 0.9029\n",
            "Epoch 143/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1856 - dice: 0.9039\n",
            "Epoch 144/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1869 - dice: 0.9036\n",
            "Epoch 145/500\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.1854 - dice: 0.9046\n",
            "Epoch 146/500\n",
            "33/33 [==============================] - 3s 98ms/step - loss: 0.1820 - dice: 0.9049\n",
            "Epoch 147/500\n",
            "33/33 [==============================] - 3s 80ms/step - loss: 0.1808 - dice: 0.9062\n",
            "Epoch 148/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1783 - dice: 0.9075\n",
            "Epoch 149/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1817 - dice: 0.9063\n",
            "Epoch 150/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.1825 - dice: 0.9060\n",
            "Epoch 151/500\n",
            "33/33 [==============================] - 3s 86ms/step - loss: 0.1795 - dice: 0.9063\n",
            "Epoch 152/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.1749 - dice: 0.9089\n",
            "Epoch 153/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1712 - dice: 0.9105\n",
            "Epoch 154/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1706 - dice: 0.9107\n",
            "Epoch 155/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.1702 - dice: 0.9116\n",
            "Epoch 156/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1701 - dice: 0.9109\n",
            "Epoch 157/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.1672 - dice: 0.9124\n",
            "Epoch 158/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1694 - dice: 0.9119\n",
            "Epoch 159/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.1677 - dice: 0.9119\n",
            "Epoch 160/500\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 0.1659 - dice: 0.9134\n",
            "Epoch 161/500\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.1618 - dice: 0.9150\n",
            "Epoch 162/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1612 - dice: 0.9154\n",
            "Epoch 163/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1592 - dice: 0.9162\n",
            "Epoch 164/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.1603 - dice: 0.9157\n",
            "Epoch 165/500\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.1634 - dice: 0.9150\n",
            "Epoch 166/500\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 0.1591 - dice: 0.9163\n",
            "Epoch 167/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1576 - dice: 0.9172\n",
            "Epoch 168/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1601 - dice: 0.9161\n",
            "Epoch 169/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.1586 - dice: 0.9169\n",
            "Epoch 170/500\n",
            "33/33 [==============================] - 3s 84ms/step - loss: 0.1598 - dice: 0.9166\n",
            "Epoch 171/500\n",
            "33/33 [==============================] - 3s 98ms/step - loss: 0.1569 - dice: 0.9175\n",
            "Epoch 172/500\n",
            "33/33 [==============================] - 3s 78ms/step - loss: 0.1555 - dice: 0.9186\n",
            "Epoch 173/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1543 - dice: 0.9187\n",
            "Epoch 174/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.1539 - dice: 0.9187\n",
            "Epoch 175/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1529 - dice: 0.9195\n",
            "Epoch 176/500\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.1498 - dice: 0.9204\n",
            "Epoch 177/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.1472 - dice: 0.9217\n",
            "Epoch 178/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.1483 - dice: 0.9219\n",
            "Epoch 179/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1501 - dice: 0.9208\n",
            "Epoch 180/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1538 - dice: 0.9198\n",
            "Epoch 181/500\n",
            "33/33 [==============================] - 3s 97ms/step - loss: 0.1696 - dice: 0.9136\n",
            "Epoch 182/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.1591 - dice: 0.9167\n",
            "Epoch 183/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.1510 - dice: 0.9205\n",
            "Epoch 184/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1469 - dice: 0.9218\n",
            "Epoch 185/500\n",
            "33/33 [==============================] - 3s 90ms/step - loss: 0.1451 - dice: 0.9227\n",
            "Epoch 186/500\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.1453 - dice: 0.9228\n",
            "Epoch 187/500\n",
            "33/33 [==============================] - 3s 80ms/step - loss: 0.1434 - dice: 0.9237\n",
            "Epoch 188/500\n",
            "33/33 [==============================] - 3s 73ms/step - loss: 0.1444 - dice: 0.9237\n",
            "Epoch 189/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1434 - dice: 0.9238\n",
            "Epoch 190/500\n",
            "33/33 [==============================] - 3s 86ms/step - loss: 0.1417 - dice: 0.9248\n",
            "Epoch 191/500\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 0.1419 - dice: 0.9246\n",
            "Epoch 192/500\n",
            "33/33 [==============================] - 3s 82ms/step - loss: 0.1390 - dice: 0.9256\n",
            "Epoch 193/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1416 - dice: 0.9250\n",
            "Epoch 194/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.1385 - dice: 0.9260\n",
            "Epoch 195/500\n",
            "33/33 [==============================] - 3s 80ms/step - loss: 0.1382 - dice: 0.9265\n",
            "Epoch 196/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1397 - dice: 0.9261\n",
            "Epoch 197/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.1391 - dice: 0.9261\n",
            "Epoch 198/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1404 - dice: 0.9256\n",
            "Epoch 199/500\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 0.1371 - dice: 0.9264\n",
            "Epoch 200/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.1365 - dice: 0.9275\n",
            "Epoch 201/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.1359 - dice: 0.9274\n",
            "Epoch 202/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.1362 - dice: 0.9274\n",
            "Epoch 203/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1341 - dice: 0.9281\n",
            "Epoch 204/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1334 - dice: 0.9288\n",
            "Epoch 205/500\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.1328 - dice: 0.9291\n",
            "Epoch 206/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1325 - dice: 0.9294\n",
            "Epoch 207/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1331 - dice: 0.9287\n",
            "Epoch 208/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.1315 - dice: 0.9297\n",
            "Epoch 209/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1302 - dice: 0.9300\n",
            "Epoch 210/500\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.1292 - dice: 0.9309\n",
            "Epoch 211/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.1272 - dice: 0.9314\n",
            "Epoch 212/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1318 - dice: 0.9302\n",
            "Epoch 213/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1316 - dice: 0.9300\n",
            "Epoch 214/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1305 - dice: 0.9296\n",
            "Epoch 215/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.1271 - dice: 0.9318\n",
            "Epoch 216/500\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.1285 - dice: 0.9314\n",
            "Epoch 217/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1302 - dice: 0.9304\n",
            "Epoch 218/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1306 - dice: 0.9304\n",
            "Epoch 219/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1267 - dice: 0.9317\n",
            "Epoch 220/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1255 - dice: 0.9327\n",
            "Epoch 221/500\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 0.1249 - dice: 0.9326\n",
            "Epoch 222/500\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 0.1265 - dice: 0.9323\n",
            "Epoch 223/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.1244 - dice: 0.9333\n",
            "Epoch 224/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1242 - dice: 0.9330\n",
            "Epoch 225/500\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1233 - dice: 0.9337\n",
            "Epoch 226/500\n",
            "33/33 [==============================] - 3s 97ms/step - loss: 0.1251 - dice: 0.9328\n",
            "Epoch 227/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1226 - dice: 0.9340\n",
            "Epoch 228/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1238 - dice: 0.9335\n",
            "Epoch 229/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1222 - dice: 0.9343\n",
            "Epoch 230/500\n",
            "33/33 [==============================] - 3s 85ms/step - loss: 0.1234 - dice: 0.9338\n",
            "Epoch 231/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.1219 - dice: 0.9343\n",
            "Epoch 232/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.1220 - dice: 0.9341\n",
            "Epoch 233/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.1194 - dice: 0.9356\n",
            "Epoch 234/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1195 - dice: 0.9352\n",
            "Epoch 235/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.1188 - dice: 0.9358\n",
            "Epoch 236/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1188 - dice: 0.9359\n",
            "Epoch 237/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.1186 - dice: 0.9359\n",
            "Epoch 238/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1200 - dice: 0.9353\n",
            "Epoch 239/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1184 - dice: 0.9360\n",
            "Epoch 240/500\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.1172 - dice: 0.9366\n",
            "Epoch 241/500\n",
            "33/33 [==============================] - 3s 97ms/step - loss: 0.1159 - dice: 0.9373\n",
            "Epoch 242/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1177 - dice: 0.9364\n",
            "Epoch 243/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1197 - dice: 0.9354\n",
            "Epoch 244/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1180 - dice: 0.9366\n",
            "Epoch 245/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1162 - dice: 0.9368\n",
            "Epoch 246/500\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 0.1153 - dice: 0.9376\n",
            "Epoch 247/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1142 - dice: 0.9381\n",
            "Epoch 248/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1144 - dice: 0.9379\n",
            "Epoch 249/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1159 - dice: 0.9373\n",
            "Epoch 250/500\n",
            "33/33 [==============================] - 3s 97ms/step - loss: 0.1173 - dice: 0.9367\n",
            "Epoch 251/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1139 - dice: 0.9380\n",
            "Epoch 252/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1132 - dice: 0.9384\n",
            "Epoch 253/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1151 - dice: 0.9379\n",
            "Epoch 254/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.1129 - dice: 0.9390\n",
            "Epoch 255/500\n",
            "33/33 [==============================] - 3s 80ms/step - loss: 0.1145 - dice: 0.9381\n",
            "Epoch 256/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1146 - dice: 0.9381\n",
            "Epoch 257/500\n",
            "33/33 [==============================] - 2s 72ms/step - loss: 0.1123 - dice: 0.9388\n",
            "Epoch 258/500\n",
            "33/33 [==============================] - 3s 84ms/step - loss: 0.1129 - dice: 0.9389\n",
            "Epoch 259/500\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.1112 - dice: 0.9395\n",
            "Epoch 260/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1105 - dice: 0.9399\n",
            "Epoch 261/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1086 - dice: 0.9405\n",
            "Epoch 262/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1098 - dice: 0.9405\n",
            "Epoch 263/500\n",
            "33/33 [==============================] - 3s 83ms/step - loss: 0.1104 - dice: 0.9400\n",
            "Epoch 264/500\n",
            "33/33 [==============================] - 3s 77ms/step - loss: 0.1091 - dice: 0.9404\n",
            "Epoch 265/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1094 - dice: 0.9404\n",
            "Epoch 266/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.1093 - dice: 0.9404\n",
            "Epoch 267/500\n",
            "33/33 [==============================] - 3s 90ms/step - loss: 0.1087 - dice: 0.9409\n",
            "Epoch 268/500\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 0.1093 - dice: 0.9406\n",
            "Epoch 269/500\n",
            "33/33 [==============================] - 3s 78ms/step - loss: 0.1089 - dice: 0.9406\n",
            "Epoch 270/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1072 - dice: 0.9413\n",
            "Epoch 271/500\n",
            "33/33 [==============================] - 2s 72ms/step - loss: 0.1070 - dice: 0.9418\n",
            "Epoch 272/500\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.1134 - dice: 0.9404\n",
            "Epoch 273/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1818 - dice: 0.9168\n",
            "Epoch 274/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1811 - dice: 0.9129\n",
            "Epoch 275/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.2004 - dice: 0.9032\n",
            "Epoch 276/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1372 - dice: 0.9250\n",
            "Epoch 277/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.1155 - dice: 0.9357\n",
            "Epoch 278/500\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 0.1115 - dice: 0.9382\n",
            "Epoch 279/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1079 - dice: 0.9401\n",
            "Epoch 280/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.1071 - dice: 0.9411\n",
            "Epoch 281/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1052 - dice: 0.9417\n",
            "Epoch 282/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1054 - dice: 0.9422\n",
            "Epoch 283/500\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.1047 - dice: 0.9424\n",
            "Epoch 284/500\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 0.1025 - dice: 0.9432\n",
            "Epoch 285/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1021 - dice: 0.9437\n",
            "Epoch 286/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1013 - dice: 0.9440\n",
            "Epoch 287/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1020 - dice: 0.9438\n",
            "Epoch 288/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1013 - dice: 0.9442\n",
            "Epoch 289/500\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.1009 - dice: 0.9445\n",
            "Epoch 290/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1017 - dice: 0.9440\n",
            "Epoch 291/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1007 - dice: 0.9446\n",
            "Epoch 292/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.1014 - dice: 0.9444\n",
            "Epoch 293/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.1007 - dice: 0.9449\n",
            "Epoch 294/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.1008 - dice: 0.9444\n",
            "Epoch 295/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.1011 - dice: 0.9443\n",
            "Epoch 296/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.1002 - dice: 0.9449\n",
            "Epoch 297/500\n",
            "33/33 [==============================] - 3s 84ms/step - loss: 0.1002 - dice: 0.9449\n",
            "Epoch 298/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.1010 - dice: 0.9447\n",
            "Epoch 299/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.0998 - dice: 0.9451\n",
            "Epoch 300/500\n",
            "33/33 [==============================] - 3s 77ms/step - loss: 0.0999 - dice: 0.9449\n",
            "Epoch 301/500\n",
            "33/33 [==============================] - 3s 100ms/step - loss: 0.0992 - dice: 0.9454\n",
            "Epoch 302/500\n",
            "33/33 [==============================] - 3s 81ms/step - loss: 0.0982 - dice: 0.9459\n",
            "Epoch 303/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0979 - dice: 0.9460\n",
            "Epoch 304/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0979 - dice: 0.9461\n",
            "Epoch 305/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.0974 - dice: 0.9463\n",
            "Epoch 306/500\n",
            "33/33 [==============================] - 3s 85ms/step - loss: 0.0975 - dice: 0.9463\n",
            "Epoch 307/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.0978 - dice: 0.9463\n",
            "Epoch 308/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0975 - dice: 0.9461\n",
            "Epoch 309/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.0975 - dice: 0.9464\n",
            "Epoch 310/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.0972 - dice: 0.9463\n",
            "Epoch 311/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0973 - dice: 0.9464\n",
            "Epoch 312/500\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0957 - dice: 0.9470\n",
            "Epoch 313/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0971 - dice: 0.9467\n",
            "Epoch 314/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.0962 - dice: 0.9467\n",
            "Epoch 315/500\n",
            "33/33 [==============================] - 3s 84ms/step - loss: 0.0960 - dice: 0.9470\n",
            "Epoch 316/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.0957 - dice: 0.9473\n",
            "Epoch 317/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0973 - dice: 0.9465\n",
            "Epoch 318/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0965 - dice: 0.9468\n",
            "Epoch 319/500\n",
            "33/33 [==============================] - 3s 79ms/step - loss: 0.0951 - dice: 0.9474\n",
            "Epoch 320/500\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 0.0961 - dice: 0.9471\n",
            "Epoch 321/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.0947 - dice: 0.9475\n",
            "Epoch 322/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.0958 - dice: 0.9476\n",
            "Epoch 323/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0939 - dice: 0.9479\n",
            "Epoch 324/500\n",
            "33/33 [==============================] - 3s 84ms/step - loss: 0.0972 - dice: 0.9471\n",
            "Epoch 325/500\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.1005 - dice: 0.9449\n",
            "Epoch 326/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0959 - dice: 0.9471\n",
            "Epoch 327/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0949 - dice: 0.9474\n",
            "Epoch 328/500\n",
            "33/33 [==============================] - 3s 80ms/step - loss: 0.0935 - dice: 0.9483\n",
            "Epoch 329/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.0941 - dice: 0.9480\n",
            "Epoch 330/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0946 - dice: 0.9477\n",
            "Epoch 331/500\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0937 - dice: 0.9483\n",
            "Epoch 332/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0945 - dice: 0.9478\n",
            "Epoch 333/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.0936 - dice: 0.9484\n",
            "Epoch 334/500\n",
            "33/33 [==============================] - 3s 78ms/step - loss: 0.0934 - dice: 0.9484\n",
            "Epoch 335/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.0936 - dice: 0.9481\n",
            "Epoch 336/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.0940 - dice: 0.9480\n",
            "Epoch 337/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0935 - dice: 0.9482\n",
            "Epoch 338/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0931 - dice: 0.9485\n",
            "Epoch 339/500\n",
            "33/33 [==============================] - 3s 77ms/step - loss: 0.0924 - dice: 0.9490\n",
            "Epoch 340/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0919 - dice: 0.9490\n",
            "Epoch 341/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0920 - dice: 0.9489\n",
            "Epoch 342/500\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 0.0917 - dice: 0.9492\n",
            "Epoch 343/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0921 - dice: 0.9491\n",
            "Epoch 344/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.0911 - dice: 0.9496\n",
            "Epoch 345/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0906 - dice: 0.9495\n",
            "Epoch 346/500\n",
            "33/33 [==============================] - 3s 82ms/step - loss: 0.0920 - dice: 0.9494\n",
            "Epoch 347/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0914 - dice: 0.9494\n",
            "Epoch 348/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.0914 - dice: 0.9493\n",
            "Epoch 349/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.0908 - dice: 0.9498\n",
            "Epoch 350/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0910 - dice: 0.9494\n",
            "Epoch 351/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.0909 - dice: 0.9497\n",
            "Epoch 352/500\n",
            "33/33 [==============================] - 3s 85ms/step - loss: 0.0905 - dice: 0.9498\n",
            "Epoch 353/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0897 - dice: 0.9501\n",
            "Epoch 354/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0901 - dice: 0.9500\n",
            "Epoch 355/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0898 - dice: 0.9502\n",
            "Epoch 356/500\n",
            "33/33 [==============================] - 3s 90ms/step - loss: 0.0902 - dice: 0.9500\n",
            "Epoch 357/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.0902 - dice: 0.9502\n",
            "Epoch 358/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0893 - dice: 0.9503\n",
            "Epoch 359/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0895 - dice: 0.9503\n",
            "Epoch 360/500\n",
            "33/33 [==============================] - 3s 77ms/step - loss: 0.0892 - dice: 0.9508\n",
            "Epoch 361/500\n",
            "33/33 [==============================] - 3s 97ms/step - loss: 0.0943 - dice: 0.9483\n",
            "Epoch 362/500\n",
            "33/33 [==============================] - 3s 80ms/step - loss: 0.0910 - dice: 0.9495\n",
            "Epoch 363/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0894 - dice: 0.9502\n",
            "Epoch 364/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0891 - dice: 0.9505\n",
            "Epoch 365/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.0877 - dice: 0.9511\n",
            "Epoch 366/500\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0870 - dice: 0.9514\n",
            "Epoch 367/500\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0880 - dice: 0.9510\n",
            "Epoch 368/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0876 - dice: 0.9512\n",
            "Epoch 369/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0887 - dice: 0.9509\n",
            "Epoch 370/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0869 - dice: 0.9515\n",
            "Epoch 371/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0875 - dice: 0.9515\n",
            "Epoch 372/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0872 - dice: 0.9513\n",
            "Epoch 373/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0867 - dice: 0.9519\n",
            "Epoch 374/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0878 - dice: 0.9514\n",
            "Epoch 375/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0871 - dice: 0.9514\n",
            "Epoch 376/500\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0861 - dice: 0.9520\n",
            "Epoch 377/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0861 - dice: 0.9520\n",
            "Epoch 378/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0860 - dice: 0.9521\n",
            "Epoch 379/500\n",
            "33/33 [==============================] - 3s 90ms/step - loss: 0.0847 - dice: 0.9526\n",
            "Epoch 380/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0853 - dice: 0.9526\n",
            "Epoch 381/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.0863 - dice: 0.9520\n",
            "Epoch 382/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0860 - dice: 0.9520\n",
            "Epoch 383/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0863 - dice: 0.9519\n",
            "Epoch 384/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0846 - dice: 0.9526\n",
            "Epoch 385/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0849 - dice: 0.9526\n",
            "Epoch 386/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0855 - dice: 0.9525\n",
            "Epoch 387/500\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 0.0843 - dice: 0.9528\n",
            "Epoch 388/500\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0832 - dice: 0.9536\n",
            "Epoch 389/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0834 - dice: 0.9533\n",
            "Epoch 390/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0843 - dice: 0.9530\n",
            "Epoch 391/500\n",
            "33/33 [==============================] - 3s 81ms/step - loss: 0.0840 - dice: 0.9531\n",
            "Epoch 392/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0833 - dice: 0.9535\n",
            "Epoch 393/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0834 - dice: 0.9532\n",
            "Epoch 394/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0840 - dice: 0.9533\n",
            "Epoch 395/500\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.0834 - dice: 0.9533\n",
            "Epoch 396/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0826 - dice: 0.9536\n",
            "Epoch 397/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0833 - dice: 0.9534\n",
            "Epoch 398/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0835 - dice: 0.9534\n",
            "Epoch 399/500\n",
            "33/33 [==============================] - 3s 85ms/step - loss: 0.0830 - dice: 0.9535\n",
            "Epoch 400/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.0822 - dice: 0.9539\n",
            "Epoch 401/500\n",
            "33/33 [==============================] - 3s 79ms/step - loss: 0.0829 - dice: 0.9536\n",
            "Epoch 402/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.0834 - dice: 0.9534\n",
            "Epoch 403/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0832 - dice: 0.9536\n",
            "Epoch 404/500\n",
            "33/33 [==============================] - 3s 90ms/step - loss: 0.0824 - dice: 0.9538\n",
            "Epoch 405/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0820 - dice: 0.9542\n",
            "Epoch 406/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0829 - dice: 0.9537\n",
            "Epoch 407/500\n",
            "33/33 [==============================] - 3s 82ms/step - loss: 0.0821 - dice: 0.9541\n",
            "Epoch 408/500\n",
            "33/33 [==============================] - 3s 98ms/step - loss: 0.0804 - dice: 0.9548\n",
            "Epoch 409/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0815 - dice: 0.9544\n",
            "Epoch 410/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.0826 - dice: 0.9538\n",
            "Epoch 411/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.0813 - dice: 0.9543\n",
            "Epoch 412/500\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0807 - dice: 0.9547\n",
            "Epoch 413/500\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 0.0800 - dice: 0.9548\n",
            "Epoch 414/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0804 - dice: 0.9548\n",
            "Epoch 415/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0809 - dice: 0.9547\n",
            "Epoch 416/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0804 - dice: 0.9548\n",
            "Epoch 417/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0794 - dice: 0.9555\n",
            "Epoch 418/500\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.0813 - dice: 0.9547\n",
            "Epoch 419/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0795 - dice: 0.9551\n",
            "Epoch 420/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0805 - dice: 0.9548\n",
            "Epoch 421/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0807 - dice: 0.9548\n",
            "Epoch 422/500\n",
            "33/33 [==============================] - 3s 84ms/step - loss: 0.0797 - dice: 0.9552\n",
            "Epoch 423/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0800 - dice: 0.9552\n",
            "Epoch 424/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0800 - dice: 0.9550\n",
            "Epoch 425/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0793 - dice: 0.9555\n",
            "Epoch 426/500\n",
            "33/33 [==============================] - 3s 77ms/step - loss: 0.0786 - dice: 0.9557\n",
            "Epoch 427/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0796 - dice: 0.9555\n",
            "Epoch 428/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0787 - dice: 0.9556\n",
            "Epoch 429/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0779 - dice: 0.9560\n",
            "Epoch 430/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0780 - dice: 0.9560\n",
            "Epoch 431/500\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.0793 - dice: 0.9557\n",
            "Epoch 432/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0794 - dice: 0.9554\n",
            "Epoch 433/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0780 - dice: 0.9562\n",
            "Epoch 434/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0790 - dice: 0.9558\n",
            "Epoch 435/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.0790 - dice: 0.9555\n",
            "Epoch 436/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0778 - dice: 0.9560\n",
            "Epoch 437/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0770 - dice: 0.9568\n",
            "Epoch 438/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.2247 - dice: 0.9110\n",
            "Epoch 439/500\n",
            "33/33 [==============================] - 3s 79ms/step - loss: 0.1749 - dice: 0.9141\n",
            "Epoch 440/500\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.1242 - dice: 0.9334\n",
            "Epoch 441/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.1016 - dice: 0.9423\n",
            "Epoch 442/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0872 - dice: 0.9499\n",
            "Epoch 443/500\n",
            "33/33 [==============================] - 3s 85ms/step - loss: 0.0833 - dice: 0.9522\n",
            "Epoch 444/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0806 - dice: 0.9539\n",
            "Epoch 445/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0799 - dice: 0.9545\n",
            "Epoch 446/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0784 - dice: 0.9552\n",
            "Epoch 447/500\n",
            "33/33 [==============================] - 3s 80ms/step - loss: 0.0774 - dice: 0.9558\n",
            "Epoch 448/500\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.0777 - dice: 0.9559\n",
            "Epoch 449/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0779 - dice: 0.9559\n",
            "Epoch 450/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0762 - dice: 0.9566\n",
            "Epoch 451/500\n",
            "33/33 [==============================] - 3s 90ms/step - loss: 0.0765 - dice: 0.9565\n",
            "Epoch 452/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0758 - dice: 0.9570\n",
            "Epoch 453/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.0759 - dice: 0.9569\n",
            "Epoch 454/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0755 - dice: 0.9572\n",
            "Epoch 455/500\n",
            "33/33 [==============================] - 3s 80ms/step - loss: 0.0766 - dice: 0.9565\n",
            "Epoch 456/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0758 - dice: 0.9572\n",
            "Epoch 457/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0749 - dice: 0.9575\n",
            "Epoch 458/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0744 - dice: 0.9577\n",
            "Epoch 459/500\n",
            "33/33 [==============================] - 3s 77ms/step - loss: 0.0743 - dice: 0.9580\n",
            "Epoch 460/500\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 0.0742 - dice: 0.9578\n",
            "Epoch 461/500\n",
            "33/33 [==============================] - 3s 83ms/step - loss: 0.0741 - dice: 0.9580\n",
            "Epoch 462/500\n",
            "33/33 [==============================] - 2s 73ms/step - loss: 0.0740 - dice: 0.9580\n",
            "Epoch 463/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0733 - dice: 0.9584\n",
            "Epoch 464/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0737 - dice: 0.9582\n",
            "Epoch 465/500\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0742 - dice: 0.9582\n",
            "Epoch 466/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0735 - dice: 0.9583\n",
            "Epoch 467/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0732 - dice: 0.9585\n",
            "Epoch 468/500\n",
            "33/33 [==============================] - 3s 81ms/step - loss: 0.0737 - dice: 0.9582\n",
            "Epoch 469/500\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.0734 - dice: 0.9584\n",
            "Epoch 470/500\n",
            "33/33 [==============================] - 3s 81ms/step - loss: 0.0735 - dice: 0.9584\n",
            "Epoch 471/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0732 - dice: 0.9585\n",
            "Epoch 472/500\n",
            "33/33 [==============================] - 3s 74ms/step - loss: 0.0732 - dice: 0.9584\n",
            "Epoch 473/500\n",
            "33/33 [==============================] - 3s 86ms/step - loss: 0.0729 - dice: 0.9586\n",
            "Epoch 474/500\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.0727 - dice: 0.9588\n",
            "Epoch 475/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0734 - dice: 0.9585\n",
            "Epoch 476/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0739 - dice: 0.9583\n",
            "Epoch 477/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0721 - dice: 0.9591\n",
            "Epoch 478/500\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0729 - dice: 0.9587\n",
            "Epoch 479/500\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.0717 - dice: 0.9592\n",
            "Epoch 480/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0722 - dice: 0.9591\n",
            "Epoch 481/500\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0727 - dice: 0.9590\n",
            "Epoch 482/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0722 - dice: 0.9589\n",
            "Epoch 483/500\n",
            "33/33 [==============================] - 3s 94ms/step - loss: 0.0723 - dice: 0.9591\n",
            "Epoch 484/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0721 - dice: 0.9591\n",
            "Epoch 485/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0724 - dice: 0.9589\n",
            "Epoch 486/500\n",
            "33/33 [==============================] - 3s 84ms/step - loss: 0.0720 - dice: 0.9591\n",
            "Epoch 487/500\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.0715 - dice: 0.9595\n",
            "Epoch 488/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0715 - dice: 0.9592\n",
            "Epoch 489/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0715 - dice: 0.9595\n",
            "Epoch 490/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0721 - dice: 0.9591\n",
            "Epoch 491/500\n",
            "33/33 [==============================] - 3s 84ms/step - loss: 0.0717 - dice: 0.9593\n",
            "Epoch 492/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0713 - dice: 0.9594\n",
            "Epoch 493/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0721 - dice: 0.9593\n",
            "Epoch 494/500\n",
            "33/33 [==============================] - 3s 83ms/step - loss: 0.0721 - dice: 0.9590\n",
            "Epoch 495/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0719 - dice: 0.9591\n",
            "Epoch 496/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0717 - dice: 0.9595\n",
            "Epoch 497/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0712 - dice: 0.9595\n",
            "Epoch 498/500\n",
            "33/33 [==============================] - 3s 77ms/step - loss: 0.0713 - dice: 0.9596\n",
            "Epoch 499/500\n",
            "33/33 [==============================] - 3s 76ms/step - loss: 0.0712 - dice: 0.9596\n",
            "Epoch 500/500\n",
            "33/33 [==============================] - 3s 75ms/step - loss: 0.0714 - dice: 0.9595\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7be957627160>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model.fit_generator(generator=tg,\n",
        "                    steps_per_epoch=len(tg),\n",
        "                    epochs=500, verbose=1,\n",
        "                    # callbacks=[checkpoint, train_val, tb_mask]\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVhvOoGCxDJQ"
      },
      "outputs": [],
      "source": [
        "savemodelto = \"drive/My Drive/carseg_data/\"\n",
        "model.save(savemodelto+'model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKHBe2GhyCwT",
        "outputId": "1df1ddb5-d7e3-4be0-a1f4-c6a5dd1313a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPqnx8TYyE36"
      },
      "outputs": [],
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.save_weights(\"model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ils_ANEsyHwU",
        "outputId": "1ecd335c-57c1-4bc0-fd36-d3a26237e206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved.\n"
          ]
        }
      ],
      "source": [
        "print(\"Model saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqciazf6LE9T"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy\n",
        "\n",
        "def binary_crossentropy_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred)\n",
        "\n",
        "def categorical_cross_entropy_loss(y_true, y_pred):\n",
        "    return categorical_crossentropy(y_true, y_pred)\n",
        "\n",
        "def DiceLoss(targets, inputs, smooth=1e-6):\n",
        "    inputs = K.flatten(inputs)\n",
        "    targets = K.flatten(targets)\n",
        "    intersection = K.sum(targets * inputs)\n",
        "    return 1-(2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
        "\n",
        "def DiceBCELoss(targets, inputs, smooth=1e-6):\n",
        "\n",
        "    # Calculate BCE loss\n",
        "    BCE = binary_crossentropy_loss(targets, inputs)\n",
        "\n",
        "    # Calculate intersection and dice loss\n",
        "    dice_loss = DiceLoss(targets, inputs)\n",
        "\n",
        "    # Combine BCE and dice loss\n",
        "    Dice_BCE = BCE + dice_loss\n",
        "\n",
        "    return Dice_BCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huP8dklu7_Qk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7c456d4-67d8-4540-b50f-9cbaf8c1d86d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training model with parameters: {'batch_size': 8, 'learning_rate': 0.001, 'loss': <function DiceLoss at 0x7bcc24dc2680>, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>}\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)           (None, 256, 256, 3)          0         ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 256, 256, 16)         448       ['lambda_1[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)         (None, 256, 256, 16)         0         ['conv2d_19[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 256, 256, 16)         2320      ['dropout_9[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 128, 128, 16)         0         ['conv2d_20[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 128, 128, 32)         4640      ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, 128, 128, 32)         0         ['conv2d_21[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 128, 128, 32)         9248      ['dropout_10[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 64, 64, 32)           0         ['conv2d_22[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 64, 64, 64)           18496     ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, 64, 64, 64)           0         ['conv2d_23[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 64, 64, 64)           36928     ['dropout_11[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPoolin  (None, 32, 32, 64)           0         ['conv2d_24[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 32, 32, 128)          73856     ['max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)        (None, 32, 32, 128)          0         ['conv2d_25[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 32, 32, 128)          147584    ['dropout_12[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_26[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 16, 16, 256)          295168    ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)        (None, 16, 16, 256)          0         ['conv2d_27[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 16, 16, 256)          590080    ['dropout_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2D  (None, 32, 32, 128)          131200    ['conv2d_28[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 32, 32, 256)          0         ['conv2d_transpose_4[0][0]',  \n",
            " )                                                                   'conv2d_26[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 32, 32, 128)          295040    ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)        (None, 32, 32, 128)          0         ['conv2d_29[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 32, 32, 128)          147584    ['dropout_14[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2D  (None, 64, 64, 64)           32832     ['conv2d_30[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 64, 64, 128)          0         ['conv2d_transpose_5[0][0]',  \n",
            " )                                                                   'conv2d_24[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 64, 64, 64)           73792     ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)        (None, 64, 64, 64)           0         ['conv2d_31[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 64, 64, 64)           36928     ['dropout_15[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2D  (None, 128, 128, 32)         8224      ['conv2d_32[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate  (None, 128, 128, 64)         0         ['conv2d_transpose_6[0][0]',  \n",
            " )                                                                   'conv2d_22[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 128, 128, 32)         18464     ['concatenate_6[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)        (None, 128, 128, 32)         0         ['conv2d_33[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 128, 128, 32)         9248      ['dropout_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2D  (None, 256, 256, 16)         2064      ['conv2d_34[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate  (None, 256, 256, 32)         0         ['conv2d_transpose_7[0][0]',  \n",
            " )                                                                   'conv2d_20[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 256, 256, 16)         4624      ['concatenate_7[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)        (None, 256, 256, 16)         0         ['conv2d_35[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 256, 256, 16)         2320      ['dropout_17[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 256, 256, 10)         170       ['conv2d_36[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-f4a94efc7375>:45: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator=tg,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "17/17 [==============================] - 13s 134ms/step - loss: 0.5324 - dice: 0.4676 - val_loss: 0.4276 - val_dice: 0.5724\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 2s 115ms/step - loss: 0.4554 - dice: 0.5446 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 2s 123ms/step - loss: 0.4556 - dice: 0.5444 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 3s 156ms/step - loss: 0.4572 - dice: 0.5428 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 3s 170ms/step - loss: 0.4553 - dice: 0.5447 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 2s 112ms/step - loss: 0.4547 - dice: 0.5453 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 2s 109ms/step - loss: 0.4565 - dice: 0.5435 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 2s 110ms/step - loss: 0.4563 - dice: 0.5437 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 2s 114ms/step - loss: 0.4577 - dice: 0.5423 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 2s 140ms/step - loss: 0.4548 - dice: 0.5452 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 3s 167ms/step - loss: 0.4542 - dice: 0.5458 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 4s 218ms/step - loss: 0.4548 - dice: 0.5452 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 2s 110ms/step - loss: 0.4556 - dice: 0.5444 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 2s 111ms/step - loss: 0.4574 - dice: 0.5426 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 2s 111ms/step - loss: 0.4552 - dice: 0.5448 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 2s 114ms/step - loss: 0.4549 - dice: 0.5451 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 2s 130ms/step - loss: 0.4550 - dice: 0.5450 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 3s 161ms/step - loss: 0.4554 - dice: 0.5446 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 2s 112ms/step - loss: 0.4570 - dice: 0.5430 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 2s 111ms/step - loss: 0.4559 - dice: 0.5441 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 2s 115ms/step - loss: 0.4563 - dice: 0.5437 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 2s 131ms/step - loss: 0.4579 - dice: 0.5421 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 2s 141ms/step - loss: 0.4563 - dice: 0.5437 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 3s 166ms/step - loss: 0.4575 - dice: 0.5425 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 2s 113ms/step - loss: 0.4545 - dice: 0.5455 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 2s 135ms/step - loss: 0.4566 - dice: 0.5434 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 2s 115ms/step - loss: 0.4559 - dice: 0.5441 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 2s 116ms/step - loss: 0.4572 - dice: 0.5428 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 2s 137ms/step - loss: 0.4570 - dice: 0.5430 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 3s 166ms/step - loss: 0.4554 - dice: 0.5446 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 3s 164ms/step - loss: 0.4556 - dice: 0.5444 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 2s 114ms/step - loss: 0.4556 - dice: 0.5444 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - 2s 111ms/step - loss: 0.4559 - dice: 0.5441 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - 2s 111ms/step - loss: 0.4565 - dice: 0.5435 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - 2s 129ms/step - loss: 0.4554 - dice: 0.5446 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - 3s 154ms/step - loss: 0.4580 - dice: 0.5420 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - 2s 110ms/step - loss: 0.4548 - dice: 0.5452 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - 2s 112ms/step - loss: 0.4545 - dice: 0.5455 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - 2s 108ms/step - loss: 0.4554 - dice: 0.5446 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - 2s 113ms/step - loss: 0.4550 - dice: 0.5450 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - 3s 148ms/step - loss: 0.4553 - dice: 0.5447 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - 3s 166ms/step - loss: 0.4543 - dice: 0.5457 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - 3s 158ms/step - loss: 0.4554 - dice: 0.5446 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - 2s 110ms/step - loss: 0.4565 - dice: 0.5435 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - 2s 109ms/step - loss: 0.4542 - dice: 0.5458 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - 2s 109ms/step - loss: 0.4566 - dice: 0.5434 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - 2s 122ms/step - loss: 0.4577 - dice: 0.5423 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - 3s 156ms/step - loss: 0.4541 - dice: 0.5459 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - 3s 149ms/step - loss: 0.4579 - dice: 0.5421 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - 3s 163ms/step - loss: 0.4557 - dice: 0.5443 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - 2s 109ms/step - loss: 0.4557 - dice: 0.5443 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - 2s 138ms/step - loss: 0.4561 - dice: 0.5439 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - 2s 129ms/step - loss: 0.4561 - dice: 0.5439 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - 2s 112ms/step - loss: 0.4552 - dice: 0.5448 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - 3s 150ms/step - loss: 0.4560 - dice: 0.5440 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - 3s 155ms/step - loss: 0.4555 - dice: 0.5445 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - 2s 110ms/step - loss: 0.4558 - dice: 0.5442 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - 2s 112ms/step - loss: 0.4564 - dice: 0.5436 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - 2s 110ms/step - loss: 0.4565 - dice: 0.5435 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - 2s 112ms/step - loss: 0.4552 - dice: 0.5448 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - 2s 118ms/step - loss: 0.4534 - dice: 0.5466 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - 3s 161ms/step - loss: 0.4559 - dice: 0.5441 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - 2s 114ms/step - loss: 0.4531 - dice: 0.5469 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - 2s 112ms/step - loss: 0.4548 - dice: 0.5452 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - 2s 106ms/step - loss: 0.4558 - dice: 0.5442 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - 2s 107ms/step - loss: 0.4559 - dice: 0.5441 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - 2s 126ms/step - loss: 0.4568 - dice: 0.5432 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - 3s 152ms/step - loss: 0.4554 - dice: 0.5446 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - 2s 108ms/step - loss: 0.4556 - dice: 0.5444 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - 2s 107ms/step - loss: 0.4554 - dice: 0.5446 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - 2s 111ms/step - loss: 0.4558 - dice: 0.5442 - val_loss: 0.4262 - val_dice: 0.5738\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-f4a94efc7375>:54: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  val_loss = model.evaluate_generator(generator=val_generator, steps=len(val_generator))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " conv2d_609 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_288[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_128 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_609[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_610 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_128[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_289 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_610[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_611 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_289[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_129 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_611[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_612 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_129[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_290 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_612[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_613 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_290[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_130 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_613[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_614 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_130[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_291 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_614[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_615 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_291[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_131 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_615[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_616 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_131[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_292 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_616[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_617 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_292[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_128 (Conv  (None, 32, 32, 128)          131200    ['conv2d_617[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_128 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_128[0][0]',\n",
            " te)                                                                 'conv2d_615[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_618 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_128[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_293 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_618[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_619 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_293[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_129 (Conv  (None, 64, 64, 64)           32832     ['conv2d_619[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_129 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_129[0][0]',\n",
            " te)                                                                 'conv2d_613[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_620 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_129[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_294 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_620[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_621 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_294[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_130 (Conv  (None, 128, 128, 32)         8224      ['conv2d_621[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_130 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_130[0][0]',\n",
            " te)                                                                 'conv2d_611[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_622 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_130[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_295 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_622[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_623 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_295[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_131 (Conv  (None, 256, 256, 16)         2064      ['conv2d_623[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_131 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_131[0][0]',\n",
            " te)                                                                 'conv2d_609[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_624 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_131[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_296 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_624[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_625 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_296[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_626 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_625[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 10s 444ms/step - loss: 3.4191 - dice: 0.0807 - val_loss: 2.6469 - val_dice: 0.0967\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 2.6115 - dice: 0.1053 - val_loss: 2.2738 - val_dice: 0.1200\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 2s 286ms/step - loss: 2.2962 - dice: 0.1280 - val_loss: 2.0924 - val_dice: 0.1440\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 2.1343 - dice: 0.1494 - val_loss: 1.9704 - val_dice: 0.1653\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 3s 381ms/step - loss: 2.0035 - dice: 0.1720 - val_loss: 1.8497 - val_dice: 0.1941\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 3s 352ms/step - loss: 1.8899 - dice: 0.1981 - val_loss: 1.7354 - val_dice: 0.2270\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 3s 321ms/step - loss: 1.7664 - dice: 0.2296 - val_loss: 1.6320 - val_dice: 0.2760\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 1.6572 - dice: 0.2676 - val_loss: 1.5389 - val_dice: 0.3277\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 1.5447 - dice: 0.3159 - val_loss: 1.5502 - val_dice: 0.3989\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 1.4607 - dice: 0.3556 - val_loss: 1.4607 - val_dice: 0.4420\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 3s 368ms/step - loss: 1.3912 - dice: 0.3917 - val_loss: 1.3884 - val_dice: 0.4867\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 3s 353ms/step - loss: 1.3403 - dice: 0.4243 - val_loss: 1.4566 - val_dice: 0.5151\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 2s 294ms/step - loss: 1.2806 - dice: 0.4511 - val_loss: 2.0214 - val_dice: 0.5359\n",
            "\n",
            "Training model with parameters: {'batch_size': 16, 'learning_rate': 0.0001, 'loss': <function categorical_cross_entropy_loss at 0x7bccb964dcf0>, 'optimizer': <class 'keras.src.optimizers.sgd.SGD'>}\n",
            "Model: \"model_33\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_34 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_33 (Lambda)          (None, 256, 256, 3)          0         ['input_34[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_627 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_33[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_297 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_627[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_628 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_297[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_132 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_628[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_629 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_132[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_298 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_629[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_630 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_298[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_133 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_630[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_631 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_133[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_299 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_631[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_632 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_299[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_134 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_632[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_633 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_134[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_300 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_633[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_634 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_300[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_135 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_634[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_635 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_135[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_301 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_635[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_636 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_301[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_132 (Conv  (None, 32, 32, 128)          131200    ['conv2d_636[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_132 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_132[0][0]',\n",
            " te)                                                                 'conv2d_634[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_637 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_132[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_302 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_637[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_638 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_302[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_133 (Conv  (None, 64, 64, 64)           32832     ['conv2d_638[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_133 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_133[0][0]',\n",
            " te)                                                                 'conv2d_632[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_639 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_133[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_303 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_639[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_640 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_303[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_134 (Conv  (None, 128, 128, 32)         8224      ['conv2d_640[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_134 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_134[0][0]',\n",
            " te)                                                                 'conv2d_630[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_641 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_134[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_304 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_641[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_642 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_304[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_135 (Conv  (None, 256, 256, 16)         2064      ['conv2d_642[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_135 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_135[0][0]',\n",
            " te)                                                                 'conv2d_628[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_643 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_135[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_305 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_643[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_644 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_305[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_645 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_644[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 7s 403ms/step - loss: 3.4281 - dice: 0.0592 - val_loss: 3.0783 - val_dice: 0.0661\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 3s 343ms/step - loss: 3.3988 - dice: 0.0598 - val_loss: 3.0493 - val_dice: 0.0670\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 3s 353ms/step - loss: 3.3511 - dice: 0.0609 - val_loss: 3.0220 - val_dice: 0.0679\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 3s 330ms/step - loss: 3.3196 - dice: 0.0617 - val_loss: 2.9959 - val_dice: 0.0688\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 3s 330ms/step - loss: 3.2860 - dice: 0.0627 - val_loss: 2.9711 - val_dice: 0.0697\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 3.2636 - dice: 0.0630 - val_loss: 2.9473 - val_dice: 0.0705\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 2s 299ms/step - loss: 3.2203 - dice: 0.0645 - val_loss: 2.9250 - val_dice: 0.0713\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 3s 321ms/step - loss: 3.1977 - dice: 0.0651 - val_loss: 2.9035 - val_dice: 0.0721\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 3s 400ms/step - loss: 3.1689 - dice: 0.0660 - val_loss: 2.8831 - val_dice: 0.0729\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 3s 355ms/step - loss: 3.1470 - dice: 0.0667 - val_loss: 2.8633 - val_dice: 0.0737\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 2s 285ms/step - loss: 3.1156 - dice: 0.0677 - val_loss: 2.8447 - val_dice: 0.0745\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 2s 312ms/step - loss: 3.0870 - dice: 0.0687 - val_loss: 2.8269 - val_dice: 0.0753\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 3s 326ms/step - loss: 3.0749 - dice: 0.0689 - val_loss: 2.8096 - val_dice: 0.0760\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 3s 330ms/step - loss: 3.0508 - dice: 0.0699 - val_loss: 2.7930 - val_dice: 0.0767\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 3s 389ms/step - loss: 3.0382 - dice: 0.0704 - val_loss: 2.7769 - val_dice: 0.0775\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 3s 337ms/step - loss: 3.0136 - dice: 0.0713 - val_loss: 2.7615 - val_dice: 0.0782\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 2s 303ms/step - loss: 2.9976 - dice: 0.0720 - val_loss: 2.7467 - val_dice: 0.0789\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 2s 306ms/step - loss: 2.9789 - dice: 0.0728 - val_loss: 2.7323 - val_dice: 0.0796\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 3s 396ms/step - loss: 2.9577 - dice: 0.0735 - val_loss: 2.7185 - val_dice: 0.0803\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 3s 322ms/step - loss: 2.9419 - dice: 0.0742 - val_loss: 2.7051 - val_dice: 0.0810\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 2s 290ms/step - loss: 2.9222 - dice: 0.0751 - val_loss: 2.6923 - val_dice: 0.0817\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 2s 306ms/step - loss: 2.9111 - dice: 0.0755 - val_loss: 2.6799 - val_dice: 0.0824\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 3s 315ms/step - loss: 2.8963 - dice: 0.0764 - val_loss: 2.6677 - val_dice: 0.0830\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 3s 390ms/step - loss: 2.8857 - dice: 0.0766 - val_loss: 2.6559 - val_dice: 0.0837\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 3s 337ms/step - loss: 2.8602 - dice: 0.0778 - val_loss: 2.6448 - val_dice: 0.0843\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 2.8478 - dice: 0.0786 - val_loss: 2.6338 - val_dice: 0.0850\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 2.8337 - dice: 0.0792 - val_loss: 2.6233 - val_dice: 0.0856\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 2.8217 - dice: 0.0799 - val_loss: 2.6130 - val_dice: 0.0863\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 2.8118 - dice: 0.0803 - val_loss: 2.6030 - val_dice: 0.0869\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 3s 341ms/step - loss: 2.8000 - dice: 0.0810 - val_loss: 2.5932 - val_dice: 0.0875\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 2.7883 - dice: 0.0816 - val_loss: 2.5836 - val_dice: 0.0882\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 2s 296ms/step - loss: 2.7753 - dice: 0.0822 - val_loss: 2.5745 - val_dice: 0.0888\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 2s 296ms/step - loss: 2.7638 - dice: 0.0828 - val_loss: 2.5656 - val_dice: 0.0894\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 2s 318ms/step - loss: 2.7554 - dice: 0.0834 - val_loss: 2.5568 - val_dice: 0.0900\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 3s 399ms/step - loss: 2.7416 - dice: 0.0841 - val_loss: 2.5483 - val_dice: 0.0906\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 2s 292ms/step - loss: 2.7341 - dice: 0.0846 - val_loss: 2.5399 - val_dice: 0.0912\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 2s 301ms/step - loss: 2.7242 - dice: 0.0853 - val_loss: 2.5317 - val_dice: 0.0918\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 2.7137 - dice: 0.0859 - val_loss: 2.5236 - val_dice: 0.0924\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 2.6999 - dice: 0.0865 - val_loss: 2.5159 - val_dice: 0.0930\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 3s 395ms/step - loss: 2.6938 - dice: 0.0872 - val_loss: 2.5082 - val_dice: 0.0936\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 2.6809 - dice: 0.0878 - val_loss: 2.5009 - val_dice: 0.0942\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 2s 245ms/step - loss: 2.6749 - dice: 0.0883 - val_loss: 2.4937 - val_dice: 0.0948\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 2.6651 - dice: 0.0889 - val_loss: 2.4865 - val_dice: 0.0954\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 3s 325ms/step - loss: 2.6535 - dice: 0.0896 - val_loss: 2.4795 - val_dice: 0.0960\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 3s 313ms/step - loss: 2.6479 - dice: 0.0901 - val_loss: 2.4727 - val_dice: 0.0966\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 2s 294ms/step - loss: 2.6425 - dice: 0.0905 - val_loss: 2.4659 - val_dice: 0.0972\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 2.6309 - dice: 0.0912 - val_loss: 2.4592 - val_dice: 0.0978\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 2.6251 - dice: 0.0917 - val_loss: 2.4528 - val_dice: 0.0983\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 3s 383ms/step - loss: 2.6129 - dice: 0.0925 - val_loss: 2.4466 - val_dice: 0.0989\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 3s 375ms/step - loss: 2.6116 - dice: 0.0928 - val_loss: 2.4403 - val_dice: 0.0995\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 2.6020 - dice: 0.0936 - val_loss: 2.4341 - val_dice: 0.1001\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 2s 292ms/step - loss: 2.5948 - dice: 0.0940 - val_loss: 2.4281 - val_dice: 0.1006\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 2s 294ms/step - loss: 2.5881 - dice: 0.0946 - val_loss: 2.4222 - val_dice: 0.1012\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 3s 356ms/step - loss: 2.5818 - dice: 0.0950 - val_loss: 2.4163 - val_dice: 0.1018\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 2.5726 - dice: 0.0957 - val_loss: 2.4107 - val_dice: 0.1024\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 2s 291ms/step - loss: 2.5671 - dice: 0.0961 - val_loss: 2.4051 - val_dice: 0.1029\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 2s 299ms/step - loss: 2.5595 - dice: 0.0966 - val_loss: 2.3995 - val_dice: 0.1035\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 2.5533 - dice: 0.0973 - val_loss: 2.3941 - val_dice: 0.1041\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 3s 371ms/step - loss: 2.5457 - dice: 0.0981 - val_loss: 2.3886 - val_dice: 0.1047\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 2s 287ms/step - loss: 2.5411 - dice: 0.0983 - val_loss: 2.3834 - val_dice: 0.1052\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 3s 335ms/step - loss: 2.5305 - dice: 0.0992 - val_loss: 2.3781 - val_dice: 0.1058\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 2s 292ms/step - loss: 2.5272 - dice: 0.0994 - val_loss: 2.3730 - val_dice: 0.1064\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 3s 350ms/step - loss: 2.5228 - dice: 0.0999 - val_loss: 2.3679 - val_dice: 0.1069\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 2s 290ms/step - loss: 2.5160 - dice: 0.1006 - val_loss: 2.3629 - val_dice: 0.1075\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 2.5108 - dice: 0.1010 - val_loss: 2.3580 - val_dice: 0.1081\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 2s 297ms/step - loss: 2.5033 - dice: 0.1017 - val_loss: 2.3531 - val_dice: 0.1086\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 2.4956 - dice: 0.1023 - val_loss: 2.3484 - val_dice: 0.1092\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 3s 389ms/step - loss: 2.4925 - dice: 0.1028 - val_loss: 2.3436 - val_dice: 0.1097\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 3s 373ms/step - loss: 2.4858 - dice: 0.1034 - val_loss: 2.3388 - val_dice: 0.1103\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 2s 297ms/step - loss: 2.4840 - dice: 0.1035 - val_loss: 2.3342 - val_dice: 0.1109\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 3s 327ms/step - loss: 2.4752 - dice: 0.1044 - val_loss: 2.3296 - val_dice: 0.1114\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 2s 292ms/step - loss: 2.4692 - dice: 0.1051 - val_loss: 2.3250 - val_dice: 0.1120\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 3s 368ms/step - loss: 2.4658 - dice: 0.1053 - val_loss: 2.3205 - val_dice: 0.1126\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 3s 387ms/step - loss: 2.4603 - dice: 0.1058 - val_loss: 2.3161 - val_dice: 0.1132\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 2s 310ms/step - loss: 2.4517 - dice: 0.1067 - val_loss: 2.3117 - val_dice: 0.1137\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 2s 314ms/step - loss: 2.4504 - dice: 0.1070 - val_loss: 2.3073 - val_dice: 0.1143\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 2s 303ms/step - loss: 2.4453 - dice: 0.1072 - val_loss: 2.3031 - val_dice: 0.1148\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 3s 366ms/step - loss: 2.4377 - dice: 0.1082 - val_loss: 2.2989 - val_dice: 0.1154\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 3s 379ms/step - loss: 2.4324 - dice: 0.1088 - val_loss: 2.2946 - val_dice: 0.1160\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 2s 297ms/step - loss: 2.4288 - dice: 0.1093 - val_loss: 2.2904 - val_dice: 0.1166\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 3s 324ms/step - loss: 2.4233 - dice: 0.1098 - val_loss: 2.2863 - val_dice: 0.1171\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 2s 299ms/step - loss: 2.4207 - dice: 0.1101 - val_loss: 2.2822 - val_dice: 0.1177\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 3s 390ms/step - loss: 2.4169 - dice: 0.1104 - val_loss: 2.2782 - val_dice: 0.1182\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 3s 372ms/step - loss: 2.4140 - dice: 0.1109 - val_loss: 2.2742 - val_dice: 0.1188\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 2s 289ms/step - loss: 2.4069 - dice: 0.1115 - val_loss: 2.2703 - val_dice: 0.1194\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 2s 311ms/step - loss: 2.4007 - dice: 0.1123 - val_loss: 2.2664 - val_dice: 0.1199\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 2s 294ms/step - loss: 2.3983 - dice: 0.1125 - val_loss: 2.2625 - val_dice: 0.1205\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 3s 391ms/step - loss: 2.3926 - dice: 0.1132 - val_loss: 2.2586 - val_dice: 0.1210\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 3s 378ms/step - loss: 2.3868 - dice: 0.1141 - val_loss: 2.2547 - val_dice: 0.1216\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 2s 288ms/step - loss: 2.3817 - dice: 0.1146 - val_loss: 2.2509 - val_dice: 0.1222\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 3s 321ms/step - loss: 2.3789 - dice: 0.1148 - val_loss: 2.2471 - val_dice: 0.1228\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 2s 296ms/step - loss: 2.3703 - dice: 0.1159 - val_loss: 2.2433 - val_dice: 0.1233\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 3s 318ms/step - loss: 2.3636 - dice: 0.1168 - val_loss: 2.2396 - val_dice: 0.1239\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 3s 357ms/step - loss: 2.3638 - dice: 0.1168 - val_loss: 2.2359 - val_dice: 0.1245\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 3s 320ms/step - loss: 2.3598 - dice: 0.1173 - val_loss: 2.2322 - val_dice: 0.1251\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 2s 288ms/step - loss: 2.3601 - dice: 0.1170 - val_loss: 2.2286 - val_dice: 0.1256\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 2s 298ms/step - loss: 2.3570 - dice: 0.1176 - val_loss: 2.2251 - val_dice: 0.1262\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 3s 338ms/step - loss: 2.3410 - dice: 0.1195 - val_loss: 2.2214 - val_dice: 0.1268\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 3s 365ms/step - loss: 2.3405 - dice: 0.1195 - val_loss: 2.2179 - val_dice: 0.1274\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 2.3384 - dice: 0.1200 - val_loss: 2.2143 - val_dice: 0.1279\n",
            "\n",
            "Training model with parameters: {'batch_size': 16, 'learning_rate': 0.0001, 'loss': <function DiceBCELoss at 0x7bcc24dc25f0>, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>}\n",
            "Model: \"model_34\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_35 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_34 (Lambda)          (None, 256, 256, 3)          0         ['input_35[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_646 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_34[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_306 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_646[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_647 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_306[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_136 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_647[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_648 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_136[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_307 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_648[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_649 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_307[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_137 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_649[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_650 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_137[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_308 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_650[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_651 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_308[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_138 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_651[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_652 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_138[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_309 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_652[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_653 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_309[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_139 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_653[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_654 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_139[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_310 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_654[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_655 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_310[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_136 (Conv  (None, 32, 32, 128)          131200    ['conv2d_655[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_136 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_136[0][0]',\n",
            " te)                                                                 'conv2d_653[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_656 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_136[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_311 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_656[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_657 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_311[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_137 (Conv  (None, 64, 64, 64)           32832     ['conv2d_657[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_137 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_137[0][0]',\n",
            " te)                                                                 'conv2d_651[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_658 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_137[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_312 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_658[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_659 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_312[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_138 (Conv  (None, 128, 128, 32)         8224      ['conv2d_659[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_138 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_138[0][0]',\n",
            " te)                                                                 'conv2d_649[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_660 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_138[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_313 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_660[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_661 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_313[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_139 (Conv  (None, 256, 256, 16)         2064      ['conv2d_661[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_139 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_139[0][0]',\n",
            " te)                                                                 'conv2d_647[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_662 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_139[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_314 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_662[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_663 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_314[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_664 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_663[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 8s 465ms/step - loss: 1.5015 - dice: 0.1329 - val_loss: 1.3366 - val_dice: 0.1747\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 3s 372ms/step - loss: 1.2522 - dice: 0.2268 - val_loss: 1.1119 - val_dice: 0.2846\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 2s 301ms/step - loss: 1.0718 - dice: 0.3363 - val_loss: 0.9231 - val_dice: 0.4202\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 0.9539 - dice: 0.4251 - val_loss: 0.8583 - val_dice: 0.4541\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 0.9050 - dice: 0.4495 - val_loss: 0.8059 - val_dice: 0.4895\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 2s 294ms/step - loss: 0.8486 - dice: 0.4802 - val_loss: 0.7666 - val_dice: 0.5129\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 3s 361ms/step - loss: 0.8235 - dice: 0.4901 - val_loss: 0.7418 - val_dice: 0.5184\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 3s 338ms/step - loss: 0.7811 - dice: 0.5055 - val_loss: 0.7582 - val_dice: 0.5579\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 0.7621 - dice: 0.5188 - val_loss: 0.7228 - val_dice: 0.5621\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 2s 293ms/step - loss: 0.7575 - dice: 0.5180 - val_loss: 0.6652 - val_dice: 0.5690\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 0.7403 - dice: 0.5324 - val_loss: 0.6543 - val_dice: 0.5739\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 2s 305ms/step - loss: 0.7068 - dice: 0.5446 - val_loss: 0.6500 - val_dice: 0.5775\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 3s 372ms/step - loss: 0.6999 - dice: 0.5484 - val_loss: 0.7449 - val_dice: 0.5732\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 3s 332ms/step - loss: 0.6924 - dice: 0.5585 - val_loss: 0.6256 - val_dice: 0.6004\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 3s 340ms/step - loss: 0.6608 - dice: 0.5764 - val_loss: 0.5979 - val_dice: 0.6153\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 2s 310ms/step - loss: 0.6399 - dice: 0.5895 - val_loss: 0.7318 - val_dice: 0.5852\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 3s 354ms/step - loss: 0.6399 - dice: 0.5943 - val_loss: 0.6410 - val_dice: 0.6093\n",
            "\n",
            "Training model with parameters: {'batch_size': 16, 'learning_rate': 0.0001, 'loss': <function DiceBCELoss at 0x7bcc24dc25f0>, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>}\n",
            "Model: \"model_35\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_36 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_35 (Lambda)          (None, 256, 256, 3)          0         ['input_36[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_665 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_35[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_315 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_665[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_666 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_315[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_140 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_666[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_667 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_140[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_316 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_667[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_668 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_316[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_141 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_668[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_669 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_141[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_317 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_669[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_670 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_317[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_142 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_670[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_671 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_142[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_318 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_671[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_672 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_318[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_143 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_672[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_673 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_143[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_319 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_673[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_674 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_319[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_140 (Conv  (None, 32, 32, 128)          131200    ['conv2d_674[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_140 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_140[0][0]',\n",
            " te)                                                                 'conv2d_672[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_675 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_140[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_320 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_675[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_676 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_320[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_141 (Conv  (None, 64, 64, 64)           32832     ['conv2d_676[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_141 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_141[0][0]',\n",
            " te)                                                                 'conv2d_670[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_677 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_141[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_321 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_677[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_678 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_321[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_142 (Conv  (None, 128, 128, 32)         8224      ['conv2d_678[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_142 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_142[0][0]',\n",
            " te)                                                                 'conv2d_668[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_679 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_142[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_322 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_679[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_680 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_322[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_143 (Conv  (None, 256, 256, 16)         2064      ['conv2d_680[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_143 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_143[0][0]',\n",
            " te)                                                                 'conv2d_666[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_681 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_143[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_323 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_681[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_682 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_323[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_683 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_682[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 10s 415ms/step - loss: 1.8079 - dice: 0.0982 - val_loss: 1.6561 - val_dice: 0.1146\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 2s 287ms/step - loss: 1.6498 - dice: 0.1221 - val_loss: 1.5505 - val_dice: 0.1435\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 2s 292ms/step - loss: 1.5577 - dice: 0.1491 - val_loss: 1.4838 - val_dice: 0.1742\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 1.4879 - dice: 0.1799 - val_loss: 1.4199 - val_dice: 0.2097\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 3s 379ms/step - loss: 1.4196 - dice: 0.2184 - val_loss: 1.3584 - val_dice: 0.2463\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 1.3606 - dice: 0.2530 - val_loss: 1.3028 - val_dice: 0.2797\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 3s 325ms/step - loss: 1.3022 - dice: 0.2894 - val_loss: 1.2520 - val_dice: 0.3110\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 3s 322ms/step - loss: 1.2546 - dice: 0.3198 - val_loss: 1.2087 - val_dice: 0.3390\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 3s 384ms/step - loss: 1.2148 - dice: 0.3478 - val_loss: 1.1689 - val_dice: 0.3685\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 1.1755 - dice: 0.3801 - val_loss: 1.1151 - val_dice: 0.4152\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 2s 286ms/step - loss: 1.1305 - dice: 0.4227 - val_loss: 1.0518 - val_dice: 0.4913\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 1.0839 - dice: 0.4661 - val_loss: 1.0705 - val_dice: 0.5383\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 3s 327ms/step - loss: 1.0433 - dice: 0.5008 - val_loss: 1.1577 - val_dice: 0.5462\n",
            "\n",
            "Training model with parameters: {'batch_size': 16, 'learning_rate': 0.0001, 'loss': <function DiceBCELoss at 0x7bcc24dc25f0>, 'optimizer': <class 'keras.src.optimizers.sgd.SGD'>}\n",
            "Model: \"model_36\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_37 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_36 (Lambda)          (None, 256, 256, 3)          0         ['input_37[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_684 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_36[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_324 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_684[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_685 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_324[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_144 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_685[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_686 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_144[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_325 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_686[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_687 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_325[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_145 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_687[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_688 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_145[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_326 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_688[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_689 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_326[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_146 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_689[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_690 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_146[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_327 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_690[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_691 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_327[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_147 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_691[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_692 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_147[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_328 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_692[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_693 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_328[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_144 (Conv  (None, 32, 32, 128)          131200    ['conv2d_693[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_144 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_144[0][0]',\n",
            " te)                                                                 'conv2d_691[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_694 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_144[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_329 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_694[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_695 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_329[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_145 (Conv  (None, 64, 64, 64)           32832     ['conv2d_695[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_145 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_145[0][0]',\n",
            " te)                                                                 'conv2d_689[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_696 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_145[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_330 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_696[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_697 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_330[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_146 (Conv  (None, 128, 128, 32)         8224      ['conv2d_697[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_146 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_146[0][0]',\n",
            " te)                                                                 'conv2d_687[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_698 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_146[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_331 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_698[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_699 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_331[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_147 (Conv  (None, 256, 256, 16)         2064      ['conv2d_699[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_147 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_147[0][0]',\n",
            " te)                                                                 'conv2d_685[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_700 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_147[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_332 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_700[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_701 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_332[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_702 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_701[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 9s 358ms/step - loss: 1.8804 - dice: 0.0777 - val_loss: 1.8159 - val_dice: 0.0817\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 2s 297ms/step - loss: 1.8737 - dice: 0.0780 - val_loss: 1.8141 - val_dice: 0.0819\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 3s 353ms/step - loss: 1.8746 - dice: 0.0780 - val_loss: 1.8123 - val_dice: 0.0821\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 2s 305ms/step - loss: 1.8754 - dice: 0.0777 - val_loss: 1.8105 - val_dice: 0.0823\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 2s 289ms/step - loss: 1.8717 - dice: 0.0787 - val_loss: 1.8087 - val_dice: 0.0825\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 1.8667 - dice: 0.0790 - val_loss: 1.8070 - val_dice: 0.0827\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 2s 308ms/step - loss: 1.8643 - dice: 0.0793 - val_loss: 1.8053 - val_dice: 0.0829\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 3s 376ms/step - loss: 1.8667 - dice: 0.0788 - val_loss: 1.8036 - val_dice: 0.0831\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 2s 302ms/step - loss: 1.8638 - dice: 0.0793 - val_loss: 1.8019 - val_dice: 0.0833\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 1.8620 - dice: 0.0795 - val_loss: 1.8002 - val_dice: 0.0835\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 3s 325ms/step - loss: 1.8593 - dice: 0.0799 - val_loss: 1.7985 - val_dice: 0.0837\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 3s 358ms/step - loss: 1.8552 - dice: 0.0802 - val_loss: 1.7969 - val_dice: 0.0839\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 3s 375ms/step - loss: 1.8559 - dice: 0.0800 - val_loss: 1.7953 - val_dice: 0.0841\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 3s 314ms/step - loss: 1.8517 - dice: 0.0808 - val_loss: 1.7937 - val_dice: 0.0843\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 1.8521 - dice: 0.0803 - val_loss: 1.7921 - val_dice: 0.0845\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 1.8415 - dice: 0.0821 - val_loss: 1.7906 - val_dice: 0.0847\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 3s 325ms/step - loss: 1.8503 - dice: 0.0807 - val_loss: 1.7891 - val_dice: 0.0849\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 1.8476 - dice: 0.0812 - val_loss: 1.7875 - val_dice: 0.0851\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 1.8444 - dice: 0.0814 - val_loss: 1.7860 - val_dice: 0.0853\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 1.8418 - dice: 0.0818 - val_loss: 1.7845 - val_dice: 0.0855\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 2s 288ms/step - loss: 1.8411 - dice: 0.0817 - val_loss: 1.7830 - val_dice: 0.0857\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 3s 349ms/step - loss: 1.8406 - dice: 0.0820 - val_loss: 1.7815 - val_dice: 0.0858\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 3s 355ms/step - loss: 1.8371 - dice: 0.0824 - val_loss: 1.7801 - val_dice: 0.0860\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 1.8324 - dice: 0.0832 - val_loss: 1.7786 - val_dice: 0.0862\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 1.8352 - dice: 0.0823 - val_loss: 1.7772 - val_dice: 0.0864\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 2s 245ms/step - loss: 1.8281 - dice: 0.0836 - val_loss: 1.7758 - val_dice: 0.0866\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 3s 345ms/step - loss: 1.8310 - dice: 0.0828 - val_loss: 1.7744 - val_dice: 0.0868\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 2s 287ms/step - loss: 1.8285 - dice: 0.0830 - val_loss: 1.7730 - val_dice: 0.0870\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 1.8250 - dice: 0.0842 - val_loss: 1.7717 - val_dice: 0.0872\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 1.8258 - dice: 0.0838 - val_loss: 1.7703 - val_dice: 0.0874\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 2s 317ms/step - loss: 1.8249 - dice: 0.0839 - val_loss: 1.7690 - val_dice: 0.0876\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 3s 402ms/step - loss: 1.8225 - dice: 0.0840 - val_loss: 1.7676 - val_dice: 0.0878\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 3s 308ms/step - loss: 1.8217 - dice: 0.0845 - val_loss: 1.7663 - val_dice: 0.0879\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 1.8202 - dice: 0.0846 - val_loss: 1.7650 - val_dice: 0.0881\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 1.8191 - dice: 0.0843 - val_loss: 1.7637 - val_dice: 0.0883\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 1.8192 - dice: 0.0844 - val_loss: 1.7624 - val_dice: 0.0885\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 3s 354ms/step - loss: 1.8160 - dice: 0.0851 - val_loss: 1.7611 - val_dice: 0.0887\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 3s 365ms/step - loss: 1.8139 - dice: 0.0856 - val_loss: 1.7598 - val_dice: 0.0889\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 1.8132 - dice: 0.0850 - val_loss: 1.7586 - val_dice: 0.0891\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 1.8088 - dice: 0.0862 - val_loss: 1.7573 - val_dice: 0.0893\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 1.8081 - dice: 0.0863 - val_loss: 1.7561 - val_dice: 0.0894\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 1.8109 - dice: 0.0855 - val_loss: 1.7549 - val_dice: 0.0896\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 3s 334ms/step - loss: 1.8065 - dice: 0.0863 - val_loss: 1.7537 - val_dice: 0.0898\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 1.8042 - dice: 0.0868 - val_loss: 1.7525 - val_dice: 0.0900\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 1.8038 - dice: 0.0869 - val_loss: 1.7513 - val_dice: 0.0902\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 1.8018 - dice: 0.0870 - val_loss: 1.7501 - val_dice: 0.0904\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 2s 297ms/step - loss: 1.8037 - dice: 0.0868 - val_loss: 1.7489 - val_dice: 0.0905\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 3s 367ms/step - loss: 1.8002 - dice: 0.0873 - val_loss: 1.7478 - val_dice: 0.0907\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 3s 330ms/step - loss: 1.8008 - dice: 0.0871 - val_loss: 1.7466 - val_dice: 0.0909\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 2s 285ms/step - loss: 1.7989 - dice: 0.0873 - val_loss: 1.7455 - val_dice: 0.0911\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 1.7989 - dice: 0.0873 - val_loss: 1.7443 - val_dice: 0.0913\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 1.7950 - dice: 0.0877 - val_loss: 1.7432 - val_dice: 0.0915\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 2s 314ms/step - loss: 1.7925 - dice: 0.0885 - val_loss: 1.7421 - val_dice: 0.0916\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 3s 401ms/step - loss: 1.7939 - dice: 0.0885 - val_loss: 1.7410 - val_dice: 0.0918\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 2s 297ms/step - loss: 1.7898 - dice: 0.0887 - val_loss: 1.7399 - val_dice: 0.0920\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 1.7879 - dice: 0.0888 - val_loss: 1.7388 - val_dice: 0.0922\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 1.7885 - dice: 0.0887 - val_loss: 1.7378 - val_dice: 0.0924\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 3s 334ms/step - loss: 1.7846 - dice: 0.0895 - val_loss: 1.7367 - val_dice: 0.0925\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 2s 248ms/step - loss: 1.7869 - dice: 0.0889 - val_loss: 1.7357 - val_dice: 0.0927\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 1.7823 - dice: 0.0896 - val_loss: 1.7346 - val_dice: 0.0929\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 1.7854 - dice: 0.0896 - val_loss: 1.7336 - val_dice: 0.0931\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 1.7809 - dice: 0.0905 - val_loss: 1.7326 - val_dice: 0.0932\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 3s 341ms/step - loss: 1.7810 - dice: 0.0901 - val_loss: 1.7315 - val_dice: 0.0934\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 1.7781 - dice: 0.0908 - val_loss: 1.7305 - val_dice: 0.0936\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 1.7787 - dice: 0.0904 - val_loss: 1.7295 - val_dice: 0.0938\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 1.7788 - dice: 0.0903 - val_loss: 1.7285 - val_dice: 0.0939\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 2s 248ms/step - loss: 1.7754 - dice: 0.0913 - val_loss: 1.7276 - val_dice: 0.0941\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 3s 369ms/step - loss: 1.7771 - dice: 0.0907 - val_loss: 1.7265 - val_dice: 0.0943\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 3s 343ms/step - loss: 1.7755 - dice: 0.0910 - val_loss: 1.7256 - val_dice: 0.0945\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 1.7743 - dice: 0.0912 - val_loss: 1.7246 - val_dice: 0.0946\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 2s 272ms/step - loss: 1.7724 - dice: 0.0915 - val_loss: 1.7236 - val_dice: 0.0948\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 2s 316ms/step - loss: 1.7711 - dice: 0.0917 - val_loss: 1.7226 - val_dice: 0.0950\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 3s 372ms/step - loss: 1.7690 - dice: 0.0923 - val_loss: 1.7217 - val_dice: 0.0952\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 1.7708 - dice: 0.0915 - val_loss: 1.7207 - val_dice: 0.0953\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 1.7661 - dice: 0.0924 - val_loss: 1.7198 - val_dice: 0.0955\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 1.7679 - dice: 0.0924 - val_loss: 1.7188 - val_dice: 0.0957\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 3s 342ms/step - loss: 1.7682 - dice: 0.0918 - val_loss: 1.7179 - val_dice: 0.0959\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 3s 379ms/step - loss: 1.7647 - dice: 0.0930 - val_loss: 1.7170 - val_dice: 0.0960\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 2s 291ms/step - loss: 1.7643 - dice: 0.0930 - val_loss: 1.7160 - val_dice: 0.0962\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 1.7621 - dice: 0.0932 - val_loss: 1.7151 - val_dice: 0.0964\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 1.7615 - dice: 0.0934 - val_loss: 1.7142 - val_dice: 0.0966\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 1.7612 - dice: 0.0934 - val_loss: 1.7133 - val_dice: 0.0967\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 3s 336ms/step - loss: 1.7600 - dice: 0.0936 - val_loss: 1.7124 - val_dice: 0.0969\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 2s 286ms/step - loss: 1.7593 - dice: 0.0934 - val_loss: 1.7116 - val_dice: 0.0971\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 2s 288ms/step - loss: 1.7565 - dice: 0.0943 - val_loss: 1.7107 - val_dice: 0.0972\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 1.7548 - dice: 0.0947 - val_loss: 1.7098 - val_dice: 0.0974\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 2s 289ms/step - loss: 1.7582 - dice: 0.0932 - val_loss: 1.7090 - val_dice: 0.0976\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 3s 381ms/step - loss: 1.7553 - dice: 0.0941 - val_loss: 1.7081 - val_dice: 0.0977\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 3s 349ms/step - loss: 1.7531 - dice: 0.0949 - val_loss: 1.7072 - val_dice: 0.0979\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 1.7535 - dice: 0.0948 - val_loss: 1.7064 - val_dice: 0.0981\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 1.7520 - dice: 0.0947 - val_loss: 1.7056 - val_dice: 0.0982\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 2s 305ms/step - loss: 1.7527 - dice: 0.0946 - val_loss: 1.7047 - val_dice: 0.0984\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 1.7516 - dice: 0.0950 - val_loss: 1.7039 - val_dice: 0.0986\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 3s 376ms/step - loss: 1.7487 - dice: 0.0956 - val_loss: 1.7031 - val_dice: 0.0987\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 1.7481 - dice: 0.0955 - val_loss: 1.7022 - val_dice: 0.0989\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 1.7474 - dice: 0.0958 - val_loss: 1.7014 - val_dice: 0.0991\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 1.7459 - dice: 0.0957 - val_loss: 1.7006 - val_dice: 0.0992\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 2s 305ms/step - loss: 1.7474 - dice: 0.0953 - val_loss: 1.6998 - val_dice: 0.0994\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 3s 403ms/step - loss: 1.7427 - dice: 0.0967 - val_loss: 1.6990 - val_dice: 0.0996\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 3s 317ms/step - loss: 1.7439 - dice: 0.0966 - val_loss: 1.6982 - val_dice: 0.0997\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.001, 'loss': <function DiceLoss at 0x7bcc24dc2680>, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>}\n",
            "Model: \"model_37\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_38 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_37 (Lambda)          (None, 256, 256, 3)          0         ['input_38[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_703 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_37[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_333 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_703[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_704 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_333[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_148 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_704[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_705 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_148[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_334 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_705[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_706 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_334[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_149 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_706[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_707 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_149[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_335 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_707[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_708 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_335[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_150 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_708[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_709 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_150[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_336 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_709[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_710 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_336[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_151 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_710[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_711 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_151[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_337 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_711[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_712 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_337[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_148 (Conv  (None, 32, 32, 128)          131200    ['conv2d_712[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_148 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_148[0][0]',\n",
            " te)                                                                 'conv2d_710[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_713 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_148[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_338 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_713[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_714 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_338[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_149 (Conv  (None, 64, 64, 64)           32832     ['conv2d_714[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_149 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_149[0][0]',\n",
            " te)                                                                 'conv2d_708[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_715 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_149[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_339 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_715[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_716 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_339[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_150 (Conv  (None, 128, 128, 32)         8224      ['conv2d_716[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_150 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_150[0][0]',\n",
            " te)                                                                 'conv2d_706[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_717 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_150[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_340 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_717[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_718 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_340[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_151 (Conv  (None, 256, 256, 16)         2064      ['conv2d_718[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_151 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_151[0][0]',\n",
            " te)                                                                 'conv2d_704[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_719 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_151[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_341 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_719[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_720 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_341[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_721 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_720[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 9s 878ms/step - loss: 0.7637 - dice: 0.2363 - val_loss: 0.5594 - val_dice: 0.4406\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 3s 719ms/step - loss: 0.4944 - dice: 0.5056 - val_loss: 0.4325 - val_dice: 0.5675\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.4537 - dice: 0.5463 - val_loss: 0.4290 - val_dice: 0.5710\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 0.4556 - dice: 0.5444 - val_loss: 0.4275 - val_dice: 0.5725\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 2s 648ms/step - loss: 0.4509 - dice: 0.5491 - val_loss: 0.4268 - val_dice: 0.5732\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.4581 - dice: 0.5419 - val_loss: 0.4265 - val_dice: 0.5735\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 3s 762ms/step - loss: 0.4599 - dice: 0.5401 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 3s 718ms/step - loss: 0.4595 - dice: 0.5405 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 0.4570 - dice: 0.5430 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 0.4549 - dice: 0.5451 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.4550 - dice: 0.5450 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 2s 635ms/step - loss: 0.4552 - dice: 0.5448 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 3s 801ms/step - loss: 0.4543 - dice: 0.5457 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 0.4557 - dice: 0.5443 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.4556 - dice: 0.5444 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 2s 643ms/step - loss: 0.4554 - dice: 0.5446 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 2s 615ms/step - loss: 0.4560 - dice: 0.5440 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 3s 706ms/step - loss: 0.4545 - dice: 0.5455 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 2s 602ms/step - loss: 0.4536 - dice: 0.5464 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.4546 - dice: 0.5454 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 0.4543 - dice: 0.5457 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.4488 - dice: 0.5512 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 2s 599ms/step - loss: 0.4560 - dice: 0.5440 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.4602 - dice: 0.5398 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.4550 - dice: 0.5450 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 0.4569 - dice: 0.5431 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.4536 - dice: 0.5464 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 2s 647ms/step - loss: 0.4578 - dice: 0.5422 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 3s 764ms/step - loss: 0.4565 - dice: 0.5435 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.4593 - dice: 0.5407 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 0.4588 - dice: 0.5412 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 0.4533 - dice: 0.5467 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 3s 719ms/step - loss: 0.4617 - dice: 0.5383 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.4522 - dice: 0.5478 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.4582 - dice: 0.5418 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.4556 - dice: 0.5444 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 2s 639ms/step - loss: 0.4593 - dice: 0.5407 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.4597 - dice: 0.5403 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 3s 686ms/step - loss: 0.4524 - dice: 0.5476 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.4582 - dice: 0.5418 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.4588 - dice: 0.5412 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.4573 - dice: 0.5427 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 2s 583ms/step - loss: 0.4554 - dice: 0.5446 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 3s 758ms/step - loss: 0.4592 - dice: 0.5408 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 3s 688ms/step - loss: 0.4559 - dice: 0.5441 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.4593 - dice: 0.5407 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 0.4537 - dice: 0.5463 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 2s 581ms/step - loss: 0.4514 - dice: 0.5486 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 0.4535 - dice: 0.5465 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.4537 - dice: 0.5463 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 3s 721ms/step - loss: 0.4524 - dice: 0.5476 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 0.4563 - dice: 0.5437 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 0.4573 - dice: 0.5427 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.4557 - dice: 0.5443 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 0.4548 - dice: 0.5452 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 0.4568 - dice: 0.5432 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.4578 - dice: 0.5422 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 0.4496 - dice: 0.5504 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.4623 - dice: 0.5377 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 2s 658ms/step - loss: 0.4534 - dice: 0.5466 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 3s 757ms/step - loss: 0.4567 - dice: 0.5433 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 0.4534 - dice: 0.5466 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.4562 - dice: 0.5438 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 0.4608 - dice: 0.5392 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 2s 574ms/step - loss: 0.4588 - dice: 0.5412 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 2s 630ms/step - loss: 0.4515 - dice: 0.5485 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 3s 760ms/step - loss: 0.4542 - dice: 0.5458 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 0.4598 - dice: 0.5402 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.4607 - dice: 0.5393 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 0.4603 - dice: 0.5397 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 3s 666ms/step - loss: 0.4498 - dice: 0.5502 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.4574 - dice: 0.5426 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.4575 - dice: 0.5425 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 2s 582ms/step - loss: 0.4594 - dice: 0.5406 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.4568 - dice: 0.5432 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 2s 590ms/step - loss: 0.4554 - dice: 0.5446 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.4535 - dice: 0.5465 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 0.4564 - dice: 0.5436 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 0.4515 - dice: 0.5485 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.4570 - dice: 0.5430 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 3s 669ms/step - loss: 0.4567 - dice: 0.5433 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 3s 783ms/step - loss: 0.4534 - dice: 0.5466 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 0.4532 - dice: 0.5468 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 0.4597 - dice: 0.5403 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 2s 587ms/step - loss: 0.4580 - dice: 0.5420 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.4577 - dice: 0.5423 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 3s 670ms/step - loss: 0.4549 - dice: 0.5451 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.4602 - dice: 0.5398 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 0.4566 - dice: 0.5434 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 0.4554 - dice: 0.5446 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 0.4596 - dice: 0.5404 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 0.4543 - dice: 0.5457 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 3s 765ms/step - loss: 0.4592 - dice: 0.5408 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.4607 - dice: 0.5393 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.4507 - dice: 0.5493 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 0.4583 - dice: 0.5417 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 2s 577ms/step - loss: 0.4570 - dice: 0.5430 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.4563 - dice: 0.5437 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 0.4530 - dice: 0.5470 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.4570 - dice: 0.5430 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.001, 'loss': <function DiceLoss at 0x7bcc24dc2680>, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>}\n",
            "Model: \"model_38\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_39 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_38 (Lambda)          (None, 256, 256, 3)          0         ['input_39[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_722 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_38[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_342 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_722[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_723 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_342[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_152 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_723[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_724 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_152[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_343 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_724[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_725 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_343[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_153 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_725[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_726 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_153[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_344 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_726[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_727 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_344[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_154 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_727[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_728 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_154[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_345 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_728[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_729 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_345[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_155 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_729[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_730 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_155[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_346 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_730[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_731 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_346[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_152 (Conv  (None, 32, 32, 128)          131200    ['conv2d_731[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_152 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_152[0][0]',\n",
            " te)                                                                 'conv2d_729[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_732 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_152[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_347 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_732[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_733 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_347[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_153 (Conv  (None, 64, 64, 64)           32832     ['conv2d_733[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_153 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_153[0][0]',\n",
            " te)                                                                 'conv2d_727[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_734 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_153[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_348 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_734[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_735 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_348[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_154 (Conv  (None, 128, 128, 32)         8224      ['conv2d_735[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_154 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_154[0][0]',\n",
            " te)                                                                 'conv2d_725[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_736 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_154[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_349 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_736[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_737 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_349[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_155 (Conv  (None, 256, 256, 16)         2064      ['conv2d_737[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_155 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_155[0][0]',\n",
            " te)                                                                 'conv2d_723[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_738 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_155[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_350 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_738[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_739 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_350[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_740 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_739[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 11s 635ms/step - loss: 0.8815 - dice: 0.1185 - val_loss: 0.7797 - val_dice: 0.2203\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 0.7507 - dice: 0.2493 - val_loss: 0.6871 - val_dice: 0.3129\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 574ms/step - loss: 0.6628 - dice: 0.3372 - val_loss: 0.6131 - val_dice: 0.3869\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 2s 586ms/step - loss: 0.6018 - dice: 0.3982 - val_loss: 0.5588 - val_dice: 0.4412\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 3s 766ms/step - loss: 0.5528 - dice: 0.4472 - val_loss: 0.5030 - val_dice: 0.4970\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 0.5048 - dice: 0.4952 - val_loss: 0.4593 - val_dice: 0.5407\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.4636 - dice: 0.5364 - val_loss: 0.4406 - val_dice: 0.5594\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.4206 - dice: 0.5794 - val_loss: 0.4079 - val_dice: 0.5921\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 3s 661ms/step - loss: 0.3688 - dice: 0.6312 - val_loss: 0.3502 - val_dice: 0.6498\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 3s 792ms/step - loss: 0.3361 - dice: 0.6639 - val_loss: 0.3457 - val_dice: 0.6543\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.3243 - dice: 0.6757 - val_loss: 0.3500 - val_dice: 0.6500\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.3321 - dice: 0.6679 - val_loss: 0.3396 - val_dice: 0.6604\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 0.3089 - dice: 0.6911 - val_loss: 0.3193 - val_dice: 0.6807\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 0.3090 - dice: 0.6910 - val_loss: 0.3309 - val_dice: 0.6691\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 2s 640ms/step - loss: 0.3020 - dice: 0.6980 - val_loss: 0.3054 - val_dice: 0.6946\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 3s 734ms/step - loss: 0.3007 - dice: 0.6993 - val_loss: 0.3171 - val_dice: 0.6829\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 0.3014 - dice: 0.6986 - val_loss: 0.3133 - val_dice: 0.6867\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.001, 'loss': <function DiceLoss at 0x7bcc24dc2680>, 'optimizer': <class 'keras.src.optimizers.sgd.SGD'>}\n",
            "Model: \"model_39\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_40 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_39 (Lambda)          (None, 256, 256, 3)          0         ['input_40[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_741 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_39[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_351 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_741[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_742 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_351[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_156 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_742[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_743 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_156[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_352 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_743[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_744 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_352[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_157 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_744[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_745 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_157[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_353 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_745[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_746 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_353[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_158 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_746[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_747 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_158[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_354 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_747[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_748 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_354[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_159 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_748[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_749 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_159[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_355 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_749[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_750 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_355[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_156 (Conv  (None, 32, 32, 128)          131200    ['conv2d_750[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_156 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_156[0][0]',\n",
            " te)                                                                 'conv2d_748[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_751 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_156[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_356 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_751[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_752 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_356[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_157 (Conv  (None, 64, 64, 64)           32832     ['conv2d_752[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_157 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_157[0][0]',\n",
            " te)                                                                 'conv2d_746[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_753 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_157[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_357 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_753[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_754 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_357[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_158 (Conv  (None, 128, 128, 32)         8224      ['conv2d_754[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_158 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_158[0][0]',\n",
            " te)                                                                 'conv2d_744[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_755 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_158[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_358 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_755[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_756 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_358[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_159 (Conv  (None, 256, 256, 16)         2064      ['conv2d_756[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_159 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_159[0][0]',\n",
            " te)                                                                 'conv2d_742[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_757 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_159[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_359 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_757[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_758 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_359[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_759 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_758[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 7s 831ms/step - loss: 0.9005 - dice: 0.0995 - val_loss: 0.9036 - val_dice: 0.0964\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 3s 677ms/step - loss: 0.9002 - dice: 0.0998 - val_loss: 0.9034 - val_dice: 0.0966\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 0.9000 - dice: 0.1000 - val_loss: 0.9031 - val_dice: 0.0969\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 2s 632ms/step - loss: 0.8997 - dice: 0.1003 - val_loss: 0.9029 - val_dice: 0.0971\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 2s 635ms/step - loss: 0.8997 - dice: 0.1003 - val_loss: 0.9027 - val_dice: 0.0973\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.8991 - dice: 0.1009 - val_loss: 0.9025 - val_dice: 0.0975\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 3s 633ms/step - loss: 0.8990 - dice: 0.1010 - val_loss: 0.9023 - val_dice: 0.0977\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.8986 - dice: 0.1014 - val_loss: 0.9021 - val_dice: 0.0979\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 0.8984 - dice: 0.1016 - val_loss: 0.9018 - val_dice: 0.0982\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 2s 584ms/step - loss: 0.8984 - dice: 0.1016 - val_loss: 0.9016 - val_dice: 0.0984\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.8981 - dice: 0.1019 - val_loss: 0.9014 - val_dice: 0.0986\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.8977 - dice: 0.1023 - val_loss: 0.9012 - val_dice: 0.0988\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 0.8976 - dice: 0.1024 - val_loss: 0.9009 - val_dice: 0.0991\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.8972 - dice: 0.1028 - val_loss: 0.9007 - val_dice: 0.0993\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 2s 608ms/step - loss: 0.8969 - dice: 0.1031 - val_loss: 0.9005 - val_dice: 0.0995\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 0.8966 - dice: 0.1034 - val_loss: 0.9002 - val_dice: 0.0998\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 2s 624ms/step - loss: 0.8962 - dice: 0.1038 - val_loss: 0.9000 - val_dice: 0.1000\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.8962 - dice: 0.1038 - val_loss: 0.8998 - val_dice: 0.1002\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 0.8960 - dice: 0.1040 - val_loss: 0.8995 - val_dice: 0.1005\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 2s 643ms/step - loss: 0.8958 - dice: 0.1042 - val_loss: 0.8993 - val_dice: 0.1007\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 0.8957 - dice: 0.1043 - val_loss: 0.8990 - val_dice: 0.1010\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 2s 578ms/step - loss: 0.8949 - dice: 0.1051 - val_loss: 0.8988 - val_dice: 0.1012\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 2s 578ms/step - loss: 0.8948 - dice: 0.1052 - val_loss: 0.8985 - val_dice: 0.1015\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 0.8947 - dice: 0.1053 - val_loss: 0.8983 - val_dice: 0.1017\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.8943 - dice: 0.1057 - val_loss: 0.8980 - val_dice: 0.1020\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 2s 598ms/step - loss: 0.8937 - dice: 0.1063 - val_loss: 0.8977 - val_dice: 0.1023\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 3s 764ms/step - loss: 0.8937 - dice: 0.1063 - val_loss: 0.8975 - val_dice: 0.1025\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 0.8932 - dice: 0.1068 - val_loss: 0.8972 - val_dice: 0.1028\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 0.8929 - dice: 0.1071 - val_loss: 0.8969 - val_dice: 0.1031\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 2s 626ms/step - loss: 0.8927 - dice: 0.1073 - val_loss: 0.8966 - val_dice: 0.1034\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 2s 631ms/step - loss: 0.8923 - dice: 0.1077 - val_loss: 0.8964 - val_dice: 0.1036\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 3s 757ms/step - loss: 0.8919 - dice: 0.1081 - val_loss: 0.8961 - val_dice: 0.1039\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.8918 - dice: 0.1082 - val_loss: 0.8958 - val_dice: 0.1042\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.8910 - dice: 0.1090 - val_loss: 0.8955 - val_dice: 0.1045\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 0.8909 - dice: 0.1091 - val_loss: 0.8952 - val_dice: 0.1048\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 2s 647ms/step - loss: 0.8907 - dice: 0.1093 - val_loss: 0.8949 - val_dice: 0.1051\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.8905 - dice: 0.1095 - val_loss: 0.8946 - val_dice: 0.1054\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 2s 598ms/step - loss: 0.8899 - dice: 0.1101 - val_loss: 0.8943 - val_dice: 0.1057\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 0.8892 - dice: 0.1108 - val_loss: 0.8940 - val_dice: 0.1060\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 0.8889 - dice: 0.1111 - val_loss: 0.8936 - val_dice: 0.1064\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.8890 - dice: 0.1110 - val_loss: 0.8933 - val_dice: 0.1067\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 2s 601ms/step - loss: 0.8885 - dice: 0.1115 - val_loss: 0.8930 - val_dice: 0.1070\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.8881 - dice: 0.1119 - val_loss: 0.8926 - val_dice: 0.1074\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.8876 - dice: 0.1124 - val_loss: 0.8923 - val_dice: 0.1077\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 0.8873 - dice: 0.1127 - val_loss: 0.8919 - val_dice: 0.1081\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 0.8867 - dice: 0.1133 - val_loss: 0.8916 - val_dice: 0.1084\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 3s 672ms/step - loss: 0.8862 - dice: 0.1138 - val_loss: 0.8912 - val_dice: 0.1088\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 0.8862 - dice: 0.1138 - val_loss: 0.8908 - val_dice: 0.1092\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 0.8860 - dice: 0.1140 - val_loss: 0.8905 - val_dice: 0.1095\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.8850 - dice: 0.1150 - val_loss: 0.8901 - val_dice: 0.1099\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 0.8848 - dice: 0.1152 - val_loss: 0.8897 - val_dice: 0.1103\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 0.8845 - dice: 0.1155 - val_loss: 0.8893 - val_dice: 0.1107\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.8841 - dice: 0.1159 - val_loss: 0.8889 - val_dice: 0.1111\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.8835 - dice: 0.1165 - val_loss: 0.8885 - val_dice: 0.1115\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 2s 574ms/step - loss: 0.8832 - dice: 0.1168 - val_loss: 0.8880 - val_dice: 0.1120\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 0.8825 - dice: 0.1175 - val_loss: 0.8876 - val_dice: 0.1124\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.8821 - dice: 0.1179 - val_loss: 0.8872 - val_dice: 0.1128\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 3s 717ms/step - loss: 0.8816 - dice: 0.1184 - val_loss: 0.8867 - val_dice: 0.1133\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 0.8809 - dice: 0.1191 - val_loss: 0.8862 - val_dice: 0.1138\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 2s 639ms/step - loss: 0.8805 - dice: 0.1195 - val_loss: 0.8858 - val_dice: 0.1142\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.8798 - dice: 0.1202 - val_loss: 0.8853 - val_dice: 0.1147\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 0.8796 - dice: 0.1204 - val_loss: 0.8848 - val_dice: 0.1152\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 2s 574ms/step - loss: 0.8784 - dice: 0.1216 - val_loss: 0.8842 - val_dice: 0.1158\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 3s 731ms/step - loss: 0.8777 - dice: 0.1223 - val_loss: 0.8837 - val_dice: 0.1163\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 3s 711ms/step - loss: 0.8773 - dice: 0.1227 - val_loss: 0.8831 - val_dice: 0.1169\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 0.8770 - dice: 0.1230 - val_loss: 0.8826 - val_dice: 0.1174\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 0.8761 - dice: 0.1239 - val_loss: 0.8820 - val_dice: 0.1180\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 0.8755 - dice: 0.1245 - val_loss: 0.8814 - val_dice: 0.1186\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 3s 711ms/step - loss: 0.8756 - dice: 0.1244 - val_loss: 0.8808 - val_dice: 0.1192\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.8747 - dice: 0.1253 - val_loss: 0.8802 - val_dice: 0.1198\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 0.8743 - dice: 0.1257 - val_loss: 0.8795 - val_dice: 0.1205\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 0.8731 - dice: 0.1269 - val_loss: 0.8789 - val_dice: 0.1211\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 0.8718 - dice: 0.1282 - val_loss: 0.8782 - val_dice: 0.1218\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.8717 - dice: 0.1283 - val_loss: 0.8775 - val_dice: 0.1225\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 0.8709 - dice: 0.1291 - val_loss: 0.8768 - val_dice: 0.1232\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.8694 - dice: 0.1306 - val_loss: 0.8760 - val_dice: 0.1240\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 0.8693 - dice: 0.1307 - val_loss: 0.8752 - val_dice: 0.1248\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 2s 615ms/step - loss: 0.8684 - dice: 0.1316 - val_loss: 0.8744 - val_dice: 0.1256\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 3s 716ms/step - loss: 0.8671 - dice: 0.1329 - val_loss: 0.8736 - val_dice: 0.1264\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.8670 - dice: 0.1330 - val_loss: 0.8727 - val_dice: 0.1273\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.8656 - dice: 0.1344 - val_loss: 0.8718 - val_dice: 0.1282\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 0.8655 - dice: 0.1345 - val_loss: 0.8710 - val_dice: 0.1290\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 2s 648ms/step - loss: 0.8634 - dice: 0.1366 - val_loss: 0.8700 - val_dice: 0.1300\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 0.8625 - dice: 0.1375 - val_loss: 0.8690 - val_dice: 0.1310\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 2s 577ms/step - loss: 0.8621 - dice: 0.1379 - val_loss: 0.8680 - val_dice: 0.1320\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.8612 - dice: 0.1388 - val_loss: 0.8670 - val_dice: 0.1330\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 0.8587 - dice: 0.1413 - val_loss: 0.8659 - val_dice: 0.1342\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 3s 725ms/step - loss: 0.8593 - dice: 0.1407 - val_loss: 0.8648 - val_dice: 0.1352\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.8582 - dice: 0.1418 - val_loss: 0.8636 - val_dice: 0.1364\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.8565 - dice: 0.1435 - val_loss: 0.8624 - val_dice: 0.1376\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.8543 - dice: 0.1457 - val_loss: 0.8612 - val_dice: 0.1388\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 0.8543 - dice: 0.1457 - val_loss: 0.8599 - val_dice: 0.1401\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 3s 722ms/step - loss: 0.8526 - dice: 0.1474 - val_loss: 0.8585 - val_dice: 0.1415\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 3s 703ms/step - loss: 0.8513 - dice: 0.1487 - val_loss: 0.8572 - val_dice: 0.1428\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 0.8498 - dice: 0.1502 - val_loss: 0.8558 - val_dice: 0.1442\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.8481 - dice: 0.1519 - val_loss: 0.8543 - val_dice: 0.1457\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 2s 621ms/step - loss: 0.8478 - dice: 0.1522 - val_loss: 0.8528 - val_dice: 0.1472\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 0.8464 - dice: 0.1536 - val_loss: 0.8513 - val_dice: 0.1487\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 3s 795ms/step - loss: 0.8444 - dice: 0.1556 - val_loss: 0.8497 - val_dice: 0.1503\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.8439 - dice: 0.1561 - val_loss: 0.8481 - val_dice: 0.1519\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.001, 'loss': <function categorical_cross_entropy_loss at 0x7bccb964dcf0>, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>}\n",
            "Model: \"model_40\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_41 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_40 (Lambda)          (None, 256, 256, 3)          0         ['input_41[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_760 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_40[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_360 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_760[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_761 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_360[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_160 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_761[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_762 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_160[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_361 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_762[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_763 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_361[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_161 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_763[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_764 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_161[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_362 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_764[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_765 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_362[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_162 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_765[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_766 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_162[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_363 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_766[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_767 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_363[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_163 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_767[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_768 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_163[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_364 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_768[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_769 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_364[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_160 (Conv  (None, 32, 32, 128)          131200    ['conv2d_769[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_160 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_160[0][0]',\n",
            " te)                                                                 'conv2d_767[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_770 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_160[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_365 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_770[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_771 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_365[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_161 (Conv  (None, 64, 64, 64)           32832     ['conv2d_771[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_161 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_161[0][0]',\n",
            " te)                                                                 'conv2d_765[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_772 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_161[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_366 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_772[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_773 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_366[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_162 (Conv  (None, 128, 128, 32)         8224      ['conv2d_773[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_162 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_162[0][0]',\n",
            " te)                                                                 'conv2d_763[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_774 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_162[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_367 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_774[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_775 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_367[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_163 (Conv  (None, 256, 256, 16)         2064      ['conv2d_775[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_163 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_163[0][0]',\n",
            " te)                                                                 'conv2d_761[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_776 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_163[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_368 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_776[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_777 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_368[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_778 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_777[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 8s 880ms/step - loss: 2.2609 - dice: 0.1973 - val_loss: 1.7111 - val_dice: 0.2670\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 3s 634ms/step - loss: 1.6814 - dice: 0.3154 - val_loss: 1.4303 - val_dice: 0.3505\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 1.6288 - dice: 0.3473 - val_loss: 1.4392 - val_dice: 0.3422\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 2s 616ms/step - loss: 1.4899 - dice: 0.3521 - val_loss: 1.3892 - val_dice: 0.3898\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 2s 615ms/step - loss: 1.4216 - dice: 0.3825 - val_loss: 1.3182 - val_dice: 0.4137\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 3s 732ms/step - loss: 1.3869 - dice: 0.3906 - val_loss: 1.3597 - val_dice: 0.4670\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 2s 605ms/step - loss: 1.4275 - dice: 0.4002 - val_loss: 1.2990 - val_dice: 0.4217\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 1.3840 - dice: 0.4015 - val_loss: 1.2967 - val_dice: 0.4604\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 1.3862 - dice: 0.4028 - val_loss: 1.2904 - val_dice: 0.4529\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.3283 - dice: 0.4246 - val_loss: 1.2640 - val_dice: 0.4614\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 3s 702ms/step - loss: 1.2900 - dice: 0.4437 - val_loss: 1.2457 - val_dice: 0.4975\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 1.4216 - dice: 0.4512 - val_loss: 1.3490 - val_dice: 0.3682\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 1.3094 - dice: 0.4082 - val_loss: 1.2429 - val_dice: 0.4800\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.2800 - dice: 0.4442 - val_loss: 1.2113 - val_dice: 0.4856\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 1.3080 - dice: 0.4461 - val_loss: 1.1979 - val_dice: 0.4511\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 1.2319 - dice: 0.4569 - val_loss: 1.1563 - val_dice: 0.4998\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 1.3398 - dice: 0.4463 - val_loss: 1.3223 - val_dice: 0.4725\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 1.2844 - dice: 0.4449 - val_loss: 1.1652 - val_dice: 0.5074\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.001, 'loss': <function categorical_cross_entropy_loss at 0x7bccb964dcf0>, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>}\n",
            "Model: \"model_41\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_42 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_41 (Lambda)          (None, 256, 256, 3)          0         ['input_42[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_779 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_41[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_369 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_779[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_780 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_369[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_164 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_780[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_781 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_164[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_370 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_781[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_782 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_370[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_165 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_782[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_783 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_165[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_371 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_783[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_784 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_371[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_166 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_784[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_785 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_166[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_372 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_785[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_786 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_372[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_167 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_786[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_787 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_167[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_373 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_787[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_788 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_373[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_164 (Conv  (None, 32, 32, 128)          131200    ['conv2d_788[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_164 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_164[0][0]',\n",
            " te)                                                                 'conv2d_786[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_789 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_164[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_374 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_789[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_790 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_374[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_165 (Conv  (None, 64, 64, 64)           32832     ['conv2d_790[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_165 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_165[0][0]',\n",
            " te)                                                                 'conv2d_784[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_791 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_165[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_375 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_791[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_792 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_375[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_166 (Conv  (None, 128, 128, 32)         8224      ['conv2d_792[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_166 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_166[0][0]',\n",
            " te)                                                                 'conv2d_782[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_793 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_166[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_376 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_793[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_794 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_376[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_167 (Conv  (None, 256, 256, 16)         2064      ['conv2d_794[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_167 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_167[0][0]',\n",
            " te)                                                                 'conv2d_780[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_795 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_167[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_377 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_795[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_796 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_377[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_797 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_796[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 11s 648ms/step - loss: 2.1127 - dice: 0.1806 - val_loss: 1.6411 - val_dice: 0.2949\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 1.5905 - dice: 0.3446 - val_loss: 1.4893 - val_dice: 0.3811\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 1.5039 - dice: 0.3914 - val_loss: 1.5087 - val_dice: 0.3199\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 1.4571 - dice: 0.3796 - val_loss: 1.4556 - val_dice: 0.3345\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 3s 763ms/step - loss: 1.3989 - dice: 0.3763 - val_loss: 1.3651 - val_dice: 0.3860\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 3s 695ms/step - loss: 1.3507 - dice: 0.4116 - val_loss: 1.3094 - val_dice: 0.4066\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 1.3113 - dice: 0.4251 - val_loss: 1.3929 - val_dice: 0.4913\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.2488 - dice: 0.4829 - val_loss: 1.3306 - val_dice: 0.4785\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.001, 'loss': <function categorical_cross_entropy_loss at 0x7bccb964dcf0>, 'optimizer': <class 'keras.src.optimizers.sgd.SGD'>}\n",
            "Model: \"model_42\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_43 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_42 (Lambda)          (None, 256, 256, 3)          0         ['input_43[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_798 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_42[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_378 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_798[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_799 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_378[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_168 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_799[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_800 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_168[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_379 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_800[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_801 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_379[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_169 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_801[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_802 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_169[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_380 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_802[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_803 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_380[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_170 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_803[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_804 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_170[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_381 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_804[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_805 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_381[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_171 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_805[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_806 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_171[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_382 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_806[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_807 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_382[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_168 (Conv  (None, 32, 32, 128)          131200    ['conv2d_807[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_168 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_168[0][0]',\n",
            " te)                                                                 'conv2d_805[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_808 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_168[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_383 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_808[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_809 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_383[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_169 (Conv  (None, 64, 64, 64)           32832     ['conv2d_809[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_169 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_169[0][0]',\n",
            " te)                                                                 'conv2d_803[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_810 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_169[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_384 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_810[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_811 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_384[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_170 (Conv  (None, 128, 128, 32)         8224      ['conv2d_811[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_170 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_170[0][0]',\n",
            " te)                                                                 'conv2d_801[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_812 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_170[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_385 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_812[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_813 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_385[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_171 (Conv  (None, 256, 256, 16)         2064      ['conv2d_813[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_171 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_171[0][0]',\n",
            " te)                                                                 'conv2d_799[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_814 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_171[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_386 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_814[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_815 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_386[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_816 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_815[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 8s 661ms/step - loss: 3.5917 - dice: 0.0656 - val_loss: 3.1206 - val_dice: 0.0685\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 3.1464 - dice: 0.0747 - val_loss: 2.8038 - val_dice: 0.0783\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 2.8658 - dice: 0.0846 - val_loss: 2.6038 - val_dice: 0.0885\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 2s 581ms/step - loss: 2.6805 - dice: 0.0948 - val_loss: 2.4735 - val_dice: 0.0978\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 3s 771ms/step - loss: 2.5514 - dice: 0.1040 - val_loss: 2.3857 - val_dice: 0.1057\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 3s 676ms/step - loss: 2.4623 - dice: 0.1118 - val_loss: 2.3208 - val_dice: 0.1125\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 2.3935 - dice: 0.1188 - val_loss: 2.2706 - val_dice: 0.1184\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 2.3423 - dice: 0.1244 - val_loss: 2.2301 - val_dice: 0.1234\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 2.2918 - dice: 0.1308 - val_loss: 2.1942 - val_dice: 0.1282\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 2.2527 - dice: 0.1364 - val_loss: 2.1623 - val_dice: 0.1326\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 2.2185 - dice: 0.1412 - val_loss: 2.1336 - val_dice: 0.1368\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 2.1869 - dice: 0.1459 - val_loss: 2.1066 - val_dice: 0.1410\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 2.1484 - dice: 0.1516 - val_loss: 2.0808 - val_dice: 0.1452\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 2.1267 - dice: 0.1558 - val_loss: 2.0564 - val_dice: 0.1493\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 2s 630ms/step - loss: 2.0950 - dice: 0.1615 - val_loss: 2.0329 - val_dice: 0.1535\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 3s 759ms/step - loss: 2.0754 - dice: 0.1660 - val_loss: 2.0100 - val_dice: 0.1577\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 3s 621ms/step - loss: 2.0476 - dice: 0.1714 - val_loss: 1.9881 - val_dice: 0.1620\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 2.0217 - dice: 0.1769 - val_loss: 1.9665 - val_dice: 0.1664\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 2.0059 - dice: 0.1809 - val_loss: 1.9457 - val_dice: 0.1709\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.9829 - dice: 0.1862 - val_loss: 1.9260 - val_dice: 0.1753\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 2s 624ms/step - loss: 1.9627 - dice: 0.1914 - val_loss: 1.9065 - val_dice: 0.1800\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 3s 761ms/step - loss: 1.9405 - dice: 0.1964 - val_loss: 1.8873 - val_dice: 0.1847\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 2s 585ms/step - loss: 1.9227 - dice: 0.2016 - val_loss: 1.8689 - val_dice: 0.1896\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.9038 - dice: 0.2075 - val_loss: 1.8510 - val_dice: 0.1945\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.8858 - dice: 0.2116 - val_loss: 1.8338 - val_dice: 0.1994\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.8754 - dice: 0.2169 - val_loss: 1.8176 - val_dice: 0.2043\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 2s 646ms/step - loss: 1.8615 - dice: 0.2221 - val_loss: 1.8020 - val_dice: 0.2092\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 1.8410 - dice: 0.2287 - val_loss: 1.7872 - val_dice: 0.2141\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 1.8319 - dice: 0.2317 - val_loss: 1.7733 - val_dice: 0.2189\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.8152 - dice: 0.2383 - val_loss: 1.7598 - val_dice: 0.2238\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 1.8022 - dice: 0.2429 - val_loss: 1.7470 - val_dice: 0.2286\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 1.7894 - dice: 0.2476 - val_loss: 1.7349 - val_dice: 0.2333\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 2s 620ms/step - loss: 1.7758 - dice: 0.2531 - val_loss: 1.7234 - val_dice: 0.2380\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 3s 716ms/step - loss: 1.7660 - dice: 0.2575 - val_loss: 1.7126 - val_dice: 0.2425\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 3s 611ms/step - loss: 1.7498 - dice: 0.2629 - val_loss: 1.7023 - val_dice: 0.2470\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 1.7429 - dice: 0.2672 - val_loss: 1.6928 - val_dice: 0.2513\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 1.7377 - dice: 0.2705 - val_loss: 1.6839 - val_dice: 0.2554\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.7316 - dice: 0.2738 - val_loss: 1.6755 - val_dice: 0.2594\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 3s 694ms/step - loss: 1.7111 - dice: 0.2808 - val_loss: 1.6673 - val_dice: 0.2634\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 1.7086 - dice: 0.2849 - val_loss: 1.6601 - val_dice: 0.2670\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 1.7169 - dice: 0.2861 - val_loss: 1.6536 - val_dice: 0.2703\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 1.6980 - dice: 0.2916 - val_loss: 1.6473 - val_dice: 0.2736\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 1.6965 - dice: 0.2930 - val_loss: 1.6415 - val_dice: 0.2767\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 1.7024 - dice: 0.2943 - val_loss: 1.6361 - val_dice: 0.2794\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 3s 687ms/step - loss: 1.6868 - dice: 0.3002 - val_loss: 1.6311 - val_dice: 0.2822\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 1.6853 - dice: 0.2983 - val_loss: 1.6259 - val_dice: 0.2851\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 1.6806 - dice: 0.3053 - val_loss: 1.6216 - val_dice: 0.2874\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 1.6721 - dice: 0.3070 - val_loss: 1.6172 - val_dice: 0.2899\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 2s 620ms/step - loss: 1.6820 - dice: 0.3067 - val_loss: 1.6133 - val_dice: 0.2919\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 3s 720ms/step - loss: 1.6668 - dice: 0.3114 - val_loss: 1.6093 - val_dice: 0.2941\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 1.6697 - dice: 0.3134 - val_loss: 1.6059 - val_dice: 0.2959\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.6580 - dice: 0.3150 - val_loss: 1.6023 - val_dice: 0.2978\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 1.6376 - dice: 0.3192 - val_loss: 1.5984 - val_dice: 0.3000\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 2s 612ms/step - loss: 1.6443 - dice: 0.3204 - val_loss: 1.5951 - val_dice: 0.3019\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 1.6446 - dice: 0.3224 - val_loss: 1.5921 - val_dice: 0.3036\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 1.6381 - dice: 0.3234 - val_loss: 1.5890 - val_dice: 0.3054\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 1.6414 - dice: 0.3253 - val_loss: 1.5863 - val_dice: 0.3068\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 1.6471 - dice: 0.3225 - val_loss: 1.5835 - val_dice: 0.3082\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 3s 734ms/step - loss: 1.6561 - dice: 0.3224 - val_loss: 1.5811 - val_dice: 0.3093\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 1.6388 - dice: 0.3267 - val_loss: 1.5785 - val_dice: 0.3106\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.6358 - dice: 0.3292 - val_loss: 1.5761 - val_dice: 0.3117\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.6317 - dice: 0.3290 - val_loss: 1.5736 - val_dice: 0.3130\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.6174 - dice: 0.3330 - val_loss: 1.5711 - val_dice: 0.3142\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 1.6298 - dice: 0.3316 - val_loss: 1.5690 - val_dice: 0.3152\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.6246 - dice: 0.3332 - val_loss: 1.5668 - val_dice: 0.3161\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 1.6162 - dice: 0.3357 - val_loss: 1.5645 - val_dice: 0.3172\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 1.6229 - dice: 0.3343 - val_loss: 1.5625 - val_dice: 0.3181\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 2s 611ms/step - loss: 1.6151 - dice: 0.3363 - val_loss: 1.5603 - val_dice: 0.3191\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 3s 710ms/step - loss: 1.6299 - dice: 0.3345 - val_loss: 1.5585 - val_dice: 0.3197\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 2s 614ms/step - loss: 1.6041 - dice: 0.3399 - val_loss: 1.5564 - val_dice: 0.3207\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 1.6058 - dice: 0.3378 - val_loss: 1.5541 - val_dice: 0.3218\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 2s 585ms/step - loss: 1.6172 - dice: 0.3376 - val_loss: 1.5523 - val_dice: 0.3225\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 1.5970 - dice: 0.3430 - val_loss: 1.5505 - val_dice: 0.3233\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 2s 659ms/step - loss: 1.6009 - dice: 0.3402 - val_loss: 1.5486 - val_dice: 0.3242\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 3s 713ms/step - loss: 1.6054 - dice: 0.3408 - val_loss: 1.5468 - val_dice: 0.3249\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.6083 - dice: 0.3415 - val_loss: 1.5451 - val_dice: 0.3254\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.5964 - dice: 0.3442 - val_loss: 1.5433 - val_dice: 0.3261\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 1.5840 - dice: 0.3467 - val_loss: 1.5415 - val_dice: 0.3269\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 2s 639ms/step - loss: 1.6044 - dice: 0.3410 - val_loss: 1.5398 - val_dice: 0.3274\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 1.5928 - dice: 0.3439 - val_loss: 1.5380 - val_dice: 0.3282\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 2s 581ms/step - loss: 1.5872 - dice: 0.3455 - val_loss: 1.5362 - val_dice: 0.3289\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.5794 - dice: 0.3484 - val_loss: 1.5345 - val_dice: 0.3297\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 2s 641ms/step - loss: 1.5897 - dice: 0.3456 - val_loss: 1.5328 - val_dice: 0.3304\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 2s 621ms/step - loss: 1.5852 - dice: 0.3474 - val_loss: 1.5312 - val_dice: 0.3310\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 3s 760ms/step - loss: 1.5889 - dice: 0.3470 - val_loss: 1.5296 - val_dice: 0.3314\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 2s 574ms/step - loss: 1.5779 - dice: 0.3491 - val_loss: 1.5280 - val_dice: 0.3320\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 1.5886 - dice: 0.3454 - val_loss: 1.5265 - val_dice: 0.3326\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 1.5723 - dice: 0.3511 - val_loss: 1.5249 - val_dice: 0.3331\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.5740 - dice: 0.3496 - val_loss: 1.5232 - val_dice: 0.3338\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 2s 647ms/step - loss: 1.5646 - dice: 0.3531 - val_loss: 1.5216 - val_dice: 0.3344\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 3s 752ms/step - loss: 1.5646 - dice: 0.3526 - val_loss: 1.5201 - val_dice: 0.3351\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 2s 591ms/step - loss: 1.5652 - dice: 0.3538 - val_loss: 1.5186 - val_dice: 0.3355\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 1.5661 - dice: 0.3538 - val_loss: 1.5173 - val_dice: 0.3359\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.5613 - dice: 0.3534 - val_loss: 1.5159 - val_dice: 0.3366\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.5701 - dice: 0.3526 - val_loss: 1.5146 - val_dice: 0.3370\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 3s 709ms/step - loss: 1.5676 - dice: 0.3513 - val_loss: 1.5132 - val_dice: 0.3375\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 1.5691 - dice: 0.3529 - val_loss: 1.5119 - val_dice: 0.3378\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.5819 - dice: 0.3477 - val_loss: 1.5105 - val_dice: 0.3381\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 1.5609 - dice: 0.3540 - val_loss: 1.5091 - val_dice: 0.3385\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.5655 - dice: 0.3543 - val_loss: 1.5080 - val_dice: 0.3388\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.001, 'loss': <function DiceBCELoss at 0x7bcc24dc25f0>, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>}\n",
            "Model: \"model_43\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_44 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_43 (Lambda)          (None, 256, 256, 3)          0         ['input_44[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_817 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_43[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_387 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_817[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_818 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_387[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_172 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_818[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_819 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_172[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_388 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_819[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_820 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_388[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_173 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_820[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_821 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_173[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_389 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_821[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_822 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_389[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_174 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_822[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_823 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_174[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_390 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_823[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_824 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_390[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_175 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_824[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_825 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_175[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_391 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_825[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_826 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_391[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_172 (Conv  (None, 32, 32, 128)          131200    ['conv2d_826[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_172 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_172[0][0]',\n",
            " te)                                                                 'conv2d_824[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_827 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_172[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_392 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_827[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_828 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_392[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_173 (Conv  (None, 64, 64, 64)           32832     ['conv2d_828[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_173 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_173[0][0]',\n",
            " te)                                                                 'conv2d_822[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_829 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_173[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_393 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_829[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_830 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_393[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_174 (Conv  (None, 128, 128, 32)         8224      ['conv2d_830[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_174 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_174[0][0]',\n",
            " te)                                                                 'conv2d_820[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_831 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_174[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_394 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_831[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_832 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_394[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_175 (Conv  (None, 256, 256, 16)         2064      ['conv2d_832[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_175 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_175[0][0]',\n",
            " te)                                                                 'conv2d_818[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_833 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_175[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_395 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_833[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_834 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_395[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_835 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_834[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 8s 618ms/step - loss: 1.5837 - dice: 0.1399 - val_loss: 1.2632 - val_dice: 0.2397\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.1457 - dice: 0.3127 - val_loss: 0.9123 - val_dice: 0.4121\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 0.8962 - dice: 0.4332 - val_loss: 0.7648 - val_dice: 0.5180\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 3s 786ms/step - loss: 0.8180 - dice: 0.4850 - val_loss: 0.8224 - val_dice: 0.4441\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 3s 712ms/step - loss: 0.7756 - dice: 0.4913 - val_loss: 0.6823 - val_dice: 0.5570\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 0.7817 - dice: 0.5078 - val_loss: 0.7290 - val_dice: 0.5207\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 0.7446 - dice: 0.5143 - val_loss: 0.7233 - val_dice: 0.5168\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.001, 'loss': <function DiceBCELoss at 0x7bcc24dc25f0>, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>}\n",
            "Model: \"model_44\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_45 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_44 (Lambda)          (None, 256, 256, 3)          0         ['input_45[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_836 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_44[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_396 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_836[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_837 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_396[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_176 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_837[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_838 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_176[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_397 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_838[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_839 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_397[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_177 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_839[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_840 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_177[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_398 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_840[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_841 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_398[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_178 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_841[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_842 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_178[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_399 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_842[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_843 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_399[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_179 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_843[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_844 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_179[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_400 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_844[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_845 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_400[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_176 (Conv  (None, 32, 32, 128)          131200    ['conv2d_845[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_176 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_176[0][0]',\n",
            " te)                                                                 'conv2d_843[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_846 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_176[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_401 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_846[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_847 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_401[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_177 (Conv  (None, 64, 64, 64)           32832     ['conv2d_847[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_177 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_177[0][0]',\n",
            " te)                                                                 'conv2d_841[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_848 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_177[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_402 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_848[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_849 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_402[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_178 (Conv  (None, 128, 128, 32)         8224      ['conv2d_849[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_178 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_178[0][0]',\n",
            " te)                                                                 'conv2d_839[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_850 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_178[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_403 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_850[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_851 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_403[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_179 (Conv  (None, 256, 256, 16)         2064      ['conv2d_851[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_179 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_179[0][0]',\n",
            " te)                                                                 'conv2d_837[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_852 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_179[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_404 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_852[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_853 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_404[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_854 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_853[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 11s 733ms/step - loss: 1.5718 - dice: 0.1230 - val_loss: 1.4073 - val_dice: 0.1666\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 1.3382 - dice: 0.2076 - val_loss: 1.2274 - val_dice: 0.2584\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 592ms/step - loss: 1.1721 - dice: 0.3032 - val_loss: 1.0772 - val_dice: 0.3599\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 3s 764ms/step - loss: 0.9903 - dice: 0.4133 - val_loss: 0.8715 - val_dice: 0.4697\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 3s 660ms/step - loss: 0.9262 - dice: 0.4535 - val_loss: 0.7570 - val_dice: 0.5611\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 2s 637ms/step - loss: 0.8257 - dice: 0.5086 - val_loss: 0.7101 - val_dice: 0.5365\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 0.7814 - dice: 0.4879 - val_loss: 0.7118 - val_dice: 0.5327\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 2s 633ms/step - loss: 0.7491 - dice: 0.5112 - val_loss: 0.7111 - val_dice: 0.5620\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.001, 'loss': <function DiceBCELoss at 0x7bcc24dc25f0>, 'optimizer': <class 'keras.src.optimizers.sgd.SGD'>}\n",
            "Model: \"model_45\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_46 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_45 (Lambda)          (None, 256, 256, 3)          0         ['input_46[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_855 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_45[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_405 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_855[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_856 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_405[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_180 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_856[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_857 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_180[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_406 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_857[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_858 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_406[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_181 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_858[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_859 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_181[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_407 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_859[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_860 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_407[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_182 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_860[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_861 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_182[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_408 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_861[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_862 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_408[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_183 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_862[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_863 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_183[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_409 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_863[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_864 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_409[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_180 (Conv  (None, 32, 32, 128)          131200    ['conv2d_864[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_180 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_180[0][0]',\n",
            " te)                                                                 'conv2d_862[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_865 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_180[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_410 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_865[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_866 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_410[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_181 (Conv  (None, 64, 64, 64)           32832     ['conv2d_866[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_181 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_181[0][0]',\n",
            " te)                                                                 'conv2d_860[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_867 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_181[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_411 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_867[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_868 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_411[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_182 (Conv  (None, 128, 128, 32)         8224      ['conv2d_868[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_182 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_182[0][0]',\n",
            " te)                                                                 'conv2d_858[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_869 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_182[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_412 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_869[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_870 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_412[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_183 (Conv  (None, 256, 256, 16)         2064      ['conv2d_870[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_183 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_183[0][0]',\n",
            " te)                                                                 'conv2d_856[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_871 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_183[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_413 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_871[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_872 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_413[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_873 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_872[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 7s 647ms/step - loss: 1.6571 - dice: 0.0889 - val_loss: 1.6284 - val_dice: 0.0923\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 1.6568 - dice: 0.0891 - val_loss: 1.6271 - val_dice: 0.0927\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 638ms/step - loss: 1.6549 - dice: 0.0897 - val_loss: 1.6258 - val_dice: 0.0931\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 1.6541 - dice: 0.0899 - val_loss: 1.6246 - val_dice: 0.0935\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 3s 626ms/step - loss: 1.6530 - dice: 0.0902 - val_loss: 1.6233 - val_dice: 0.0939\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 2s 574ms/step - loss: 1.6516 - dice: 0.0907 - val_loss: 1.6221 - val_dice: 0.0943\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.6501 - dice: 0.0911 - val_loss: 1.6209 - val_dice: 0.0947\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 2s 624ms/step - loss: 1.6485 - dice: 0.0915 - val_loss: 1.6197 - val_dice: 0.0951\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 1.6481 - dice: 0.0916 - val_loss: 1.6186 - val_dice: 0.0954\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 1.6459 - dice: 0.0922 - val_loss: 1.6174 - val_dice: 0.0958\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 1.6451 - dice: 0.0925 - val_loss: 1.6162 - val_dice: 0.0962\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.6448 - dice: 0.0925 - val_loss: 1.6151 - val_dice: 0.0966\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 2s 625ms/step - loss: 1.6432 - dice: 0.0931 - val_loss: 1.6140 - val_dice: 0.0970\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 3s 761ms/step - loss: 1.6413 - dice: 0.0937 - val_loss: 1.6129 - val_dice: 0.0973\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 3s 614ms/step - loss: 1.6402 - dice: 0.0941 - val_loss: 1.6117 - val_dice: 0.0977\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 1.6391 - dice: 0.0945 - val_loss: 1.6106 - val_dice: 0.0981\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.6389 - dice: 0.0944 - val_loss: 1.6096 - val_dice: 0.0985\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.6369 - dice: 0.0952 - val_loss: 1.6085 - val_dice: 0.0988\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 3s 669ms/step - loss: 1.6363 - dice: 0.0953 - val_loss: 1.6074 - val_dice: 0.0992\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 3s 759ms/step - loss: 1.6353 - dice: 0.0957 - val_loss: 1.6063 - val_dice: 0.0996\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 2s 583ms/step - loss: 1.6335 - dice: 0.0962 - val_loss: 1.6053 - val_dice: 0.0999\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 2s 622ms/step - loss: 1.6330 - dice: 0.0964 - val_loss: 1.6042 - val_dice: 0.1003\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 1.6321 - dice: 0.0966 - val_loss: 1.6032 - val_dice: 0.1007\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 1.6301 - dice: 0.0972 - val_loss: 1.6021 - val_dice: 0.1011\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 1.6296 - dice: 0.0975 - val_loss: 1.6011 - val_dice: 0.1014\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 3s 712ms/step - loss: 1.6289 - dice: 0.0977 - val_loss: 1.6001 - val_dice: 0.1018\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 1.6276 - dice: 0.0982 - val_loss: 1.5990 - val_dice: 0.1022\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 1.6260 - dice: 0.0987 - val_loss: 1.5980 - val_dice: 0.1025\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.6261 - dice: 0.0987 - val_loss: 1.5970 - val_dice: 0.1029\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 2s 627ms/step - loss: 1.6240 - dice: 0.0993 - val_loss: 1.5959 - val_dice: 0.1033\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 3s 704ms/step - loss: 1.6231 - dice: 0.0997 - val_loss: 1.5949 - val_dice: 0.1037\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 2s 574ms/step - loss: 1.6223 - dice: 0.1000 - val_loss: 1.5939 - val_dice: 0.1040\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 1.6204 - dice: 0.1006 - val_loss: 1.5929 - val_dice: 0.1044\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 1.6198 - dice: 0.1008 - val_loss: 1.5919 - val_dice: 0.1048\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 2s 579ms/step - loss: 1.6196 - dice: 0.1008 - val_loss: 1.5909 - val_dice: 0.1052\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 1.6177 - dice: 0.1016 - val_loss: 1.5899 - val_dice: 0.1055\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 1.6169 - dice: 0.1018 - val_loss: 1.5889 - val_dice: 0.1059\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.6159 - dice: 0.1023 - val_loss: 1.5879 - val_dice: 0.1063\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 1.6147 - dice: 0.1026 - val_loss: 1.5869 - val_dice: 0.1067\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 2s 661ms/step - loss: 1.6137 - dice: 0.1030 - val_loss: 1.5859 - val_dice: 0.1071\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 3s 769ms/step - loss: 1.6129 - dice: 0.1033 - val_loss: 1.5849 - val_dice: 0.1074\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 2s 590ms/step - loss: 1.6111 - dice: 0.1041 - val_loss: 1.5839 - val_dice: 0.1078\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 1.6110 - dice: 0.1039 - val_loss: 1.5829 - val_dice: 0.1082\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 1.6093 - dice: 0.1045 - val_loss: 1.5819 - val_dice: 0.1086\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 3s 703ms/step - loss: 1.6085 - dice: 0.1048 - val_loss: 1.5809 - val_dice: 0.1090\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 2s 579ms/step - loss: 1.6071 - dice: 0.1055 - val_loss: 1.5799 - val_dice: 0.1094\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.6065 - dice: 0.1056 - val_loss: 1.5789 - val_dice: 0.1098\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 1.6053 - dice: 0.1062 - val_loss: 1.5778 - val_dice: 0.1102\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 2s 639ms/step - loss: 1.6040 - dice: 0.1066 - val_loss: 1.5768 - val_dice: 0.1106\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 3s 715ms/step - loss: 1.6034 - dice: 0.1066 - val_loss: 1.5758 - val_dice: 0.1110\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 1.6031 - dice: 0.1068 - val_loss: 1.5748 - val_dice: 0.1114\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 2s 577ms/step - loss: 1.6010 - dice: 0.1076 - val_loss: 1.5738 - val_dice: 0.1118\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 2s 584ms/step - loss: 1.6006 - dice: 0.1078 - val_loss: 1.5729 - val_dice: 0.1122\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 2s 650ms/step - loss: 1.5989 - dice: 0.1086 - val_loss: 1.5718 - val_dice: 0.1126\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 3s 771ms/step - loss: 1.5985 - dice: 0.1086 - val_loss: 1.5708 - val_dice: 0.1130\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 2s 591ms/step - loss: 1.5976 - dice: 0.1090 - val_loss: 1.5698 - val_dice: 0.1134\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 1.5956 - dice: 0.1096 - val_loss: 1.5688 - val_dice: 0.1138\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 2s 585ms/step - loss: 1.5947 - dice: 0.1101 - val_loss: 1.5678 - val_dice: 0.1143\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 1.5940 - dice: 0.1104 - val_loss: 1.5668 - val_dice: 0.1147\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 2s 612ms/step - loss: 1.5934 - dice: 0.1105 - val_loss: 1.5658 - val_dice: 0.1151\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 1.5925 - dice: 0.1109 - val_loss: 1.5648 - val_dice: 0.1155\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 1.5904 - dice: 0.1117 - val_loss: 1.5638 - val_dice: 0.1159\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 2s 628ms/step - loss: 1.5898 - dice: 0.1120 - val_loss: 1.5627 - val_dice: 0.1164\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 2s 579ms/step - loss: 1.5888 - dice: 0.1123 - val_loss: 1.5617 - val_dice: 0.1168\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 3s 715ms/step - loss: 1.5881 - dice: 0.1126 - val_loss: 1.5607 - val_dice: 0.1172\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 1.5861 - dice: 0.1134 - val_loss: 1.5596 - val_dice: 0.1177\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 1.5862 - dice: 0.1133 - val_loss: 1.5586 - val_dice: 0.1181\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 2s 577ms/step - loss: 1.5850 - dice: 0.1140 - val_loss: 1.5576 - val_dice: 0.1185\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 2s 634ms/step - loss: 1.5831 - dice: 0.1146 - val_loss: 1.5566 - val_dice: 0.1190\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 1.5825 - dice: 0.1149 - val_loss: 1.5555 - val_dice: 0.1194\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 3s 635ms/step - loss: 1.5820 - dice: 0.1151 - val_loss: 1.5545 - val_dice: 0.1198\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 1.5802 - dice: 0.1158 - val_loss: 1.5534 - val_dice: 0.1203\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 1.5791 - dice: 0.1162 - val_loss: 1.5524 - val_dice: 0.1207\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 1.5778 - dice: 0.1168 - val_loss: 1.5513 - val_dice: 0.1212\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 2s 602ms/step - loss: 1.5770 - dice: 0.1172 - val_loss: 1.5503 - val_dice: 0.1217\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 1.5760 - dice: 0.1175 - val_loss: 1.5492 - val_dice: 0.1221\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 1.5749 - dice: 0.1180 - val_loss: 1.5482 - val_dice: 0.1226\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.5738 - dice: 0.1184 - val_loss: 1.5471 - val_dice: 0.1230\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.5725 - dice: 0.1189 - val_loss: 1.5460 - val_dice: 0.1235\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 2s 617ms/step - loss: 1.5714 - dice: 0.1193 - val_loss: 1.5450 - val_dice: 0.1240\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 3s 785ms/step - loss: 1.5701 - dice: 0.1200 - val_loss: 1.5439 - val_dice: 0.1245\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 2s 608ms/step - loss: 1.5689 - dice: 0.1204 - val_loss: 1.5428 - val_dice: 0.1249\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 1.5686 - dice: 0.1205 - val_loss: 1.5417 - val_dice: 0.1254\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 1.5674 - dice: 0.1210 - val_loss: 1.5406 - val_dice: 0.1259\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 1.5663 - dice: 0.1215 - val_loss: 1.5395 - val_dice: 0.1264\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 3s 686ms/step - loss: 1.5650 - dice: 0.1221 - val_loss: 1.5384 - val_dice: 0.1269\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 3s 787ms/step - loss: 1.5634 - dice: 0.1228 - val_loss: 1.5373 - val_dice: 0.1274\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 1.5627 - dice: 0.1231 - val_loss: 1.5362 - val_dice: 0.1278\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 1.5619 - dice: 0.1235 - val_loss: 1.5351 - val_dice: 0.1283\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 1.5602 - dice: 0.1241 - val_loss: 1.5340 - val_dice: 0.1288\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 1.5589 - dice: 0.1246 - val_loss: 1.5329 - val_dice: 0.1294\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 3s 721ms/step - loss: 1.5580 - dice: 0.1250 - val_loss: 1.5317 - val_dice: 0.1299\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 1.5571 - dice: 0.1254 - val_loss: 1.5306 - val_dice: 0.1304\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 1.5552 - dice: 0.1264 - val_loss: 1.5295 - val_dice: 0.1309\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 1.5556 - dice: 0.1262 - val_loss: 1.5283 - val_dice: 0.1314\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 1.5528 - dice: 0.1273 - val_loss: 1.5272 - val_dice: 0.1319\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 3s 683ms/step - loss: 1.5521 - dice: 0.1276 - val_loss: 1.5260 - val_dice: 0.1325\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.5511 - dice: 0.1282 - val_loss: 1.5248 - val_dice: 0.1330\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 1.5492 - dice: 0.1290 - val_loss: 1.5237 - val_dice: 0.1336\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 1.5485 - dice: 0.1294 - val_loss: 1.5225 - val_dice: 0.1341\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.0001, 'loss': <function DiceLoss at 0x7bcc24dc2680>, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>}\n",
            "Model: \"model_46\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_47 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_46 (Lambda)          (None, 256, 256, 3)          0         ['input_47[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_874 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_46[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_414 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_874[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_875 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_414[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_184 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_875[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_876 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_184[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_415 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_876[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_877 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_415[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_185 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_877[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_878 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_185[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_416 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_878[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_879 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_416[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_186 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_879[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_880 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_186[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_417 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_880[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_881 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_417[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_187 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_881[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_882 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_187[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_418 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_882[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_883 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_418[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_184 (Conv  (None, 32, 32, 128)          131200    ['conv2d_883[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_184 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_184[0][0]',\n",
            " te)                                                                 'conv2d_881[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_884 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_184[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_419 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_884[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_885 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_419[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_185 (Conv  (None, 64, 64, 64)           32832     ['conv2d_885[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_185 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_185[0][0]',\n",
            " te)                                                                 'conv2d_879[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_886 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_185[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_420 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_886[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_887 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_420[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_186 (Conv  (None, 128, 128, 32)         8224      ['conv2d_887[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_186 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_186[0][0]',\n",
            " te)                                                                 'conv2d_877[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_888 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_186[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_421 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_888[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_889 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_421[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_187 (Conv  (None, 256, 256, 16)         2064      ['conv2d_889[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_187 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_187[0][0]',\n",
            " te)                                                                 'conv2d_875[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_890 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_187[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_422 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_890[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_891 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_422[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_892 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_891[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 10s 637ms/step - loss: 0.8248 - dice: 0.1752 - val_loss: 0.7806 - val_dice: 0.2194\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 2s 535ms/step - loss: 0.7237 - dice: 0.2763 - val_loss: 0.6547 - val_dice: 0.3453\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 630ms/step - loss: 0.5917 - dice: 0.4083 - val_loss: 0.5151 - val_dice: 0.4849\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 3s 767ms/step - loss: 0.5097 - dice: 0.4903 - val_loss: 0.4564 - val_dice: 0.5436\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 0.4801 - dice: 0.5199 - val_loss: 0.4435 - val_dice: 0.5565\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 0.4652 - dice: 0.5348 - val_loss: 0.4382 - val_dice: 0.5618\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 0.4657 - dice: 0.5343 - val_loss: 0.4350 - val_dice: 0.5650\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 3s 677ms/step - loss: 0.4581 - dice: 0.5419 - val_loss: 0.4329 - val_dice: 0.5671\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 3s 799ms/step - loss: 0.4550 - dice: 0.5450 - val_loss: 0.4313 - val_dice: 0.5687\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.4641 - dice: 0.5359 - val_loss: 0.4301 - val_dice: 0.5699\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.4561 - dice: 0.5439 - val_loss: 0.4292 - val_dice: 0.5708\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.4524 - dice: 0.5476 - val_loss: 0.4285 - val_dice: 0.5715\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 0.4603 - dice: 0.5397 - val_loss: 0.4281 - val_dice: 0.5719\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 3s 819ms/step - loss: 0.4573 - dice: 0.5427 - val_loss: 0.4277 - val_dice: 0.5723\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 0.4586 - dice: 0.5414 - val_loss: 0.4275 - val_dice: 0.5725\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 0.4538 - dice: 0.5462 - val_loss: 0.4273 - val_dice: 0.5727\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.4554 - dice: 0.5446 - val_loss: 0.4271 - val_dice: 0.5729\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 0.4607 - dice: 0.5393 - val_loss: 0.4270 - val_dice: 0.5730\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 3s 672ms/step - loss: 0.4584 - dice: 0.5416 - val_loss: 0.4269 - val_dice: 0.5731\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.4541 - dice: 0.5459 - val_loss: 0.4268 - val_dice: 0.5732\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 2s 581ms/step - loss: 0.4557 - dice: 0.5443 - val_loss: 0.4268 - val_dice: 0.5732\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.4546 - dice: 0.5454 - val_loss: 0.4267 - val_dice: 0.5733\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 0.4555 - dice: 0.5445 - val_loss: 0.4267 - val_dice: 0.5733\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 0.4528 - dice: 0.5472 - val_loss: 0.4266 - val_dice: 0.5734\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 3s 679ms/step - loss: 0.4514 - dice: 0.5486 - val_loss: 0.4266 - val_dice: 0.5734\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.4530 - dice: 0.5470 - val_loss: 0.4265 - val_dice: 0.5735\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.4523 - dice: 0.5477 - val_loss: 0.4265 - val_dice: 0.5735\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 0.4533 - dice: 0.5467 - val_loss: 0.4265 - val_dice: 0.5735\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.4613 - dice: 0.5387 - val_loss: 0.4265 - val_dice: 0.5735\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.4561 - dice: 0.5439 - val_loss: 0.4265 - val_dice: 0.5735\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 3s 679ms/step - loss: 0.4546 - dice: 0.5454 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.4575 - dice: 0.5425 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.4586 - dice: 0.5414 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.4539 - dice: 0.5461 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 0.4554 - dice: 0.5446 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 3s 756ms/step - loss: 0.4611 - dice: 0.5389 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.4583 - dice: 0.5417 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.4575 - dice: 0.5425 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.4528 - dice: 0.5472 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 2s 613ms/step - loss: 0.4543 - dice: 0.5457 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.4540 - dice: 0.5460 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 3s 645ms/step - loss: 0.4512 - dice: 0.5488 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 0.4573 - dice: 0.5427 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 0.4523 - dice: 0.5477 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.4525 - dice: 0.5475 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 2s 639ms/step - loss: 0.4563 - dice: 0.5437 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 3s 708ms/step - loss: 0.4530 - dice: 0.5470 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.4515 - dice: 0.5485 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 0.4605 - dice: 0.5395 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.4572 - dice: 0.5428 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 3s 674ms/step - loss: 0.4621 - dice: 0.5379 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 3s 792ms/step - loss: 0.4587 - dice: 0.5413 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 2s 579ms/step - loss: 0.4516 - dice: 0.5484 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.4573 - dice: 0.5427 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.4542 - dice: 0.5458 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 0.4581 - dice: 0.5419 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.4546 - dice: 0.5454 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.4496 - dice: 0.5504 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 0.4548 - dice: 0.5452 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 2s 581ms/step - loss: 0.4568 - dice: 0.5432 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 0.4514 - dice: 0.5486 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 3s 763ms/step - loss: 0.4494 - dice: 0.5506 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 3s 634ms/step - loss: 0.4507 - dice: 0.5493 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 2s 577ms/step - loss: 0.4542 - dice: 0.5458 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 0.4619 - dice: 0.5381 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 2s 631ms/step - loss: 0.4556 - dice: 0.5444 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.4555 - dice: 0.5445 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 2s 618ms/step - loss: 0.4523 - dice: 0.5477 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 2s 637ms/step - loss: 0.4587 - dice: 0.5413 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 0.4568 - dice: 0.5432 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 2s 577ms/step - loss: 0.4557 - dice: 0.5443 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 2s 596ms/step - loss: 0.4571 - dice: 0.5429 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 3s 765ms/step - loss: 0.4582 - dice: 0.5418 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 3s 622ms/step - loss: 0.4535 - dice: 0.5465 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.4558 - dice: 0.5442 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 2s 579ms/step - loss: 0.4495 - dice: 0.5505 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 0.4578 - dice: 0.5422 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 3s 678ms/step - loss: 0.4628 - dice: 0.5372 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.4609 - dice: 0.5391 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.4539 - dice: 0.5461 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 0.4606 - dice: 0.5394 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 0.4522 - dice: 0.5478 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 2s 619ms/step - loss: 0.4597 - dice: 0.5403 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 3s 688ms/step - loss: 0.4523 - dice: 0.5477 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 2s 639ms/step - loss: 0.4527 - dice: 0.5473 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.4559 - dice: 0.5441 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 2s 614ms/step - loss: 0.4519 - dice: 0.5481 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 2s 605ms/step - loss: 0.4554 - dice: 0.5446 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 3s 762ms/step - loss: 0.4636 - dice: 0.5364 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 2s 590ms/step - loss: 0.4519 - dice: 0.5481 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.4597 - dice: 0.5403 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.4592 - dice: 0.5408 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 0.4569 - dice: 0.5431 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 3s 720ms/step - loss: 0.4563 - dice: 0.5437 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.4559 - dice: 0.5441 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 2s 627ms/step - loss: 0.4514 - dice: 0.5486 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.4517 - dice: 0.5483 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 0.4550 - dice: 0.5450 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 0.4514 - dice: 0.5486 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 0.4510 - dice: 0.5490 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.0001, 'loss': <function DiceLoss at 0x7bcc24dc2680>, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>}\n",
            "Model: \"model_47\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_48 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_47 (Lambda)          (None, 256, 256, 3)          0         ['input_48[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_893 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_47[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_423 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_893[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_894 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_423[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_188 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_894[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_895 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_188[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_424 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_895[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_896 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_424[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_189 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_896[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_897 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_189[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_425 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_897[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_898 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_425[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_190 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_898[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_899 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_190[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_426 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_899[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_900 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_426[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_191 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_900[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_901 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_191[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_427 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_901[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_902 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_427[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_188 (Conv  (None, 32, 32, 128)          131200    ['conv2d_902[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_188 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_188[0][0]',\n",
            " te)                                                                 'conv2d_900[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_903 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_188[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_428 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_903[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_904 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_428[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_189 (Conv  (None, 64, 64, 64)           32832     ['conv2d_904[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_189 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_189[0][0]',\n",
            " te)                                                                 'conv2d_898[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_905 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_189[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_429 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_905[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_906 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_429[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_190 (Conv  (None, 128, 128, 32)         8224      ['conv2d_906[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_190 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_190[0][0]',\n",
            " te)                                                                 'conv2d_896[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_907 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_190[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_430 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_907[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_908 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_430[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_191 (Conv  (None, 256, 256, 16)         2064      ['conv2d_908[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_191 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_191[0][0]',\n",
            " te)                                                                 'conv2d_894[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_909 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_191[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_431 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_909[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_910 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_431[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_911 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_910[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 9s 818ms/step - loss: 0.8765 - dice: 0.1235 - val_loss: 0.8602 - val_dice: 0.1398\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 0.8359 - dice: 0.1641 - val_loss: 0.8085 - val_dice: 0.1915\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.7806 - dice: 0.2194 - val_loss: 0.7267 - val_dice: 0.2733\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.7136 - dice: 0.2864 - val_loss: 0.6401 - val_dice: 0.3599\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 0.6551 - dice: 0.3449 - val_loss: 0.5838 - val_dice: 0.4162\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 3s 693ms/step - loss: 0.6110 - dice: 0.3890 - val_loss: 0.5460 - val_dice: 0.4540\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 2s 637ms/step - loss: 0.5641 - dice: 0.4359 - val_loss: 0.5157 - val_dice: 0.4843\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.5307 - dice: 0.4693 - val_loss: 0.4827 - val_dice: 0.5173\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 2s 628ms/step - loss: 0.5000 - dice: 0.5000 - val_loss: 0.4531 - val_dice: 0.5469\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 3s 784ms/step - loss: 0.4891 - dice: 0.5109 - val_loss: 0.4429 - val_dice: 0.5571\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 0.4776 - dice: 0.5224 - val_loss: 0.4376 - val_dice: 0.5624\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.4691 - dice: 0.5309 - val_loss: 0.4351 - val_dice: 0.5649\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 0.4694 - dice: 0.5306 - val_loss: 0.4336 - val_dice: 0.5664\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 2s 634ms/step - loss: 0.4699 - dice: 0.5301 - val_loss: 0.4325 - val_dice: 0.5675\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 0.4576 - dice: 0.5424 - val_loss: 0.4316 - val_dice: 0.5684\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 2s 631ms/step - loss: 0.4653 - dice: 0.5347 - val_loss: 0.4308 - val_dice: 0.5692\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 0.4638 - dice: 0.5362 - val_loss: 0.4301 - val_dice: 0.5699\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.4641 - dice: 0.5359 - val_loss: 0.4296 - val_dice: 0.5704\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 3s 680ms/step - loss: 0.4587 - dice: 0.5413 - val_loss: 0.4291 - val_dice: 0.5709\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 3s 711ms/step - loss: 0.4598 - dice: 0.5402 - val_loss: 0.4288 - val_dice: 0.5712\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.4614 - dice: 0.5386 - val_loss: 0.4285 - val_dice: 0.5715\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.4649 - dice: 0.5351 - val_loss: 0.4282 - val_dice: 0.5718\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 0.4567 - dice: 0.5433 - val_loss: 0.4280 - val_dice: 0.5720\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 0.4580 - dice: 0.5420 - val_loss: 0.4278 - val_dice: 0.5722\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 3s 684ms/step - loss: 0.4612 - dice: 0.5388 - val_loss: 0.4276 - val_dice: 0.5724\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 3s 729ms/step - loss: 0.4603 - dice: 0.5397 - val_loss: 0.4275 - val_dice: 0.5725\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.4605 - dice: 0.5395 - val_loss: 0.4274 - val_dice: 0.5726\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.4608 - dice: 0.5392 - val_loss: 0.4273 - val_dice: 0.5727\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 2s 616ms/step - loss: 0.4557 - dice: 0.5443 - val_loss: 0.4272 - val_dice: 0.5728\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 0.4639 - dice: 0.5361 - val_loss: 0.4271 - val_dice: 0.5729\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 3s 759ms/step - loss: 0.4612 - dice: 0.5388 - val_loss: 0.4270 - val_dice: 0.5730\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.4534 - dice: 0.5466 - val_loss: 0.4269 - val_dice: 0.5731\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.4574 - dice: 0.5426 - val_loss: 0.4268 - val_dice: 0.5732\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.4595 - dice: 0.5405 - val_loss: 0.4268 - val_dice: 0.5732\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 3s 752ms/step - loss: 0.4574 - dice: 0.5426 - val_loss: 0.4267 - val_dice: 0.5733\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.4568 - dice: 0.5432 - val_loss: 0.4267 - val_dice: 0.5733\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 0.4576 - dice: 0.5424 - val_loss: 0.4266 - val_dice: 0.5734\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.4514 - dice: 0.5486 - val_loss: 0.4266 - val_dice: 0.5734\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 2s 580ms/step - loss: 0.4568 - dice: 0.5432 - val_loss: 0.4265 - val_dice: 0.5735\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 3s 786ms/step - loss: 0.4596 - dice: 0.5404 - val_loss: 0.4265 - val_dice: 0.5735\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.4540 - dice: 0.5460 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 0.4635 - dice: 0.5365 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.4578 - dice: 0.5422 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.4594 - dice: 0.5406 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.4525 - dice: 0.5475 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 3s 656ms/step - loss: 0.4571 - dice: 0.5429 - val_loss: 0.4264 - val_dice: 0.5736\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 0.4549 - dice: 0.5451 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.4594 - dice: 0.5406 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.4582 - dice: 0.5418 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 2s 628ms/step - loss: 0.4529 - dice: 0.5471 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 3s 727ms/step - loss: 0.4567 - dice: 0.5433 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 0.4581 - dice: 0.5419 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 0.4561 - dice: 0.5439 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 0.4597 - dice: 0.5403 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 2s 648ms/step - loss: 0.4527 - dice: 0.5473 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 3s 784ms/step - loss: 0.4539 - dice: 0.5461 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 2s 585ms/step - loss: 0.4593 - dice: 0.5407 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 0.4517 - dice: 0.5483 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.4562 - dice: 0.5438 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.4552 - dice: 0.5448 - val_loss: 0.4263 - val_dice: 0.5737\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.4573 - dice: 0.5427 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.4515 - dice: 0.5485 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 0.4578 - dice: 0.5422 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.4603 - dice: 0.5397 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 3s 681ms/step - loss: 0.4549 - dice: 0.5451 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.4519 - dice: 0.5481 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 0.4575 - dice: 0.5425 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 0.4484 - dice: 0.5516 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.4579 - dice: 0.5421 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 0.4608 - dice: 0.5392 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 0.4545 - dice: 0.5455 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 0.4555 - dice: 0.5445 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.4542 - dice: 0.5458 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 0.4510 - dice: 0.5490 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.4549 - dice: 0.5451 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 2s 585ms/step - loss: 0.4609 - dice: 0.5391 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 0.4535 - dice: 0.5465 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.4610 - dice: 0.5390 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 0.4566 - dice: 0.5434 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 2s 599ms/step - loss: 0.4524 - dice: 0.5476 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 3s 766ms/step - loss: 0.4618 - dice: 0.5382 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 2s 596ms/step - loss: 0.4580 - dice: 0.5420 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 0.4607 - dice: 0.5393 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.4595 - dice: 0.5405 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 0.4533 - dice: 0.5467 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 3s 691ms/step - loss: 0.4520 - dice: 0.5480 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 3s 769ms/step - loss: 0.4593 - dice: 0.5407 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 0.4527 - dice: 0.5473 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 2s 626ms/step - loss: 0.4573 - dice: 0.5427 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.4593 - dice: 0.5407 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 0.4570 - dice: 0.5430 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 0.4536 - dice: 0.5464 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.4571 - dice: 0.5429 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.4590 - dice: 0.5410 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 2s 623ms/step - loss: 0.4513 - dice: 0.5487 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.4570 - dice: 0.5430 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.4588 - dice: 0.5412 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.4612 - dice: 0.5388 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 0.4528 - dice: 0.5472 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 2s 623ms/step - loss: 0.4568 - dice: 0.5432 - val_loss: 0.4262 - val_dice: 0.5738\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.0001, 'loss': <function DiceLoss at 0x7bcc24dc2680>, 'optimizer': <class 'keras.src.optimizers.sgd.SGD'>}\n",
            "Model: \"model_48\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_49 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_48 (Lambda)          (None, 256, 256, 3)          0         ['input_49[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_912 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_48[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_432 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_912[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_913 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_432[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_192 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_913[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_914 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_192[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_433 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_914[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_915 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_433[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_193 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_915[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_916 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_193[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_434 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_916[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_917 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_434[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_194 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_917[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_918 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_194[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_435 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_918[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_919 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_435[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_195 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_919[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_920 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_195[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_436 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_920[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_921 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_436[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_192 (Conv  (None, 32, 32, 128)          131200    ['conv2d_921[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_192 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_192[0][0]',\n",
            " te)                                                                 'conv2d_919[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_922 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_192[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_437 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_922[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_923 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_437[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_193 (Conv  (None, 64, 64, 64)           32832     ['conv2d_923[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_193 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_193[0][0]',\n",
            " te)                                                                 'conv2d_917[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_924 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_193[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_438 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_924[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_925 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_438[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_194 (Conv  (None, 128, 128, 32)         8224      ['conv2d_925[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_194 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_194[0][0]',\n",
            " te)                                                                 'conv2d_915[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_926 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_194[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_439 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_926[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_927 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_439[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_195 (Conv  (None, 256, 256, 16)         2064      ['conv2d_927[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_195 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_195[0][0]',\n",
            " te)                                                                 'conv2d_913[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_928 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_195[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_440 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_928[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_929 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_440[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_930 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_929[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 7s 618ms/step - loss: 0.8983 - dice: 0.1017 - val_loss: 0.8977 - val_dice: 0.1023\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 0.8978 - dice: 0.1022 - val_loss: 0.8976 - val_dice: 0.1024\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 0.8981 - dice: 0.1019 - val_loss: 0.8976 - val_dice: 0.1024\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 3s 807ms/step - loss: 0.8978 - dice: 0.1022 - val_loss: 0.8975 - val_dice: 0.1025\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 0.8983 - dice: 0.1017 - val_loss: 0.8974 - val_dice: 0.1026\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.8981 - dice: 0.1019 - val_loss: 0.8974 - val_dice: 0.1026\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.8978 - dice: 0.1022 - val_loss: 0.8973 - val_dice: 0.1027\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 0.8980 - dice: 0.1020 - val_loss: 0.8972 - val_dice: 0.1028\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 3s 756ms/step - loss: 0.8976 - dice: 0.1024 - val_loss: 0.8971 - val_dice: 0.1029\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 0.8979 - dice: 0.1021 - val_loss: 0.8971 - val_dice: 0.1029\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 0.8977 - dice: 0.1023 - val_loss: 0.8970 - val_dice: 0.1030\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.8976 - dice: 0.1024 - val_loss: 0.8969 - val_dice: 0.1031\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.8981 - dice: 0.1019 - val_loss: 0.8968 - val_dice: 0.1032\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.8976 - dice: 0.1024 - val_loss: 0.8968 - val_dice: 0.1032\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 3s 670ms/step - loss: 0.8974 - dice: 0.1026 - val_loss: 0.8967 - val_dice: 0.1033\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 2s 633ms/step - loss: 0.8975 - dice: 0.1025 - val_loss: 0.8966 - val_dice: 0.1034\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 0.8977 - dice: 0.1023 - val_loss: 0.8966 - val_dice: 0.1034\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.8972 - dice: 0.1028 - val_loss: 0.8965 - val_dice: 0.1035\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 3s 784ms/step - loss: 0.8976 - dice: 0.1024 - val_loss: 0.8964 - val_dice: 0.1036\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 0.8972 - dice: 0.1028 - val_loss: 0.8963 - val_dice: 0.1037\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.8970 - dice: 0.1030 - val_loss: 0.8963 - val_dice: 0.1037\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.8971 - dice: 0.1029 - val_loss: 0.8962 - val_dice: 0.1038\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 0.8961 - dice: 0.1039 - val_loss: 0.8961 - val_dice: 0.1039\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 3s 803ms/step - loss: 0.8969 - dice: 0.1031 - val_loss: 0.8960 - val_dice: 0.1040\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 3s 641ms/step - loss: 0.8965 - dice: 0.1035 - val_loss: 0.8960 - val_dice: 0.1040\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 2s 623ms/step - loss: 0.8965 - dice: 0.1035 - val_loss: 0.8959 - val_dice: 0.1041\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.8964 - dice: 0.1036 - val_loss: 0.8958 - val_dice: 0.1042\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 2s 622ms/step - loss: 0.8962 - dice: 0.1038 - val_loss: 0.8957 - val_dice: 0.1043\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 0.8969 - dice: 0.1031 - val_loss: 0.8957 - val_dice: 0.1043\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 2s 602ms/step - loss: 0.8959 - dice: 0.1041 - val_loss: 0.8956 - val_dice: 0.1044\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.8959 - dice: 0.1041 - val_loss: 0.8955 - val_dice: 0.1045\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 0.8955 - dice: 0.1045 - val_loss: 0.8954 - val_dice: 0.1046\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.8964 - dice: 0.1036 - val_loss: 0.8953 - val_dice: 0.1047\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 2s 624ms/step - loss: 0.8957 - dice: 0.1043 - val_loss: 0.8953 - val_dice: 0.1047\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 3s 797ms/step - loss: 0.8963 - dice: 0.1037 - val_loss: 0.8952 - val_dice: 0.1048\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 0.8956 - dice: 0.1044 - val_loss: 0.8951 - val_dice: 0.1049\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 2s 577ms/step - loss: 0.8951 - dice: 0.1049 - val_loss: 0.8950 - val_dice: 0.1050\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.8947 - dice: 0.1053 - val_loss: 0.8950 - val_dice: 0.1050\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 2s 606ms/step - loss: 0.8946 - dice: 0.1054 - val_loss: 0.8949 - val_dice: 0.1051\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.8944 - dice: 0.1056 - val_loss: 0.8948 - val_dice: 0.1052\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 3s 616ms/step - loss: 0.8949 - dice: 0.1051 - val_loss: 0.8947 - val_dice: 0.1053\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 0.8951 - dice: 0.1049 - val_loss: 0.8946 - val_dice: 0.1054\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 0.8956 - dice: 0.1044 - val_loss: 0.8946 - val_dice: 0.1054\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.8951 - dice: 0.1049 - val_loss: 0.8945 - val_dice: 0.1055\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 2s 630ms/step - loss: 0.8952 - dice: 0.1048 - val_loss: 0.8944 - val_dice: 0.1056\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 0.8947 - dice: 0.1053 - val_loss: 0.8943 - val_dice: 0.1057\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 2s 599ms/step - loss: 0.8944 - dice: 0.1056 - val_loss: 0.8942 - val_dice: 0.1058\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.8942 - dice: 0.1058 - val_loss: 0.8942 - val_dice: 0.1058\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.8945 - dice: 0.1055 - val_loss: 0.8941 - val_dice: 0.1059\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 0.8944 - dice: 0.1056 - val_loss: 0.8940 - val_dice: 0.1060\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 2s 639ms/step - loss: 0.8938 - dice: 0.1062 - val_loss: 0.8939 - val_dice: 0.1061\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 3s 769ms/step - loss: 0.8941 - dice: 0.1059 - val_loss: 0.8938 - val_dice: 0.1062\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 0.8947 - dice: 0.1053 - val_loss: 0.8938 - val_dice: 0.1062\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 0.8939 - dice: 0.1061 - val_loss: 0.8937 - val_dice: 0.1063\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.8941 - dice: 0.1059 - val_loss: 0.8936 - val_dice: 0.1064\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.8938 - dice: 0.1062 - val_loss: 0.8935 - val_dice: 0.1065\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 3s 678ms/step - loss: 0.8938 - dice: 0.1062 - val_loss: 0.8934 - val_dice: 0.1066\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 2s 625ms/step - loss: 0.8940 - dice: 0.1060 - val_loss: 0.8934 - val_dice: 0.1066\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 0.8932 - dice: 0.1068 - val_loss: 0.8933 - val_dice: 0.1067\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.8939 - dice: 0.1061 - val_loss: 0.8932 - val_dice: 0.1068\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 2s 632ms/step - loss: 0.8940 - dice: 0.1060 - val_loss: 0.8931 - val_dice: 0.1069\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 3s 723ms/step - loss: 0.8936 - dice: 0.1064 - val_loss: 0.8930 - val_dice: 0.1070\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 0.8935 - dice: 0.1065 - val_loss: 0.8929 - val_dice: 0.1071\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 0.8930 - dice: 0.1070 - val_loss: 0.8929 - val_dice: 0.1071\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 0.8929 - dice: 0.1071 - val_loss: 0.8928 - val_dice: 0.1072\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 2s 624ms/step - loss: 0.8934 - dice: 0.1066 - val_loss: 0.8927 - val_dice: 0.1073\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.8928 - dice: 0.1072 - val_loss: 0.8926 - val_dice: 0.1074\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.8923 - dice: 0.1077 - val_loss: 0.8925 - val_dice: 0.1075\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.8928 - dice: 0.1072 - val_loss: 0.8924 - val_dice: 0.1076\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.8932 - dice: 0.1068 - val_loss: 0.8924 - val_dice: 0.1076\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 3s 682ms/step - loss: 0.8926 - dice: 0.1074 - val_loss: 0.8923 - val_dice: 0.1077\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.8922 - dice: 0.1078 - val_loss: 0.8922 - val_dice: 0.1078\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 0.8929 - dice: 0.1071 - val_loss: 0.8921 - val_dice: 0.1079\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 0.8925 - dice: 0.1075 - val_loss: 0.8920 - val_dice: 0.1080\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 2s 591ms/step - loss: 0.8928 - dice: 0.1072 - val_loss: 0.8919 - val_dice: 0.1081\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 3s 799ms/step - loss: 0.8919 - dice: 0.1081 - val_loss: 0.8918 - val_dice: 0.1082\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.8921 - dice: 0.1079 - val_loss: 0.8918 - val_dice: 0.1082\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 0.8919 - dice: 0.1081 - val_loss: 0.8917 - val_dice: 0.1083\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.8915 - dice: 0.1085 - val_loss: 0.8916 - val_dice: 0.1084\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.8916 - dice: 0.1084 - val_loss: 0.8915 - val_dice: 0.1085\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 3s 729ms/step - loss: 0.8916 - dice: 0.1084 - val_loss: 0.8914 - val_dice: 0.1086\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 0.8916 - dice: 0.1084 - val_loss: 0.8913 - val_dice: 0.1087\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 0.8911 - dice: 0.1089 - val_loss: 0.8912 - val_dice: 0.1088\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 0.8917 - dice: 0.1083 - val_loss: 0.8912 - val_dice: 0.1088\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.8915 - dice: 0.1085 - val_loss: 0.8911 - val_dice: 0.1089\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.8912 - dice: 0.1088 - val_loss: 0.8910 - val_dice: 0.1090\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 3s 727ms/step - loss: 0.8918 - dice: 0.1082 - val_loss: 0.8909 - val_dice: 0.1091\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.8910 - dice: 0.1090 - val_loss: 0.8908 - val_dice: 0.1092\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 0.8908 - dice: 0.1092 - val_loss: 0.8907 - val_dice: 0.1093\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 0.8910 - dice: 0.1090 - val_loss: 0.8906 - val_dice: 0.1094\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 2s 579ms/step - loss: 0.8907 - dice: 0.1093 - val_loss: 0.8905 - val_dice: 0.1095\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 3s 763ms/step - loss: 0.8911 - dice: 0.1089 - val_loss: 0.8904 - val_dice: 0.1096\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 3s 764ms/step - loss: 0.8904 - dice: 0.1096 - val_loss: 0.8904 - val_dice: 0.1096\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.8902 - dice: 0.1098 - val_loss: 0.8903 - val_dice: 0.1097\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.8912 - dice: 0.1088 - val_loss: 0.8902 - val_dice: 0.1098\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.8908 - dice: 0.1092 - val_loss: 0.8901 - val_dice: 0.1099\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 2s 576ms/step - loss: 0.8901 - dice: 0.1099 - val_loss: 0.8900 - val_dice: 0.1100\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.8898 - dice: 0.1102 - val_loss: 0.8899 - val_dice: 0.1101\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 0.8902 - dice: 0.1098 - val_loss: 0.8898 - val_dice: 0.1102\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.8899 - dice: 0.1101 - val_loss: 0.8897 - val_dice: 0.1103\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.0001, 'loss': <function categorical_cross_entropy_loss at 0x7bccb964dcf0>, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>}\n",
            "Model: \"model_49\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_50 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_49 (Lambda)          (None, 256, 256, 3)          0         ['input_50[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_931 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_49[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_441 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_931[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_932 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_441[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_196 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_932[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_933 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_196[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_442 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_933[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_934 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_442[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_197 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_934[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_935 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_197[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_443 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_935[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_936 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_443[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_198 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_936[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_937 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_198[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_444 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_937[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_938 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_444[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_199 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_938[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_939 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_199[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_445 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_939[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_940 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_445[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_196 (Conv  (None, 32, 32, 128)          131200    ['conv2d_940[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_196 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_196[0][0]',\n",
            " te)                                                                 'conv2d_938[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_941 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_196[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_446 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_941[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_942 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_446[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_197 (Conv  (None, 64, 64, 64)           32832     ['conv2d_942[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_197 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_197[0][0]',\n",
            " te)                                                                 'conv2d_936[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_943 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_197[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_447 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_943[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_944 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_447[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_198 (Conv  (None, 128, 128, 32)         8224      ['conv2d_944[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_198 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_198[0][0]',\n",
            " te)                                                                 'conv2d_934[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_945 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_198[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_448 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_945[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_946 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_448[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_199 (Conv  (None, 256, 256, 16)         2064      ['conv2d_946[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_199 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_199[0][0]',\n",
            " te)                                                                 'conv2d_932[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_947 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_199[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_449 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_947[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_948 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_449[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_949 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_948[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 9s 718ms/step - loss: 2.6109 - dice: 0.1428 - val_loss: 2.3881 - val_dice: 0.1484\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 2.3576 - dice: 0.1596 - val_loss: 2.2329 - val_dice: 0.1621\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 2.2301 - dice: 0.1699 - val_loss: 2.1219 - val_dice: 0.1722\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 2.1172 - dice: 0.1800 - val_loss: 2.0217 - val_dice: 0.1833\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 2s 654ms/step - loss: 2.0265 - dice: 0.1913 - val_loss: 1.9182 - val_dice: 0.1981\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 3s 723ms/step - loss: 1.9280 - dice: 0.2068 - val_loss: 1.8208 - val_dice: 0.2141\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 2s 611ms/step - loss: 1.8357 - dice: 0.2256 - val_loss: 1.7175 - val_dice: 0.2380\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 1.7561 - dice: 0.2468 - val_loss: 1.6523 - val_dice: 0.2530\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 1.6898 - dice: 0.2654 - val_loss: 1.5794 - val_dice: 0.2777\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.6230 - dice: 0.2879 - val_loss: 1.5443 - val_dice: 0.2867\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 3s 692ms/step - loss: 1.5862 - dice: 0.3017 - val_loss: 1.4971 - val_dice: 0.3073\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 1.5447 - dice: 0.3161 - val_loss: 1.4436 - val_dice: 0.3352\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 1.5126 - dice: 0.3289 - val_loss: 1.4077 - val_dice: 0.3486\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 1.4587 - dice: 0.3480 - val_loss: 1.3788 - val_dice: 0.3545\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 2s 609ms/step - loss: 1.4801 - dice: 0.3567 - val_loss: 1.3368 - val_dice: 0.3775\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 1.4045 - dice: 0.3724 - val_loss: 1.3454 - val_dice: 0.3593\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 1.4443 - dice: 0.3799 - val_loss: 1.2825 - val_dice: 0.4201\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.3578 - dice: 0.3939 - val_loss: 1.3270 - val_dice: 0.4593\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 1.3364 - dice: 0.4107 - val_loss: 1.3108 - val_dice: 0.4780\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.0001, 'loss': <function categorical_cross_entropy_loss at 0x7bccb964dcf0>, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>}\n",
            "Model: \"model_50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_51 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_50 (Lambda)          (None, 256, 256, 3)          0         ['input_51[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_950 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_50[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_450 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_950[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_951 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_450[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_200 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_951[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_952 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_200[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_451 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_952[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_953 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_451[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_201 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_953[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_954 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_201[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_452 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_954[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_955 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_452[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_202 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_955[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_956 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_202[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_453 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_956[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_957 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_453[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_203 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_957[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_958 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_203[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_454 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_958[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_959 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_454[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_200 (Conv  (None, 32, 32, 128)          131200    ['conv2d_959[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_200 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_200[0][0]',\n",
            " te)                                                                 'conv2d_957[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_960 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_200[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_455 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_960[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_961 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_455[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_201 (Conv  (None, 64, 64, 64)           32832     ['conv2d_961[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_201 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_201[0][0]',\n",
            " te)                                                                 'conv2d_955[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_962 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_201[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_456 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_962[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_963 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_456[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_202 (Conv  (None, 128, 128, 32)         8224      ['conv2d_963[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_202 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_202[0][0]',\n",
            " te)                                                                 'conv2d_953[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_964 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_202[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_457 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_964[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_965 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_457[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_203 (Conv  (None, 256, 256, 16)         2064      ['conv2d_965[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_203 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_203[0][0]',\n",
            " te)                                                                 'conv2d_951[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_966 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_203[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_458 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_966[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_967 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_458[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_968 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_967[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 10s 658ms/step - loss: 2.5018 - dice: 0.1027 - val_loss: 2.2928 - val_dice: 0.1131\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 2.3484 - dice: 0.1172 - val_loss: 2.1828 - val_dice: 0.1271\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 2.2349 - dice: 0.1318 - val_loss: 2.0826 - val_dice: 0.1418\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 2.1317 - dice: 0.1477 - val_loss: 1.9848 - val_dice: 0.1590\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 3s 702ms/step - loss: 2.0304 - dice: 0.1673 - val_loss: 1.8873 - val_dice: 0.1801\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 1.9403 - dice: 0.1893 - val_loss: 1.7960 - val_dice: 0.2033\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 1.8574 - dice: 0.2123 - val_loss: 1.7177 - val_dice: 0.2259\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 1.7774 - dice: 0.2363 - val_loss: 1.6363 - val_dice: 0.2533\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 1.7057 - dice: 0.2628 - val_loss: 1.5632 - val_dice: 0.2802\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 3s 668ms/step - loss: 1.6285 - dice: 0.2885 - val_loss: 1.4876 - val_dice: 0.3170\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 1.5430 - dice: 0.3195 - val_loss: 1.4467 - val_dice: 0.3691\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 2s 534ms/step - loss: 1.4756 - dice: 0.3578 - val_loss: 1.4077 - val_dice: 0.4159\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 1.4029 - dice: 0.3965 - val_loss: 1.3800 - val_dice: 0.4638\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 3s 732ms/step - loss: 1.3471 - dice: 0.4124 - val_loss: 1.5760 - val_dice: 0.4964\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 1.3264 - dice: 0.4378 - val_loss: 1.5413 - val_dice: 0.5300\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.0001, 'loss': <function categorical_cross_entropy_loss at 0x7bccb964dcf0>, 'optimizer': <class 'keras.src.optimizers.sgd.SGD'>}\n",
            "Model: \"model_51\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_52 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_51 (Lambda)          (None, 256, 256, 3)          0         ['input_52[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_969 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_51[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_459 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_969[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_970 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_459[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_204 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_970[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_971 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_204[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_460 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_971[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_972 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_460[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_205 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_972[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_973 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_205[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_461 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_973[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_974 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_461[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_206 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_974[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_975 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_206[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_462 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_975[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_976 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_462[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_207 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_976[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_977 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_207[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_463 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_977[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_978 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_463[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_204 (Conv  (None, 32, 32, 128)          131200    ['conv2d_978[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_204 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_204[0][0]',\n",
            " te)                                                                 'conv2d_976[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_979 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_204[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_464 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_979[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_980 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_464[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_205 (Conv  (None, 64, 64, 64)           32832     ['conv2d_980[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_205 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_205[0][0]',\n",
            " te)                                                                 'conv2d_974[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_981 (Conv2D)         (None, 64, 64, 64)           73792     ['concatenate_205[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_465 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_981[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_982 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_465[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_206 (Conv  (None, 128, 128, 32)         8224      ['conv2d_982[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_206 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_206[0][0]',\n",
            " te)                                                                 'conv2d_972[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_983 (Conv2D)         (None, 128, 128, 32)         18464     ['concatenate_206[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_466 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_983[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_984 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_466[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_207 (Conv  (None, 256, 256, 16)         2064      ['conv2d_984[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_207 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_207[0][0]',\n",
            " te)                                                                 'conv2d_970[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_985 (Conv2D)         (None, 256, 256, 16)         4624      ['concatenate_207[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_467 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_985[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_986 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_467[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_987 (Conv2D)         (None, 256, 256, 10)         170       ['conv2d_986[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 7s 806ms/step - loss: 2.7024 - dice: 0.0887 - val_loss: 2.5848 - val_dice: 0.0874\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 3s 639ms/step - loss: 2.6940 - dice: 0.0889 - val_loss: 2.5783 - val_dice: 0.0879\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 2.6826 - dice: 0.0899 - val_loss: 2.5720 - val_dice: 0.0884\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 2.6802 - dice: 0.0902 - val_loss: 2.5658 - val_dice: 0.0889\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 2.6728 - dice: 0.0908 - val_loss: 2.5596 - val_dice: 0.0894\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 3s 675ms/step - loss: 2.6695 - dice: 0.0909 - val_loss: 2.5534 - val_dice: 0.0899\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 2.6598 - dice: 0.0915 - val_loss: 2.5473 - val_dice: 0.0904\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 2.6525 - dice: 0.0923 - val_loss: 2.5412 - val_dice: 0.0909\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 2.6464 - dice: 0.0926 - val_loss: 2.5352 - val_dice: 0.0914\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 2s 644ms/step - loss: 2.6401 - dice: 0.0932 - val_loss: 2.5293 - val_dice: 0.0919\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 3s 727ms/step - loss: 2.6319 - dice: 0.0936 - val_loss: 2.5234 - val_dice: 0.0924\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 2.6248 - dice: 0.0943 - val_loss: 2.5176 - val_dice: 0.0928\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 2.6200 - dice: 0.0947 - val_loss: 2.5118 - val_dice: 0.0933\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 2.6151 - dice: 0.0951 - val_loss: 2.5061 - val_dice: 0.0938\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 3s 684ms/step - loss: 2.6048 - dice: 0.0957 - val_loss: 2.5005 - val_dice: 0.0943\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 2.6036 - dice: 0.0958 - val_loss: 2.4949 - val_dice: 0.0948\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 2s 627ms/step - loss: 2.5954 - dice: 0.0967 - val_loss: 2.4893 - val_dice: 0.0953\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 2.5920 - dice: 0.0971 - val_loss: 2.4838 - val_dice: 0.0958\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 2s 632ms/step - loss: 2.5792 - dice: 0.0979 - val_loss: 2.4783 - val_dice: 0.0963\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 3s 731ms/step - loss: 2.5780 - dice: 0.0981 - val_loss: 2.4729 - val_dice: 0.0968\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 2s 604ms/step - loss: 2.5724 - dice: 0.0987 - val_loss: 2.4676 - val_dice: 0.0973\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 2.5655 - dice: 0.0993 - val_loss: 2.4622 - val_dice: 0.0978\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 2.5579 - dice: 0.0998 - val_loss: 2.4568 - val_dice: 0.0983\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 2.5527 - dice: 0.1005 - val_loss: 2.4516 - val_dice: 0.0988\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 2s 628ms/step - loss: 2.5505 - dice: 0.1006 - val_loss: 2.4464 - val_dice: 0.0993\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 3s 689ms/step - loss: 2.5424 - dice: 0.1012 - val_loss: 2.4412 - val_dice: 0.0998\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 2s 583ms/step - loss: 2.5346 - dice: 0.1018 - val_loss: 2.4360 - val_dice: 0.1003\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 2.5260 - dice: 0.1026 - val_loss: 2.4309 - val_dice: 0.1008\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 2.5265 - dice: 0.1029 - val_loss: 2.4259 - val_dice: 0.1014\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 2.5203 - dice: 0.1032 - val_loss: 2.4210 - val_dice: 0.1018\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 2s 640ms/step - loss: 2.5131 - dice: 0.1038 - val_loss: 2.4159 - val_dice: 0.1024\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 3s 721ms/step - loss: 2.5099 - dice: 0.1043 - val_loss: 2.4110 - val_dice: 0.1029\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 3s 634ms/step - loss: 2.5038 - dice: 0.1049 - val_loss: 2.4061 - val_dice: 0.1034\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 2.4985 - dice: 0.1054 - val_loss: 2.4013 - val_dice: 0.1039\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 2.4953 - dice: 0.1059 - val_loss: 2.3964 - val_dice: 0.1044\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 2s 600ms/step - loss: 2.4859 - dice: 0.1066 - val_loss: 2.3916 - val_dice: 0.1049\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 3s 729ms/step - loss: 2.4834 - dice: 0.1069 - val_loss: 2.3868 - val_dice: 0.1054\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 3s 639ms/step - loss: 2.4787 - dice: 0.1074 - val_loss: 2.3821 - val_dice: 0.1059\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 2s 580ms/step - loss: 2.4664 - dice: 0.1084 - val_loss: 2.3774 - val_dice: 0.1064\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 2.4704 - dice: 0.1083 - val_loss: 2.3728 - val_dice: 0.1069\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 2s 576ms/step - loss: 2.4614 - dice: 0.1092 - val_loss: 2.3681 - val_dice: 0.1075\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 2s 628ms/step - loss: 2.4553 - dice: 0.1098 - val_loss: 2.3635 - val_dice: 0.1080\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 3s 759ms/step - loss: 2.4516 - dice: 0.1101 - val_loss: 2.3590 - val_dice: 0.1085\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 2.4437 - dice: 0.1108 - val_loss: 2.3544 - val_dice: 0.1090\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 2.4424 - dice: 0.1113 - val_loss: 2.3499 - val_dice: 0.1095\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 2s 574ms/step - loss: 2.4347 - dice: 0.1121 - val_loss: 2.3453 - val_dice: 0.1100\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 2.4327 - dice: 0.1122 - val_loss: 2.3408 - val_dice: 0.1106\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 2.4284 - dice: 0.1128 - val_loss: 2.3364 - val_dice: 0.1111\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 2.4233 - dice: 0.1134 - val_loss: 2.3320 - val_dice: 0.1116\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 2.4170 - dice: 0.1139 - val_loss: 2.3276 - val_dice: 0.1121\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 2s 653ms/step - loss: 2.4146 - dice: 0.1146 - val_loss: 2.3232 - val_dice: 0.1127\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 2.4075 - dice: 0.1152 - val_loss: 2.3189 - val_dice: 0.1132\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 2.4037 - dice: 0.1155 - val_loss: 2.3145 - val_dice: 0.1137\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 2.4023 - dice: 0.1159 - val_loss: 2.3102 - val_dice: 0.1142\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 2.3959 - dice: 0.1165 - val_loss: 2.3060 - val_dice: 0.1148\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 2s 609ms/step - loss: 2.3841 - dice: 0.1176 - val_loss: 2.3017 - val_dice: 0.1153\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 2.3903 - dice: 0.1173 - val_loss: 2.2975 - val_dice: 0.1158\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 3s 637ms/step - loss: 2.3835 - dice: 0.1179 - val_loss: 2.2933 - val_dice: 0.1164\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 2s 576ms/step - loss: 2.3768 - dice: 0.1187 - val_loss: 2.2891 - val_dice: 0.1169\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 2.3717 - dice: 0.1193 - val_loss: 2.2849 - val_dice: 0.1174\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 2.3617 - dice: 0.1204 - val_loss: 2.2808 - val_dice: 0.1180\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 2s 643ms/step - loss: 2.3643 - dice: 0.1202 - val_loss: 2.2767 - val_dice: 0.1185\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 2.3597 - dice: 0.1209 - val_loss: 2.2726 - val_dice: 0.1191\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 2s 581ms/step - loss: 2.3533 - dice: 0.1215 - val_loss: 2.2685 - val_dice: 0.1196\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 2s 638ms/step - loss: 2.3532 - dice: 0.1219 - val_loss: 2.2645 - val_dice: 0.1201\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 2.3462 - dice: 0.1225 - val_loss: 2.2605 - val_dice: 0.1207\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 2.3423 - dice: 0.1231 - val_loss: 2.2565 - val_dice: 0.1212\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 3s 680ms/step - loss: 2.3379 - dice: 0.1236 - val_loss: 2.2525 - val_dice: 0.1218\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 2.3346 - dice: 0.1243 - val_loss: 2.2485 - val_dice: 0.1223\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 2.3335 - dice: 0.1243 - val_loss: 2.2446 - val_dice: 0.1229\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 2s 645ms/step - loss: 2.3258 - dice: 0.1252 - val_loss: 2.2407 - val_dice: 0.1234\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 2.3222 - dice: 0.1258 - val_loss: 2.2368 - val_dice: 0.1239\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 3s 770ms/step - loss: 2.3150 - dice: 0.1266 - val_loss: 2.2329 - val_dice: 0.1245\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 2.3161 - dice: 0.1268 - val_loss: 2.2290 - val_dice: 0.1251\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 2.3019 - dice: 0.1284 - val_loss: 2.2251 - val_dice: 0.1256\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 2s 577ms/step - loss: 2.3042 - dice: 0.1282 - val_loss: 2.2213 - val_dice: 0.1262\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 2s 643ms/step - loss: 2.3038 - dice: 0.1284 - val_loss: 2.2175 - val_dice: 0.1267\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 3s 734ms/step - loss: 2.2994 - dice: 0.1294 - val_loss: 2.2137 - val_dice: 0.1273\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 2.2939 - dice: 0.1298 - val_loss: 2.2099 - val_dice: 0.1278\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 2.2911 - dice: 0.1301 - val_loss: 2.2062 - val_dice: 0.1284\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 2.2867 - dice: 0.1307 - val_loss: 2.2025 - val_dice: 0.1290\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 2s 615ms/step - loss: 2.2817 - dice: 0.1314 - val_loss: 2.1988 - val_dice: 0.1295\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 3s 754ms/step - loss: 2.2765 - dice: 0.1325 - val_loss: 2.1951 - val_dice: 0.1301\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 2.2707 - dice: 0.1331 - val_loss: 2.1914 - val_dice: 0.1307\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 2.2737 - dice: 0.1328 - val_loss: 2.1877 - val_dice: 0.1312\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 2.2666 - dice: 0.1339 - val_loss: 2.1841 - val_dice: 0.1318\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 2s 576ms/step - loss: 2.2676 - dice: 0.1335 - val_loss: 2.1805 - val_dice: 0.1323\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 2s 622ms/step - loss: 2.2600 - dice: 0.1350 - val_loss: 2.1768 - val_dice: 0.1329\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 3s 723ms/step - loss: 2.2555 - dice: 0.1354 - val_loss: 2.1732 - val_dice: 0.1335\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 2.2508 - dice: 0.1362 - val_loss: 2.1697 - val_dice: 0.1341\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 2.2477 - dice: 0.1368 - val_loss: 2.1661 - val_dice: 0.1346\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 2.2427 - dice: 0.1375 - val_loss: 2.1625 - val_dice: 0.1352\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 2s 651ms/step - loss: 2.2402 - dice: 0.1378 - val_loss: 2.1590 - val_dice: 0.1358\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 3s 730ms/step - loss: 2.2369 - dice: 0.1385 - val_loss: 2.1555 - val_dice: 0.1364\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 2s 581ms/step - loss: 2.2279 - dice: 0.1397 - val_loss: 2.1519 - val_dice: 0.1370\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 2s 626ms/step - loss: 2.2318 - dice: 0.1394 - val_loss: 2.1485 - val_dice: 0.1375\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 2.2223 - dice: 0.1408 - val_loss: 2.1449 - val_dice: 0.1381\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 2.2175 - dice: 0.1415 - val_loss: 2.1415 - val_dice: 0.1387\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 3s 689ms/step - loss: 2.2216 - dice: 0.1412 - val_loss: 2.1380 - val_dice: 0.1393\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 2.2061 - dice: 0.1429 - val_loss: 2.1346 - val_dice: 0.1399\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.0001, 'loss': <function DiceBCELoss at 0x7bcc24dc25f0>, 'optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>}\n",
            "Model: \"model_52\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_53 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_52 (Lambda)          (None, 256, 256, 3)          0         ['input_53[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_988 (Conv2D)         (None, 256, 256, 16)         448       ['lambda_52[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_468 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_988[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_989 (Conv2D)         (None, 256, 256, 16)         2320      ['dropout_468[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_208 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_989[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_990 (Conv2D)         (None, 128, 128, 32)         4640      ['max_pooling2d_208[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_469 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_990[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_991 (Conv2D)         (None, 128, 128, 32)         9248      ['dropout_469[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_209 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_991[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_992 (Conv2D)         (None, 64, 64, 64)           18496     ['max_pooling2d_209[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_470 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_992[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_993 (Conv2D)         (None, 64, 64, 64)           36928     ['dropout_470[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_210 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_993[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_994 (Conv2D)         (None, 32, 32, 128)          73856     ['max_pooling2d_210[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_471 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_994[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_995 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_471[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_211 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_995[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_996 (Conv2D)         (None, 16, 16, 256)          295168    ['max_pooling2d_211[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_472 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_996[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_997 (Conv2D)         (None, 16, 16, 256)          590080    ['dropout_472[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_208 (Conv  (None, 32, 32, 128)          131200    ['conv2d_997[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_208 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_208[0][0]',\n",
            " te)                                                                 'conv2d_995[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_998 (Conv2D)         (None, 32, 32, 128)          295040    ['concatenate_208[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_473 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_998[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_999 (Conv2D)         (None, 32, 32, 128)          147584    ['dropout_473[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_209 (Conv  (None, 64, 64, 64)           32832     ['conv2d_999[0][0]']          \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_209 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_209[0][0]',\n",
            " te)                                                                 'conv2d_993[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_1000 (Conv2D)        (None, 64, 64, 64)           73792     ['concatenate_209[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_474 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_1000[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1001 (Conv2D)        (None, 64, 64, 64)           36928     ['dropout_474[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_210 (Conv  (None, 128, 128, 32)         8224      ['conv2d_1001[0][0]']         \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_210 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_210[0][0]',\n",
            " te)                                                                 'conv2d_991[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_1002 (Conv2D)        (None, 128, 128, 32)         18464     ['concatenate_210[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_475 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_1002[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1003 (Conv2D)        (None, 128, 128, 32)         9248      ['dropout_475[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_211 (Conv  (None, 256, 256, 16)         2064      ['conv2d_1003[0][0]']         \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_211 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_211[0][0]',\n",
            " te)                                                                 'conv2d_989[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_1004 (Conv2D)        (None, 256, 256, 16)         4624      ['concatenate_211[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_476 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_1004[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1005 (Conv2D)        (None, 256, 256, 16)         2320      ['dropout_476[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1006 (Conv2D)        (None, 256, 256, 10)         170       ['conv2d_1005[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 8s 839ms/step - loss: 1.6323 - dice: 0.1127 - val_loss: 1.4888 - val_dice: 0.1242\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 3s 692ms/step - loss: 1.4652 - dice: 0.1424 - val_loss: 1.3664 - val_dice: 0.1604\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.3564 - dice: 0.1746 - val_loss: 1.2810 - val_dice: 0.1935\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 1.2785 - dice: 0.2064 - val_loss: 1.2055 - val_dice: 0.2298\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 1.2059 - dice: 0.2425 - val_loss: 1.1227 - val_dice: 0.2775\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 2s 632ms/step - loss: 1.1335 - dice: 0.2859 - val_loss: 1.0388 - val_dice: 0.3338\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 3s 785ms/step - loss: 1.0641 - dice: 0.3352 - val_loss: 0.9569 - val_dice: 0.3942\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 3s 617ms/step - loss: 0.9964 - dice: 0.3880 - val_loss: 0.9044 - val_dice: 0.4368\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.9585 - dice: 0.4217 - val_loss: 0.8691 - val_dice: 0.4640\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 0.9262 - dice: 0.4463 - val_loss: 0.8435 - val_dice: 0.4840\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 0.9057 - dice: 0.4617 - val_loss: 0.8267 - val_dice: 0.4951\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 2s 643ms/step - loss: 0.8937 - dice: 0.4686 - val_loss: 0.8143 - val_dice: 0.5012\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 3s 758ms/step - loss: 0.8752 - dice: 0.4776 - val_loss: 0.8032 - val_dice: 0.5083\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 2s 589ms/step - loss: 0.8626 - dice: 0.4840 - val_loss: 0.7954 - val_dice: 0.5117\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.8496 - dice: 0.4893 - val_loss: 0.7873 - val_dice: 0.5147\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 0.8501 - dice: 0.4861 - val_loss: 0.7809 - val_dice: 0.5130\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 0.8260 - dice: 0.4965 - val_loss: 0.7691 - val_dice: 0.5238\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 3s 709ms/step - loss: 0.8245 - dice: 0.4986 - val_loss: 0.7661 - val_dice: 0.5203\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.8096 - dice: 0.5014 - val_loss: 0.7519 - val_dice: 0.5321\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.8064 - dice: 0.5026 - val_loss: 0.7438 - val_dice: 0.5348\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 0.7910 - dice: 0.5099 - val_loss: 0.7318 - val_dice: 0.5394\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 2s 633ms/step - loss: 0.7843 - dice: 0.5121 - val_loss: 0.7285 - val_dice: 0.5478\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.7732 - dice: 0.5168 - val_loss: 0.7355 - val_dice: 0.5529\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 2s 540ms/step - loss: 0.7665 - dice: 0.5198 - val_loss: 0.7406 - val_dice: 0.5555\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.0001, 'loss': <function DiceBCELoss at 0x7bcc24dc25f0>, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>}\n",
            "Model: \"model_53\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_54 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_53 (Lambda)          (None, 256, 256, 3)          0         ['input_54[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_1007 (Conv2D)        (None, 256, 256, 16)         448       ['lambda_53[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_477 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_1007[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1008 (Conv2D)        (None, 256, 256, 16)         2320      ['dropout_477[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_212 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_1008[0][0]']         \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_1009 (Conv2D)        (None, 128, 128, 32)         4640      ['max_pooling2d_212[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_478 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_1009[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1010 (Conv2D)        (None, 128, 128, 32)         9248      ['dropout_478[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_213 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_1010[0][0]']         \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_1011 (Conv2D)        (None, 64, 64, 64)           18496     ['max_pooling2d_213[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_479 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_1011[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1012 (Conv2D)        (None, 64, 64, 64)           36928     ['dropout_479[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_214 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_1012[0][0]']         \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_1013 (Conv2D)        (None, 32, 32, 128)          73856     ['max_pooling2d_214[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_480 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_1013[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1014 (Conv2D)        (None, 32, 32, 128)          147584    ['dropout_480[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_215 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_1014[0][0]']         \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_1015 (Conv2D)        (None, 16, 16, 256)          295168    ['max_pooling2d_215[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_481 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_1015[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1016 (Conv2D)        (None, 16, 16, 256)          590080    ['dropout_481[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_212 (Conv  (None, 32, 32, 128)          131200    ['conv2d_1016[0][0]']         \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_212 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_212[0][0]',\n",
            " te)                                                                 'conv2d_1014[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1017 (Conv2D)        (None, 32, 32, 128)          295040    ['concatenate_212[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_482 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_1017[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1018 (Conv2D)        (None, 32, 32, 128)          147584    ['dropout_482[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_213 (Conv  (None, 64, 64, 64)           32832     ['conv2d_1018[0][0]']         \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_213 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_213[0][0]',\n",
            " te)                                                                 'conv2d_1012[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1019 (Conv2D)        (None, 64, 64, 64)           73792     ['concatenate_213[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_483 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_1019[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1020 (Conv2D)        (None, 64, 64, 64)           36928     ['dropout_483[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_214 (Conv  (None, 128, 128, 32)         8224      ['conv2d_1020[0][0]']         \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_214 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_214[0][0]',\n",
            " te)                                                                 'conv2d_1010[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1021 (Conv2D)        (None, 128, 128, 32)         18464     ['concatenate_214[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_484 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_1021[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1022 (Conv2D)        (None, 128, 128, 32)         9248      ['dropout_484[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_215 (Conv  (None, 256, 256, 16)         2064      ['conv2d_1022[0][0]']         \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_215 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_215[0][0]',\n",
            " te)                                                                 'conv2d_1008[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1023 (Conv2D)        (None, 256, 256, 16)         4624      ['concatenate_215[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_485 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_1023[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1024 (Conv2D)        (None, 256, 256, 16)         2320      ['dropout_485[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1025 (Conv2D)        (None, 256, 256, 10)         170       ['conv2d_1024[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 11s 702ms/step - loss: 1.6210 - dice: 0.1100 - val_loss: 1.5568 - val_dice: 0.1213\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.5639 - dice: 0.1206 - val_loss: 1.5106 - val_dice: 0.1343\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 1.5140 - dice: 0.1338 - val_loss: 1.4643 - val_dice: 0.1486\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.4665 - dice: 0.1489 - val_loss: 1.4151 - val_dice: 0.1653\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 2s 576ms/step - loss: 1.4180 - dice: 0.1680 - val_loss: 1.3605 - val_dice: 0.1879\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 1.3711 - dice: 0.1905 - val_loss: 1.3005 - val_dice: 0.2171\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 2s 578ms/step - loss: 1.3178 - dice: 0.2212 - val_loss: 1.2390 - val_dice: 0.2508\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 2s 640ms/step - loss: 1.2611 - dice: 0.2581 - val_loss: 1.1785 - val_dice: 0.2867\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 3s 773ms/step - loss: 1.2169 - dice: 0.2844 - val_loss: 1.1221 - val_dice: 0.3211\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.1657 - dice: 0.3184 - val_loss: 1.0586 - val_dice: 0.3637\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 1.1126 - dice: 0.3529 - val_loss: 0.9967 - val_dice: 0.4064\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 1.0648 - dice: 0.3803 - val_loss: 0.9332 - val_dice: 0.4597\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 3s 710ms/step - loss: 1.0191 - dice: 0.4035 - val_loss: 0.9205 - val_dice: 0.5140\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 0.9746 - dice: 0.4382 - val_loss: 0.8692 - val_dice: 0.5332\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 0.9418 - dice: 0.4578 - val_loss: 0.8493 - val_dice: 0.5465\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 0.9077 - dice: 0.4643 - val_loss: 0.8970 - val_dice: 0.5578\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.8832 - dice: 0.4811 - val_loss: 0.8699 - val_dice: 0.5615\n",
            "\n",
            "Training model with parameters: {'batch_size': 32, 'learning_rate': 0.0001, 'loss': <function DiceBCELoss at 0x7bcc24dc25f0>, 'optimizer': <class 'keras.src.optimizers.sgd.SGD'>}\n",
            "Model: \"model_54\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_55 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " lambda_54 (Lambda)          (None, 256, 256, 3)          0         ['input_55[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_1026 (Conv2D)        (None, 256, 256, 16)         448       ['lambda_54[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_486 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_1026[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1027 (Conv2D)        (None, 256, 256, 16)         2320      ['dropout_486[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_216 (MaxPool  (None, 128, 128, 16)         0         ['conv2d_1027[0][0]']         \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_1028 (Conv2D)        (None, 128, 128, 32)         4640      ['max_pooling2d_216[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_487 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_1028[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1029 (Conv2D)        (None, 128, 128, 32)         9248      ['dropout_487[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_217 (MaxPool  (None, 64, 64, 32)           0         ['conv2d_1029[0][0]']         \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_1030 (Conv2D)        (None, 64, 64, 64)           18496     ['max_pooling2d_217[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_488 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_1030[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1031 (Conv2D)        (None, 64, 64, 64)           36928     ['dropout_488[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_218 (MaxPool  (None, 32, 32, 64)           0         ['conv2d_1031[0][0]']         \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_1032 (Conv2D)        (None, 32, 32, 128)          73856     ['max_pooling2d_218[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_489 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_1032[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1033 (Conv2D)        (None, 32, 32, 128)          147584    ['dropout_489[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_219 (MaxPool  (None, 16, 16, 128)          0         ['conv2d_1033[0][0]']         \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_1034 (Conv2D)        (None, 16, 16, 256)          295168    ['max_pooling2d_219[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_490 (Dropout)       (None, 16, 16, 256)          0         ['conv2d_1034[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1035 (Conv2D)        (None, 16, 16, 256)          590080    ['dropout_490[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_216 (Conv  (None, 32, 32, 128)          131200    ['conv2d_1035[0][0]']         \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_216 (Concatena  (None, 32, 32, 256)          0         ['conv2d_transpose_216[0][0]',\n",
            " te)                                                                 'conv2d_1033[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1036 (Conv2D)        (None, 32, 32, 128)          295040    ['concatenate_216[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_491 (Dropout)       (None, 32, 32, 128)          0         ['conv2d_1036[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1037 (Conv2D)        (None, 32, 32, 128)          147584    ['dropout_491[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_217 (Conv  (None, 64, 64, 64)           32832     ['conv2d_1037[0][0]']         \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_217 (Concatena  (None, 64, 64, 128)          0         ['conv2d_transpose_217[0][0]',\n",
            " te)                                                                 'conv2d_1031[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1038 (Conv2D)        (None, 64, 64, 64)           73792     ['concatenate_217[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_492 (Dropout)       (None, 64, 64, 64)           0         ['conv2d_1038[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1039 (Conv2D)        (None, 64, 64, 64)           36928     ['dropout_492[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_218 (Conv  (None, 128, 128, 32)         8224      ['conv2d_1039[0][0]']         \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_218 (Concatena  (None, 128, 128, 64)         0         ['conv2d_transpose_218[0][0]',\n",
            " te)                                                                 'conv2d_1029[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1040 (Conv2D)        (None, 128, 128, 32)         18464     ['concatenate_218[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_493 (Dropout)       (None, 128, 128, 32)         0         ['conv2d_1040[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1041 (Conv2D)        (None, 128, 128, 32)         9248      ['dropout_493[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_219 (Conv  (None, 256, 256, 16)         2064      ['conv2d_1041[0][0]']         \n",
            " 2DTranspose)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate_219 (Concatena  (None, 256, 256, 32)         0         ['conv2d_transpose_219[0][0]',\n",
            " te)                                                                 'conv2d_1027[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1042 (Conv2D)        (None, 256, 256, 16)         4624      ['concatenate_219[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_494 (Dropout)       (None, 256, 256, 16)         0         ['conv2d_1042[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1043 (Conv2D)        (None, 256, 256, 16)         2320      ['dropout_494[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1044 (Conv2D)        (None, 256, 256, 10)         170       ['conv2d_1043[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1941258 (7.41 MB)\n",
            "Trainable params: 1941258 (7.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 6s 667ms/step - loss: 1.7272 - dice: 0.0931 - val_loss: 1.6771 - val_dice: 0.0932\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 3s 703ms/step - loss: 1.7259 - dice: 0.0934 - val_loss: 1.6766 - val_dice: 0.0932\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 1.7256 - dice: 0.0932 - val_loss: 1.6762 - val_dice: 0.0933\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 1.7259 - dice: 0.0931 - val_loss: 1.6757 - val_dice: 0.0933\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 1.7243 - dice: 0.0934 - val_loss: 1.6752 - val_dice: 0.0933\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 1.7246 - dice: 0.0931 - val_loss: 1.6748 - val_dice: 0.0934\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 3s 760ms/step - loss: 1.7234 - dice: 0.0931 - val_loss: 1.6743 - val_dice: 0.0934\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.7226 - dice: 0.0934 - val_loss: 1.6739 - val_dice: 0.0934\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 1.7221 - dice: 0.0936 - val_loss: 1.6734 - val_dice: 0.0934\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 2s 595ms/step - loss: 1.7217 - dice: 0.0937 - val_loss: 1.6730 - val_dice: 0.0935\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 2s 630ms/step - loss: 1.7210 - dice: 0.0936 - val_loss: 1.6725 - val_dice: 0.0935\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 3s 766ms/step - loss: 1.7198 - dice: 0.0936 - val_loss: 1.6721 - val_dice: 0.0935\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 2s 578ms/step - loss: 1.7212 - dice: 0.0935 - val_loss: 1.6717 - val_dice: 0.0936\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 1.7185 - dice: 0.0937 - val_loss: 1.6712 - val_dice: 0.0936\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 2s 581ms/step - loss: 1.7187 - dice: 0.0938 - val_loss: 1.6708 - val_dice: 0.0936\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 3s 652ms/step - loss: 1.7187 - dice: 0.0936 - val_loss: 1.6703 - val_dice: 0.0937\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 1.7179 - dice: 0.0938 - val_loss: 1.6699 - val_dice: 0.0937\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 2s 581ms/step - loss: 1.7171 - dice: 0.0939 - val_loss: 1.6695 - val_dice: 0.0937\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 1.7172 - dice: 0.0937 - val_loss: 1.6690 - val_dice: 0.0938\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 1.7162 - dice: 0.0938 - val_loss: 1.6686 - val_dice: 0.0938\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 2s 580ms/step - loss: 1.7160 - dice: 0.0938 - val_loss: 1.6682 - val_dice: 0.0938\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 2s 642ms/step - loss: 1.7152 - dice: 0.0940 - val_loss: 1.6678 - val_dice: 0.0939\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 3s 720ms/step - loss: 1.7144 - dice: 0.0940 - val_loss: 1.6673 - val_dice: 0.0939\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 1.7143 - dice: 0.0940 - val_loss: 1.6669 - val_dice: 0.0939\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 1.7130 - dice: 0.0940 - val_loss: 1.6665 - val_dice: 0.0940\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.7133 - dice: 0.0939 - val_loss: 1.6661 - val_dice: 0.0940\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 3s 691ms/step - loss: 1.7135 - dice: 0.0940 - val_loss: 1.6656 - val_dice: 0.0940\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 3s 765ms/step - loss: 1.7125 - dice: 0.0940 - val_loss: 1.6652 - val_dice: 0.0940\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 1.7108 - dice: 0.0943 - val_loss: 1.6648 - val_dice: 0.0941\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 1.7110 - dice: 0.0942 - val_loss: 1.6644 - val_dice: 0.0941\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 2s 580ms/step - loss: 1.7105 - dice: 0.0941 - val_loss: 1.6640 - val_dice: 0.0941\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7109 - dice: 0.0941 - val_loss: 1.6636 - val_dice: 0.0942\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 3s 731ms/step - loss: 1.7090 - dice: 0.0944 - val_loss: 1.6632 - val_dice: 0.0942\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 2s 544ms/step - loss: 1.7084 - dice: 0.0944 - val_loss: 1.6628 - val_dice: 0.0942\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 1.7073 - dice: 0.0945 - val_loss: 1.6624 - val_dice: 0.0943\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 2s 586ms/step - loss: 1.7075 - dice: 0.0945 - val_loss: 1.6620 - val_dice: 0.0943\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 1.7067 - dice: 0.0946 - val_loss: 1.6616 - val_dice: 0.0943\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 3s 668ms/step - loss: 1.7072 - dice: 0.0944 - val_loss: 1.6611 - val_dice: 0.0944\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 1.7058 - dice: 0.0947 - val_loss: 1.6607 - val_dice: 0.0944\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 1.7056 - dice: 0.0946 - val_loss: 1.6603 - val_dice: 0.0944\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.7054 - dice: 0.0946 - val_loss: 1.6600 - val_dice: 0.0945\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 1.7047 - dice: 0.0948 - val_loss: 1.6596 - val_dice: 0.0945\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 1.7042 - dice: 0.0947 - val_loss: 1.6592 - val_dice: 0.0945\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 1.7048 - dice: 0.0946 - val_loss: 1.6588 - val_dice: 0.0946\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 2s 638ms/step - loss: 1.7036 - dice: 0.0946 - val_loss: 1.6584 - val_dice: 0.0946\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.7019 - dice: 0.0948 - val_loss: 1.6580 - val_dice: 0.0946\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 2s 643ms/step - loss: 1.7031 - dice: 0.0948 - val_loss: 1.6576 - val_dice: 0.0946\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 3s 730ms/step - loss: 1.7026 - dice: 0.0948 - val_loss: 1.6572 - val_dice: 0.0947\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 1.7008 - dice: 0.0949 - val_loss: 1.6568 - val_dice: 0.0947\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.7008 - dice: 0.0950 - val_loss: 1.6564 - val_dice: 0.0947\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.7007 - dice: 0.0949 - val_loss: 1.6560 - val_dice: 0.0948\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 2s 621ms/step - loss: 1.7001 - dice: 0.0951 - val_loss: 1.6557 - val_dice: 0.0948\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 3s 793ms/step - loss: 1.7002 - dice: 0.0950 - val_loss: 1.6553 - val_dice: 0.0948\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 2s 596ms/step - loss: 1.6993 - dice: 0.0949 - val_loss: 1.6549 - val_dice: 0.0949\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 1.6987 - dice: 0.0951 - val_loss: 1.6545 - val_dice: 0.0949\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 1.6996 - dice: 0.0950 - val_loss: 1.6541 - val_dice: 0.0949\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.6981 - dice: 0.0952 - val_loss: 1.6538 - val_dice: 0.0950\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 3s 734ms/step - loss: 1.6977 - dice: 0.0950 - val_loss: 1.6534 - val_dice: 0.0950\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 1.6977 - dice: 0.0951 - val_loss: 1.6530 - val_dice: 0.0950\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.6962 - dice: 0.0953 - val_loss: 1.6526 - val_dice: 0.0951\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 2s 580ms/step - loss: 1.6964 - dice: 0.0951 - val_loss: 1.6523 - val_dice: 0.0951\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 2s 574ms/step - loss: 1.6958 - dice: 0.0953 - val_loss: 1.6519 - val_dice: 0.0951\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 1.6957 - dice: 0.0954 - val_loss: 1.6515 - val_dice: 0.0952\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 3s 703ms/step - loss: 1.6948 - dice: 0.0953 - val_loss: 1.6511 - val_dice: 0.0952\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 2s 581ms/step - loss: 1.6952 - dice: 0.0954 - val_loss: 1.6508 - val_dice: 0.0952\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 2s 578ms/step - loss: 1.6936 - dice: 0.0954 - val_loss: 1.6504 - val_dice: 0.0953\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.6942 - dice: 0.0955 - val_loss: 1.6500 - val_dice: 0.0953\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 2s 599ms/step - loss: 1.6928 - dice: 0.0956 - val_loss: 1.6497 - val_dice: 0.0953\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 3s 789ms/step - loss: 1.6928 - dice: 0.0955 - val_loss: 1.6493 - val_dice: 0.0954\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 3s 622ms/step - loss: 1.6922 - dice: 0.0956 - val_loss: 1.6489 - val_dice: 0.0954\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 1.6915 - dice: 0.0956 - val_loss: 1.6486 - val_dice: 0.0954\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 1.6919 - dice: 0.0955 - val_loss: 1.6482 - val_dice: 0.0955\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 1.6906 - dice: 0.0958 - val_loss: 1.6478 - val_dice: 0.0955\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 2s 656ms/step - loss: 1.6909 - dice: 0.0956 - val_loss: 1.6475 - val_dice: 0.0955\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 3s 754ms/step - loss: 1.6902 - dice: 0.0957 - val_loss: 1.6471 - val_dice: 0.0956\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 2s 554ms/step - loss: 1.6902 - dice: 0.0957 - val_loss: 1.6468 - val_dice: 0.0956\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 1.6889 - dice: 0.0959 - val_loss: 1.6464 - val_dice: 0.0956\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 1.6879 - dice: 0.0960 - val_loss: 1.6461 - val_dice: 0.0957\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 2s 626ms/step - loss: 1.6885 - dice: 0.0958 - val_loss: 1.6457 - val_dice: 0.0957\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 3s 769ms/step - loss: 1.6874 - dice: 0.0960 - val_loss: 1.6453 - val_dice: 0.0957\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 3s 681ms/step - loss: 1.6871 - dice: 0.0960 - val_loss: 1.6450 - val_dice: 0.0958\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 1.6871 - dice: 0.0960 - val_loss: 1.6446 - val_dice: 0.0958\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 1.6873 - dice: 0.0960 - val_loss: 1.6443 - val_dice: 0.0958\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 2s 630ms/step - loss: 1.6861 - dice: 0.0962 - val_loss: 1.6440 - val_dice: 0.0958\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 3s 770ms/step - loss: 1.6851 - dice: 0.0962 - val_loss: 1.6436 - val_dice: 0.0959\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 3s 635ms/step - loss: 1.6849 - dice: 0.0962 - val_loss: 1.6433 - val_dice: 0.0959\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 1.6848 - dice: 0.0963 - val_loss: 1.6429 - val_dice: 0.0959\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 1.6852 - dice: 0.0962 - val_loss: 1.6426 - val_dice: 0.0960\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 1.6838 - dice: 0.0962 - val_loss: 1.6422 - val_dice: 0.0960\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 2s 649ms/step - loss: 1.6834 - dice: 0.0964 - val_loss: 1.6419 - val_dice: 0.0960\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 1.6834 - dice: 0.0963 - val_loss: 1.6415 - val_dice: 0.0961\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 1.6825 - dice: 0.0964 - val_loss: 1.6412 - val_dice: 0.0961\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 2s 577ms/step - loss: 1.6827 - dice: 0.0963 - val_loss: 1.6408 - val_dice: 0.0961\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 2s 577ms/step - loss: 1.6820 - dice: 0.0963 - val_loss: 1.6405 - val_dice: 0.0962\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 3s 675ms/step - loss: 1.6826 - dice: 0.0963 - val_loss: 1.6402 - val_dice: 0.0962\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 1.6811 - dice: 0.0966 - val_loss: 1.6398 - val_dice: 0.0962\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 2s 587ms/step - loss: 1.6806 - dice: 0.0965 - val_loss: 1.6395 - val_dice: 0.0963\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 1.6799 - dice: 0.0966 - val_loss: 1.6391 - val_dice: 0.0963\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 2s 577ms/step - loss: 1.6796 - dice: 0.0966 - val_loss: 1.6388 - val_dice: 0.0963\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 2s 649ms/step - loss: 1.6799 - dice: 0.0966 - val_loss: 1.6385 - val_dice: 0.0964\n",
            "Best Hyperparameters for Model 38: {'batch_size': 32, 'learning_rate': 0.001, 'loss': <function DiceLoss at 0x7bcc24dc2680>, 'optimizer': <class 'keras.src.optimizers.adam.Adam'>}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_paths, val_paths = train_test_split(paths, test_size=0.18934911, random_state=42)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'optimizer': [RMSprop, Adam, SGD],  # Use optimizer classes, not strings (RMSprop)\n",
        "    'learning_rate': [1e-3, 1e-4], #1e-2,\n",
        "    'batch_size': [8, 16, 32],\n",
        "    'loss': [DiceLoss, categorical_cross_entropy_loss, DiceBCELoss] #binary_crossentropy_loss,DiceLoss\n",
        "}\n",
        "\n",
        "# Generate all combinations of hyperparameters\n",
        "param_combinations = list(ParameterGrid(param_grid))\n",
        "\n",
        "# Perform grid search\n",
        "best_params = None\n",
        "best_loss = float('inf')\n",
        "best_model_number = None\n",
        "model_counter = 1\n",
        "\n",
        "for params in param_combinations:\n",
        "\n",
        "    print(f\"\\nTraining model with parameters: {params}\")\n",
        "\n",
        "    model = unet(pretrained=False, base=4)\n",
        "\n",
        "    tg = DataGenerator(paths=train_paths, batch_size=params['batch_size'], augment=True)\n",
        "\n",
        "    model.compile(optimizer=params['optimizer'](learning_rate=params['learning_rate']),\n",
        "                  loss=params['loss'],\n",
        "                  metrics=[dice])\n",
        "\n",
        "    # Define EarlyStopping callback\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "    # Define validation generator\n",
        "    val_generator = DataGenerator(paths=val_paths, batch_size=params['batch_size'], augment=False)\n",
        "\n",
        "    model.fit_generator(generator=tg,\n",
        "                        steps_per_epoch=len(tg),\n",
        "                        epochs=100,  # Adjust the number of epochs based on your needs\n",
        "                        validation_data=val_generator,\n",
        "                        validation_steps=len(val_generator),\n",
        "                        verbose=1,\n",
        "                        callbacks=[early_stopping])\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    val_loss = model.evaluate_generator(generator=val_generator, steps=len(val_generator))\n",
        "\n",
        "    if val_loss[0] < best_loss:\n",
        "        best_loss = val_loss[0]\n",
        "        best_params = params\n",
        "        best_model_number = model_counter\n",
        "\n",
        "    model_counter += 1\n",
        "\n",
        "# Print the best hyperparameters and the corresponding model number\n",
        "print(f\"Best Hyperparameters for Model {best_model_number}:\", best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJhOx3I0yKOn"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbsHxbM7yNSS"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "model.fit(tg,\n",
        "          steps_per_epoch=len(tg),\n",
        "          epochs=500,\n",
        "\n",
        "          callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuKn_enyyxYT"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vswXHe9by0BH"
      },
      "outputs": [],
      "source": [
        "class_to_rgb = {\n",
        "    1: [255,128,0],\n",
        "    2: [0,128,0],\n",
        "    3: [255,255,0],\n",
        "    4: [0,255,255],\n",
        "    5: [128,0,255],\n",
        "    6: [0,255,128],\n",
        "    7: [0,128,255],\n",
        "    8: [255,0,128],\n",
        "    9: [255,255,255],\n",
        "    0: [0,0,0],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-V7Ahmqny2rI"
      },
      "outputs": [],
      "source": [
        "def classToRGB(_paddedPrediction,_class_to_rgb):\n",
        "  for x in range(0,_paddedPrediction.shape[0]):\n",
        "    for y in range(0,_paddedPrediction.shape[1]):\n",
        "      _paddedPrediction[x][y] = _class_to_rgb[_paddedPrediction[x][y][0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMU0c6nNy5mH"
      },
      "outputs": [],
      "source": [
        "# Predict all images loaded in\n",
        "for i in range(0,len(numpy_arraysx)):\n",
        "  # Image to predict\n",
        "  image=numpy_arraysx[i].reshape(1,256,256,3)\n",
        "  prediction = np.argmax(model.predict(image,verbose=0).squeeze(),axis=2)\n",
        "\n",
        "  paddedPrediction = np.pad(prediction[...,np.newaxis], ((0,0),(0,0),(0,2)), mode='constant', constant_values=1)\n",
        "  classToRGB(paddedPrediction,class_to_rgb)\n",
        "  # Predictions:\n",
        "  # Input and expected output:\n",
        "  show_image(numpy_arraysx[i])\n",
        "  show_image(numpy_arraysy[i])\n",
        "  show_image(paddedPrediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wg3h-49tdZV"
      },
      "outputs": [],
      "source": [
        "def show_segmentation_on_car_image(model, new_image_path, class_to_rgb):\n",
        "    # Load the new car image\n",
        "    new_image = Image.open(new_image_path)\n",
        "\n",
        "    # Resize the image to match the input dimensions of your model\n",
        "    new_image = new_image.resize((256, 256))\n",
        "    new_image_array = np.array(new_image) / 255.0  # Normalize pixel values\n",
        "    new_image_array = np.expand_dims(new_image_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Make predictions on the new image\n",
        "    prediction = np.argmax(model.predict(new_image_array, verbose=0).squeeze(), axis=2)\n",
        "\n",
        "    # Pad the prediction and map class values to RGB colors\n",
        "    padded_prediction = np.pad(prediction[..., np.newaxis], ((0, 0), (0, 0), (0, 2)), mode='constant', constant_values=1)\n",
        "    classToRGB(padded_prediction, class_to_rgb)\n",
        "\n",
        "    # Visualize the original image and the segmented image\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(new_image)\n",
        "    plt.title('Original Image')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(padded_prediction)\n",
        "    plt.title('Segmented Image')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "new_image_path = 'drive/My Drive/carseg_data/images/photo/no_segmentation/0168.jpg'\n",
        "show_segmentation_on_car_image(model, new_image_path, class_to_rgb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}